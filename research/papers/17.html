<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation - Ben-Or, Goldwasser, Wigderson, 1988</title>
        <link rel="stylesheet" type="text/css" href="../../style/main.css">
        <link rel="stylesheet" type="text/css" href="../../style/equation.css">
        <link rel="stylesheet" type="text/css" href="../../style/ref.css">
        <link rel="stylesheet" type="text/css" href="../../style/glossary.css">
        <link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
        <link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
        <script type="text/javascript" src="../../script/equation.js"></script>
        <script type="text/javascript" src="../../script/ref.js"></script>
        <script type="text/javascript" src="../../script/glossary.js"></script>
        <script type="text/javascript" src="../../script/def.js"></script>
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/javascript">
			<!--
            function fill(box)
			{
				switch (box)
				{
					default:
						return "No info on this equation yet.";
				}
			}

			function authorLink(ref)
			{
				switch (ref)
				{
					default:
						return "#";
				}
			}

			self_def["non-general word"] = "definition";
			//-->
        </script>
    </head>
    <body>
        <div class="main_foreground">
            <div class="main_toplevel main_header">
                <h1>Multiparty Computation</h1>
            </div>
            <div class="main_toplevel main_navigation">
                <a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
                <a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
                <a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
                <a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
                <a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
                <a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
            </div>
            <div class="main_toplevel main_section main_color1">
                <div class="main_section_nav_container">
                    <div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
                    <div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
                    <div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
                    <div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
                </div>
                <div class="main_window main_fullwidth" id="_A">
                    <div class="rp_linkbox"><a href="pdf/17.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
					
                    <span class="rp_title">Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation</span>
                    <span class="rp_info">1988
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Michael Ben-Or.html">Michael Ben-Or</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Shafi Goldwasser.html">Shafi Goldwasser</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Avi Wigderson.html">Avi Wigderson</a>    
					</span>
					
					<div class="rp_snippet">
						&ldquo;&rdquo;
					</div>
						
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a>
								<ol>
									<li><a href="#intro">Introduction</a></li>
									<li><a href="#goals">Goals and Results</a></li>
									<li><a href="#assumptions">Assumptions</a></li>
									<li><a href="#defs">Definitions</a></li>
									<li><a href="#theorems">Theorems</a></li>
									<li><a href="#protocols">Protocols</a></li>
									<li><a href="#further">Further Reading</a></li>
									<li><a href="#ref">Referencing This Paper</a></li>
								</ol>
							</li>
                            <li><a href="#_B">Annotated Paper</a></li>
                        </ol>
                    </div>
					
					<h1>Overview</h1>	
                    <section id="intro">
						<h2>Introduction</h2>
						<p class="rp_analysis">
							<b>Paper Title</b> is...
						</p>
					</section>
					<section id="goals">
						<h2>Goals and Results</h2>
						<p class="rp_analysis">
							Some goals that they had.
						</p>
						<p class="rp_analysis">
							Don't forget some results, too!
						</p>
					</section>
					<section id="assumptions">
						<h2>Assumptions</h2>
					</section>
					<section id="defs">
						<h2>Definitions</h2>
						<a href="#def1"><span class="rp_definition_header">Definition 1 - </span></a>
						<p class="rp_original rp_definition">
							A definition 
						</p>
					</section>
					<section id="theorems">
						<h2>Theorems</h2>
						<p class="rp_original">Some general definitions used by several theorems</p>
						<a href="#theorem1"><span class="rp_theorem_header">Theorem 1</span></a>
						<p class="rp_original rp_theorem">
							A theorem
						</p>
					</section>
					<section id="protocol">
						<h2>Protocols</h2>
						<h3><a href="#secxx">Some Protocol Defined</a></h3>
						<ul class="rp_analysis">
							<li><b>Number of parties: </b></li>
							<li><b>Function(s): </b></li>
							<li><b>Privacy constraints: </b></li>
							<li><b>Cheating: </b></li>
							<li><b>Bits exchanged: </b></li>
							<li><b>Subprotocols: </b></li>
							<li><b>Runtime: </b></li>
							<li><b>Assumptions: </b></li>
							<li><b>Implementations: </b></li>
							<li><b>Notes: </b></li>
						</ul>
					</section>
					<section id="further">
						<h2>Further Reading</h2>
					</section>
					<section id="ref">
						<h2>Referencing This Paper</h2>
						<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
						<p class="rp_self_reference">
							A reference for this paper
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color5" id="_B">
                <div class="main_window main_fullwidth">
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a></li>
                            <li>
                                <a href="#_B">Annotated Paper</a>
                                <ol>
                                    <li><a href="#sec1">Introduction</a></li>
                                </ol>
                            </li>
                        </ol>
                    </div>
					<section id="abstract">
						<h2>Abstract</h2>
						<p class="rp_original">
							Every function of \(n\) inputs can be efficiently computed by a complete network of \(n\) processors in such a way that:
						</p>
						<ol class="rp_original">
							<li>If no faults occur, no set of size \(t\lt\frac n 2\) of players gets any additional information (other than the function value),</li>
							<li>Even if Byzantine faults are allowed, no act of size \(t\lt\frac n 3\) can either disrupt the computation or get additional information.</li>
						</ol>
						<p class="rp_original">
							Furthermore, the above bounds on \(t\) are tight!
						</p>
					</section>
                    <section id="sec1">
                        <h2>1. Introduction</h2>
						<p class="rp_original">
							The rapid development of distributed systems raised the natural question of what tasks can be performed by them (especially when faults occur). A large body of literature over the past ten years addressed this question. There are two approaches to this question, depending on whether a limit on the computational power of processors is assumed or not.
						</p>
						<p class="rp_original">
							The cryptographic approach, inaugurated by Diffie and Hellman<sup class="reference" data-citation="DH"></sup>, assumes the players are computationally bounded, and further assumes the existence of certain (one-way) functions, that can be computed but not inverted by the player.
						</p>
						<p class="rp_original">
							This simple assumption was postulated in <span class="reference" data-citation="DH"></span> in order to achieve the basic task of secure message exchange between two of the processors, but turned out to be universal! In subsequent years, ingenious protocols based on the same assumption were given for increasingly harder tasks such as contract signing, secret exchange, joint coin flipping, voting and playing poker. These results culminated, through the definition of zero-knowledge proofs<sup class="reference" data-citation="GMR"></sup>, their existence for NP-complete problems<sup class="reference" data-citation="GMW1"></sup> in completeness theorems for two-party<sup class="reference" data-citation="Y1"></sup> and multiparty<sup class="reference" data-citation="GMW2"></sup> cryptographic distributed computation. In particular the results of Goldreich, Micali, and Wigderson in <span class="reference" data-citation="GMW2"></span> were the main inspiration to our work. They show that, if (non-uniform) one way functions exist, then every (probabilistic) function of \(n\) inputs can be computed by \(n\) computationally bounded processors in such a way that: (1) If no faults occur, no subset of the players can compute any additional information, and (2) Even if Byzantine faults are allowed, no set of size \(t\lt\frac n 2\) can either disrupt the computation or compute additional information.
						</p>
						<p class="rp_original">
							The non-cryptographic (or information-theoretic) approach does not limit the computational power of the processors. Here, the notion of privacy is much stronger - for a piece of data to be unknown to a set of players it does not suffice that they cannot compute it within a certain time bound from what they know, but simply that it cannot be computed at all!
						</p>
						<p class="rp_original">
							To facilitate the basic primitive of secret message exchange between a pair of players, we have secure channels. (For an excellent source of results and problems in the case no secure channels exist, see <span class="reference" data-citation="BL"></span>). Unlike the cryptographic case, very little was known about the capabilities of this model. Two main basic problems were studied and solved (in the synchronous case): Byzantine agreement<sup class="reference" data-citation="LPS"></sup><sup class="reference" data-citation="DS"></sup> and collective coin flipping<sup class="reference" data-citation="Y2"></sup>.
						</p>
						<p class="rp_original">
							This paper provides a full understanding of the power and limits of this model, by proving a few completeness theorems. Comparing these results to the cryptographic case of <span class="reference" data-citation="GMW2"></span>, one gets the impression that one-way functions are "more powerful" than secure channels. This should not be surprising, if one considers the case of \(n=2\). Clearly, here a secure channel is useless, and indeed two (non-fault) players can compute the OR function of their bits using cryptography, while the reader can convince herself (it will be proven later) that any protocol will leak information in the information-theoretic sense. The lower bounds we provide show that the same phenomenon is true for any value of \(n\). A similar situation arises in the Byzantine case where, using cryptography, one can allow \(t\lt\frac n 2\) fault players, bit in the non-cryptographic case one must have \(t\lt\frac n 3\).
						</p>
						<p class="rp_original">
							As happened in the cryptographic case, the protocols are based on a new method for computing with shares secrets. Our constructions are based on Algebraic Coding Theory, particularly the use of generalized BCH codes.
						</p>
						<p class="rp_original">
							It is important to stress here that our main protocols require only a polynomial amount of work from the players. (In fact, they are efficient enough to be practical!). Putting no bound on the computational power serves only to allow the most stringent definition of privacy and the most liberal definition of faultiness, both of which we can handle.
						</p>
						<p class="rp_original">
							Essentially the same results we obtain here were independently discovered by Chaum, Crépeau, and Damgård<sup class="reference" data-citation="CCD"></sup>. We briefly point out the small differences of this work from ours. The simple case of no faults is almost identical. Their solution in the case of Byzantine faults is elementary and requires no error correcting codes. The error correction is achieved using a clever scheme of zero knowledge proofs. This has two consequences: They have to allow an exponentially small error probability for both correctness and privacy (we can guarantee them with no errors), and the frequent zero knowledge proofs increase the complexity of their protocols. In the solution of <span class="reference" data-citation="CCD"></span> the simulation is of Boolean operations while our solution allows direct simulation of arithmetic operations in large finite fields. Thus, for example, computing the product of two \(n\)-bit numbers using <span class="reference" data-citation="CCD"></span> calls for \(O(\log{n})\) communication rounds. This can be done in \(O(1)\) rounds using our solution.
						</p>
						<p class="rp_original">
							We mention that the above results already found application in the new constant expected number of rounds protocol for Byzantine agreement of Feldman and Micali<sup class="reference" data-citation="FM"></sup>.
						</p>
						<p class="rp_original">
							We proceed to define the model, state the results and prove them. In the full paper we mention generalizations and extensions of our results to other tasks (playing games rather than computing functions), to other model parameters (synchrony, communication networks), and other complexity measures (number of rounds).
						</p>
                    </section>
					<section id="sec2">
						<h2>2. Definitions and Results</h2>
						<p class="rp_original">
							For this abstract, we define the model and state the results on an intuitive level. Since even the formal definition of the notions of privacy and resiliency are nontrivial, we give them explicitly in an appendix.
						</p>
						<p class="rp_original">
							The model of computation is a complete synchronous network of \(n\) processors. The pairwise communication channels between players are secure, i.e. they cannot be read or tempered with by other players. In one round of computation each of the players can do an arbitrary amount of local computation, send a message to each of the players, and read all messages that were sent to it at this round.
						</p>
						<p class="rp_original">
							We shall be interested in the computational power of this model when imposing privacy and fault tolerance requirements. For simplicity, we restrict ourselves to the computation of (probabilistic) functions \(f\) from \(n\) inputs to \(n\) outputs. We assume that player \(i\) holds the \(i\)-th input at the start of computation, and should obtain the \(i\)-th output at the end, but nothing else.
						</p>
						<p class="rp_original">
							A protocol for computing a function is a specification of \(n\) programs, one for each of the players. We distinguish two kinds of faults: "Gossip" and "Byzantine". In the first, fault processors send messages according to their predetermined program, but try to learn as much as they can by sharing the information they received. In the second, they can use totally different programs, collaborating to acquire more information or even sabotage the computation.
						</p>
						<p class="rp_original">
							A protocol is \(t\)-<i>private</i> if any set of at most \(t\) players cannot compute after the protocol more than they could jointly compute solely from their set of privacy inputs and outputs.
						</p>
						<p class="rp_original">
							A protocol is \(t\)-<i>resilient</i> if no set of \(t\) or fewer players can influence the correctness of the outputs of the remaining players. For this to make sense, the function definition should be extended to specify what it is if some players neglect to give their inputs or are caught cheating (see <span data-broken-link=true>appendix</span>).
						</p>
						<p class="rp_original">
							We can now state the main results of this paper.
						</p>
						<span class="rp_theorem_header">Theorem 1:</span>
						<p class="rp_original rp_theorem">
							For every (probabilistic) function \(f\) and \(t\lt\frac n 2\) there exists a \(t\)-private protocol.
						</p>
						<span class="rp_theorem_header">Theorem 2:</span>
						<p class="rp_original rp_theorem">
							There are functions for which there are no \(frac n 2\) private protocols.
						</p>
						<span class="rp_theorem_header">Theorem 3:</span>
						<p class="rp_original rp_theorem">
							For every probabilistic function and every \(t\lt\frac n 3\) there exists a protocol that is both \(t\)-resilient and \(t\)-private.
						</p>
						<span class="rp_theorem_header">Theorem 4:</span>
						<p class="rp_original rp_theorem">
							There are functions for which there is not \(\frac n 3\)-resilient protocol.
						</p>
					</section>
					<section id="sec3">
						<h2>3. Proof of Theorem 1</h2>
						<p class="rp_original">
							Let \(P_0,\dots,p_{n-1}\) be a set of players, and let \(n\geq 2t+1\). Let \(F\) be the function which this set of players wants to compute \(t\)-privately, where each player holds some input variables to the function \(F\). Let \(E\) be some fixed finite field \(E\), with \(|E|\gt n\). Without loss of generality we may assume that all inputs are elements from \(E\) and that \(F\) is some polynomial ( inthe input variables) over \(E\), and that we are given some arithmetic circuit computing \(|F|\), using the operations \(+,\times\), and constants from \(E\).
						</p>
						<p class="rp_original">
							To simplify our explanation, we divide the computation into three stages.
						</p>
						<span class="rp_sub_header">Stage I</span>
						<p class="rp_original rp_sub">
							The input stage, where each player will enter his input variables to the computation using a secret sharing procedure.
						</p>
						<span class="rp_sub_header">Stage II</span>
						<p class="rp_original rp_sub">
							The computation stage, where the players will simulate the circuit computing \(F\), gate by gate, keeping the value of each computed gate as secret shared by all players.
						</p>
						<span class="rp_sub_header">Stage III</span>
						<p class="rp_original rp_sub">
							The final stage, where the secret shares of the final values of \(F\) are revealed to one or all of the players.
						</p>
						<p class="rp_original">
							Stages I and III are very simple and we describe them below, and delay the details of the computation stage to the next section.
						</p>
						<section id="sec3.1">
							<h3>3.1. The Input Stage</h3>
							<p class="rp_original">
								Let \(a_0,\dots,a_{n-1}\) be some \(n\) distinct non-zero points in our field \(E\). (This is why we need \(|E|\gt n\).) Each player holding some input \(s\in E\), introduces the input to the computation by selecting \(t\) random elements \(a_i\in E\), for \(i=1,\dots,t\), setting $$f(x)=s+a_1x+\cdots+a_tx^t$$ and sending to each player \(P_i\) the value \(s_i=f(a_i)\).
							</p>
							<p class="rp_original">
								As in Shamir's<sup class="reference" data-citation="Sh"></sup> secret sharing scheme, the sequence \((s_0,\dots,s_{n-1})\) is a sequence of \(t\)-wise independent random variables uniformly distributed over \(E\), thus the value of the input is completely independent from the shares \(\{s_i\}\) that are given to any set of \(t\) player that does not include the player holding the secret.
							</p>
						</section>
						<section id="sec3.2">
							<h3>3.2. The Final Stage</h3>
							<p class="rp_original">
								To keep the \(t\)-privacy condition, we will make sure that the set of messages received by any set of \(t\) players will be completely independent from all the inputs. During the whole computation each gate which evaluates to some \(s\in E\), will be "evaluated" by the players by sharing the secret value of \(s\) using a completely independent from all the inputs, random polynomial \(f(x)\) of degree \(t\), with the only restriction that \(f(0)=s\). In particular at the end of the computation we will have the value of \(F\) shared among the players in a similar manner. If we want to let just one player know the output value, all the players send their shares to that particular player. This player can compute the interpolation polynomial \(f(x)\) and use its free coefficient as the result.
							</p>
							<p class="rp_original">
								Note that there is a one-to-one correspondence between the set of all shares and the coefficients of the polynomial \(f(x)\). Since all the coefficients of \(f(x)\), except for its free coefficient, are uniform random variables that are independent of the inputs, the set of all shares does not contain any information about the inputs that does not follow from the value of \(f(x)\).
							</p>
						</section>
					</section>
					<section id="sec4">
						<h2>4. The Computation Stage</h2>
						<p class="rp_original">
							Let \(a,b\in E\) be two secrets that are shared using the polynomials \(f(x),\,g(x)\) respectively, and let \(c\in E,\;c\neq0\) be some constant. It is enough to show how one can "compute" \(c\cdot a,\,a+b\), and \(a\cdot b\).
						</p>
						<p class="rp_original">
							The two linear operations are simply and for their evaluation we do not need any communication between the players. This is because if \(f(x)\) and \(g(x)\) encode \(a\) and \(b\), then the polynomials \(h(x)=c\cdot f(x)\) and \(k(x)=f(x)+g(x)\) encode \(c\cdot a,\,a+b\) respectively. Thus to compute for example \(a+b\), each player \(P_i\) holding \(f(a_i)\), and \(g(a_i)\) can compute \(k(a_i)=f(a_i)+g(a_i)\). Likewise, since \(c\) is a known constant \(P_i\) can compute \(h(a_i)=c\cdot f(a_i)\). Furthermore, \(h(x)\) is random if only \(f(x)\) was, and \(k(x)\) is random if only one of \(f(x)\) or \(g(x)\) was.
						</p>
						<p class="rp_original">
							As a corollary we immediately have
						</p>
						<span class="rp_theorem_header">Lemma 1: (Linear Functional)</span>
						<p class="rp_original rp_theorem">
							For any \(t,\,(t\leq n-1)\), any linear functional $$F(x_0,\dots,x_{n-1})=a_0x_0+\cdots+a_{n-1}x_{n-1},$$ where each \(P_i\) has input \(x_i\) and the \(a_i\) are known constants, can be computed \(t\)-privately. 
						</p>
						<p class="rp_original">
							From the lemma we have
						</p>
						<span class="rp_theorem_header">Corollary 1: (Matrix Multiplication)</span>
						<p class="rp_original rp_theorem">
							Let \(A\) be a constant \(n\times n\) matrix, and let each \(P_i\) hae an input variable \(x_i\). Let \(X=(x_0,\dots,x_{n-1})\) and define \(Y=(y_1,\dots,y_n)\) by $$Y=X\cdot A$$ then for any \(t,\,(t\leq n-1)\), we can \(t\)-privately compute the vector \(Y\) such that the only information given to \(P_i\) will be the value of \(Y_i\), for \(i=0,\dots,n-1\).
						</p>
						<span class="rp_sub_header">Proof:</span>
						<p class="rp_original rp_sub">
							Matrix multiplication is just the evaluation of \(n\) linear functionals. By the LEmma, we can compute each linear functional \(Y_i\) independently, and reveal the outcome only to \(P_i\).
						</p>
						<section id="sec4.1">
							<h3>4.1. The Multiplication Step</h3>
							<p class="rp_original">
								The multiplication step is only a bit harder. Let \(a\) and \(b\) be encoded by \(f(x)\) and \(g(x)\) as above. We now assume that \(n\geq 2t+1\). Not that the free coefficient of the polynomial \(h(x)=f(x)g(x)\) is \(a\cdot b\). There are two problems with using \(h(x)\) to encode the product of \(a\) times \(b\). The first, and obvious, one is that the degree of \(h(x)\) is \(2t\) instead of \(t\). While this poses no problem with interpolating \(h(x)\) from its \(n\) pieces since \(n\geq 2t+1\), it is clear that further multiplications will raise the degree, and once the degree passes \(n\) we will not have enough points for the interpolation. The second problem is more subtle. \(h(x)\) is not a <i>random</i> polynomial of degree \(2t\) (ignoring, of course, the free coefficient). For example, \(h(x)\), as a product of two polynomials, cannot be irreducible.
							</p>
							<p class="rp_original">
								To overcome these two problems we will, in one step, randomize the coefficients of \(h(x)\), and reduce its degree while keeping the free coefficient unchanged. We first describe the degree reduction procedure and then combine it with the randomization of the coefficients.
							</p>
						</section>
						<section id="sec4.2">
							<h3>4.2. The degree reduction step</h3>
							<p class="rp_original">
								Let $$h(x)=h_0+h_1x+\cdots+h_{2t}x^{2t}$$ and let $$s_i=h(\alpha_i)=f(\alpha_i)g(\alpha_i),$$ for \(i=0,\dots,n-1\) be the "shares" of \(h(x)\). Each \(P_i\) holds an \(s_i\). Define the truncation of \(h(x)\) to be $$k(x)=h_0+h_1x+\cdots+h_tx^t,$$ and \(r_i=k(\alpha_i)\) for \(i=1,\cdots,n-1\).
							</p>
							<span class="rp_sub_header">Claim:</span>
							<p class="rp_original rp_sub">
								Let \(S=(s_0,\dots,s_{n-1})\) and \(R=(r_0,\dots,r_{n-1})\) then there is a constant \(n\times n\) matrix \(A\) such that $$R=S\cdot A.$$
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Let \(H\) be the \(n\)-vector $$H=(h_0,\dots,h_t,\dots,h_{2t},0,\dots,0)$$ and let \(K\) be the \(n\)-vector $$K=(h_0,\dots,h_t,0,\dots,0).$$
							</p>
							<p class="rp_original rp_sub">
								Let \(B=(b_{i,j})\) be the \(n\times n\) (Vandermonde) matrix, where \(b_{i,j}=a_j^i\) for \(i,j=0,\dots,n-1\). Furthermore, let \(P\) be the linear projection $$P(x_0,\dots,x_{n-1})=(x_0,\dots,x_t,0,\dots,0).$$
							</p>
							<p class="rp_original rp_sub">
								We have $$H\cdot B=S$$ $$H\cdot P=K$$ and $$K\cdot B=R.$$
							</p>
							<p class="rp_original rp_sub">
								Since \(B\) is not singular (because the \(\alpha_i\)'s are distinct) we have $$S\cdot(B^{-1}PB)=R$$ but \(A=B^{-1}PB\) is some fixed constant matrix, proving our claim.
							</p>
						</section>
						<section id="sec4.3">
							<h3>4.3. The Randomization Step</h3>
							<p class="rp_original">
								As noted above, the coefficients of the product polynomial are not completely random, and likewise the coefficients of its truncation \(k(x)\) may not be completely random. To randomize the coefficients, each player \(P_i\) randomly selects a polynomial \(q_i(x)\) of degree \(2t\) with a zero free coefficient, and distributes its shares among the player. By a simple generalization of the argument in Shamir's<sup class="reference" data-citation="Sh">[?]</sup> scheme, it is easy to see that knowing \(t\) values on this polynomial gives no information on the vector of coefficients of the monomials of \(x,x^2,\dots,x^t\) of \(q_i(x)\).
							</p>
							<p class="rp_original">
								Thus instead of using \(h(x)\) in our reduction we can use $$\widetilde{h}(x)=h(x)+\sum\limits_{j=0}^{n-1}{q_j(x)}$$ which satisfies \(\widetilde{h}(0)=h(0)\) but the other coefficients of \(x^i,1\leq i\leq t\), are completely random. Since each player can evaluate his or her point \(\widetilde s_i = \widetilde h(\alpha_i)\), we can now apply the truncation procedure using the matrix multiplication lemma to arrive at a completely random polynomial \(\widetilde k(x)\) which satisfies both \(\operatorname{deg}\widetilde k(x)=t\), and \(\widetilde k(0)=a\cdot b\), and \(k(x)\) is properly shared among all the players.
							</p>
							<p class="rp_original">
								Thus (omitting many well known details, see <span class="reference" data-citation="GMW">[?]</span>) we have proved
							</p>
							<span class="rp_theorem_header" id="theorem1">Theorem 1:</span>
							<p class="rp_original rp_theorem">
								For every (probabilistic) function \(f\) and \(t\lt\frac n 2\) there exists a \(t\)-private protocol.
							</p>
							<span class="rp_sub_header">Remarks:</span>
							<ol class="rp_original rp_sub">
								<li>The complexity of computing \(F\) \(t\)-privately is bounded by a polynomial (in \(n\)) factor times the complexity of computing \(F\).</li>
								<li>If \(F\) can be computed by an arithmetic circuit over some field using unbounded fan-in linear operation and bounded fan-in multiplication, in depth \(d\), then \(F\) can be computed \(t\)-privately in \(O(d)\) rounds of exchange of information.</li>
								<li>
									<p>
										In our construction we have to reduce the degree of our polynomial only when its degree is about to pass \(n-1\). Thus if \(t=O(n^{1-\epsilon})\), for some fixed \(\epsilon\gt 0\), and we start with polynomials of degree \(t\), the players can simulate many steps of the computation before the degree comes close to \(n\), by doing the computation each on their own shares, without any communication(!). When the degree does get close to \(n\), we reduce the degree back to \(t\) in one randomizing, degree reducing step.
									</p>
									<p>
										Two simple examples are:
									</p>
									<ol type="a">
										<li>Any Boolean function \(F:\,\{0,1\}^n\;\rightarrow\;\{0,1\}\) can be represented as a multilinear polynomial over the field \(F\). Thus if \(t=O(n^{1-\epsilon})\) we can compute \(t\)-privately, in parallel, all the monomials of \(F\) in \(O(1)\) number of rounds and then use a big fan-in addition to evaluate \(F\). This procedure may use exponentially long messages but only constant number of rounds.</li>
										<li>The Boolean Majority function has a polynomial size \(O(\log n)\) depth circuit, and thus for \(t\,=\,O(n^{1-\epsilon})\), this function can be computed \(t\)-privately using only polynomically long messages in constant number of rounds.</li>
									</ol>
								</li>
							</ol>
							<p class="rp_original">
								For completeness we state the following simple result.
							</p>
							<span class="rp_theorem_header">Theorem 2:</span>
							<p class="rp_original rp_theorem">
								There are functions for which there are no 	\(frac n 2\) private protocols.
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								It is easy to see that two players, each holding one input bit, cannot compute the OR function of their bits without one of them leaking some information. This immediately generalizes to prove the theorem.
							</p>
						</section>
					</section>
					<section id="sec5">
						<h2>5. Sharing a Secret with Cheaters</h2>
						
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color8">
                <h1>References</h1>
                <ol id="referencelist">
					<li id="BL">M. Ben-Or and N. Linial, Collective coin flipping, <i>FOCS86</i>.</li>
					<li id="CCD">D. Chaum, C. Crépeau, and I. Damgård. Multiparty unconditionally secure protocols. These proceedings.</li>
					<li id="DH">W. Diffie and M. E. Helman, New directions in cryptography, <i>IEEE Trans. Inform. Theory</i>, Vol. IT-22, pp.644-654, 1976.</li>
					<li id="DS">D. Dolev and R. Strong. Polynomial algorithms for multiple processor agreement. <i>STOC82</i>.</li>
					<li id="FM">P. Feldman and S. Micali, Optimal algorithms for Byzantine agreement. These proceedings</li>
					
					<li id="GMW1">O. Goldreich, S. Micali, and A. Wigderson. Proofs that yield nothing but the validity of the assertion, and a methodology of cryptographic protocol design. <i>FOCS86</i>, pp. 174-187.</li>
					<li id="GMW2">O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game. <i>STOC87</i>, pp.218-229.</li>
					<li id="GMR">S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof systems. <i>STOC85</i>, pp. 291-304.</li>
					<li id="PSL">M. Pease, R. Shostak, and L. Lamport. Reaching agreement in the presence of faults, <i>JACM</i>. Vol. 27, pp. 228-234. 1980.</li>
					<li id="PW">W. W. Peterson and E. J. Weldon, Error correcting codes, Second Ed., MIT Press. 1972.</li>
					
					<li id="Sh">A. Shamir, How to share a secret. <i>CACM 22</i>, pp. 612-613. 1979.</li>
					<li id="Y1">A. C. Yao, How to generate and exchange secrets. <i>STOC86</i>.</li>
					<li id="Y2">A. C. Yao, On the succession problem for Byzantine Generals, manuscript. 1983.</li>
                </ol>
            </div>
            <div class="main_toplevel main_section main_color9">
                <div class="rp_problems">
                    <p><a href="mailto:multipartycomputationorg+17@gmail.com">Problem with this page?</a></p>
                </div>
                <p>Created by Nicolas Schank 2014, Brown University</p>
				<p>All original work is free for any use by anyone whatsoever.</p>
				<p>For more information about liability and licensing Yao's original paper, see <a href="../liability.html">Liability</a>.</p>
            </div>
        </div>
    </body>
</html>
<!--
4. Headings
5. Transcribe paper
7. Annotate paper
	7.0. proofread
	7.1. copy assumptions
	7.2. copy theorems
	7.3. copy definitions
	7.4. mark definitions
	7.5. mark equations
	7.6. link to previous research
8. Write protocol descriptions 
9. Check previous research for places to link
10. Write intro, goals, results
11. Tags
12. Consider implementations
13. Find reference
-->