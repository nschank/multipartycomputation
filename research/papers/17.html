<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation - Ben-Or, Goldwasser, Wigderson, 1988</title>
        <link rel="stylesheet" type="text/css" href="../../style/main.css">
        <link rel="stylesheet" type="text/css" href="../../style/equation.css">
        <link rel="stylesheet" type="text/css" href="../../style/ref.css">
        <link rel="stylesheet" type="text/css" href="../../style/glossary.css">
        <link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
        <link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
		<script type="text/javascript" src="../../script/difficulty.js"></script>
        <script type="text/javascript" src="../../script/equation.js"></script>
        <script type="text/javascript" src="../../script/ref.js"></script>
        <script type="text/javascript" src="../../script/fnote.js"></script>
        <script type="text/javascript" src="../../script/glossary.js"></script>
        <script type="text/javascript" src="../../script/def.js"></script>
        <script type="text/javascript" src="../../script/toc.js"></script>
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/javascript">
			<!--
            function fill(box)
			{
				switch (box)
				{
					case "E[x]":
						return {difficulty:5,blockName:"E[x]",info:[{type:"p",content:"\\(E[x]\\) refers to the <span class=\"load-definable\">polynomial ring</span> over the variable \\(x\\) on the field \\(E\\)."}]};
					case "omega":
						return {difficulty:5,blockName:"omega",info:[{type:"p",content:"\\(\\omega\\) is a primitive \\(n\\)th <span class=\"load-definable\">root of unity</span> within \\(E\\)."}]};
					case "truncation":
						return {difficulty:5,blockName:"truncation",info:[{type:"p",content:"The truncation \\(k(x)\\) of \\(h(x)\\), where \\(h(x)\\) is the degree \\(2t\\) function defined to be \\(h(x)=f(x)g(x)\\) for shared secrets \\(f(x)\\) and \\(g(x)\\), is defined to be $$k(x)=h_0+h_1x+\\dots+h_tx^t.$$"}]};
					default:
						console.log("Developer note: Equation " + box + " undefined");
						return {difficulty:5,info:[{type:"p",content:"No info on this equation yet."}]};
				}
			}
			
			self_def["t-private"] = {title:"\\(t\\)-private",difficulty:5,blockName:"17private",def:[{type:"p",content:"A protocol is \\(t\\)-<i>private</i> if any set of at most \\(t\\) players cannot compute more after the protocol than they could jointly compute solely from their own of private inputs and outputs."}]};
			self_def["t-resilient"] = {title:"\\(t\\)-resilient",difficulty:5,blockName:"17resilient",def:[{type:"p",content:"A protocol is \\(t\\)-<i>resilient</i> if no set of \\(t\\) or fewer players can influence the correctness of the outputs of the remaining players."}]};
			//-->
        </script>
    </head>
    <body>
        <div class="main_foreground">
            <div class="main_toplevel main_header">
                <h1>Multiparty Computation</h1>
            </div>
            <div class="main_toplevel main_navigation">
                <a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
                <a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
                <a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
                <a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
                <a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
                <a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
            </div>
            <div class="main_toplevel main_section main_color1" id="overview">
                <div class="main_section_nav_container">
                    <div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
                    <div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
                    <div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
                    <div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
                </div>
                <div class="main_window main_fullwidth">
                    <div class="rp_linkbox"><a href="pdf/17.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
					
                    <span class="rp_title">Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation</span>
                    <span class="rp_info">1988
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Michael Ben-Or.html">Michael Ben-Or</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Shafi Goldwasser.html">Shafi Goldwasser</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Avi Wigderson.html">Avi Wigderson</a>    
					</span>
					
					<div class="rp_snippet">
						&ldquo;[Chaum, Cr&eacute;peau, and Damg&aring;rd] have to allow an exponentially small error probability for both correctness and privacy (we can guarantee them with no errors).... In [their solution] the simulation is of Boolean operations while our solution allows direct simulation of arithmetic operations in large finite fields.&rdquo;
					</div>
					<h1>Overview</h1>
						
                    <div class="main_toc"></div>
						
                    <section id="intro">
						<h2>Introduction</h2>
						<p class="rp_analysis">
							<b>Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation</b> is a 1988 paper by Ben-Or, Goldwasser, and Wigderson which demonstrated the bounds of (and described a protocol for) multiparty computation which is <span class="load-definable" data-define="information theoretic security">information theoretically secure</span>. It is one of <a href="34.html">two papers</a> in the same year which demonstrates that up to &frac13; parties can be actively <span class="load-definable" data-define="malicious adversary">malicious</span> without affecting correctness or privacy. The other paper offers information theoretic security in a very similar manner, while this paper additionally guarantees correctness (as opposed to a <span class="load-definable">negligible</span> probability of incorrectness).
						</p>
						<p class="rp_analysis">
							One major difference between this paper and <a href="34.html">its chronological counterpart</a> is the type of computation performed. Chaum's construction is based around Boolean operation simulations, while this protocol uses an arithmetic circuit within a finite field. Very significantly, this finite field is <u>not</u> arbitrary as implied in the paper: it must be of the form \(GF(p^{k\operatorname\phi(n)})\), where \(n\) is the number of parties who must participate, \(p\) is any prime that is not a factor of \(n\) (generally the minimal prime), and \(k\) is any<sup class="footnote" id="fref3" data-footnote="3"><a href="#footnote3">3</a></sup> positive integer. This is necessary in order to allow for the fault tolerance properties sought; more details can be found in <a href="#sec5">Section 5</a>.
						</p>
						<p class="rp_analysis">
							Note that a true protocol specification is not given in this work; it offers completeness theorems, and uses a more general specification in order to prove its purposes. For example, no particular algorithm for the error checking and correctness is given, but its existence is sufficient to prove their claims.
						</p>
					</section>
					<section id="goals">
						<h2>Goals and Results</h2>
						<p class="rp_analysis">
							The authors intended to find upper bounds on what types of computation are possible in the <span class="load-definable" data-define="information-theoretic security">information-theoretic model</span>, and the bounds they found were optimal. This result is, of course, dependent on the specification of the network (which can be found in <a href="#assumptions">Assumptions</a>).
						</p>
						<p class="rp_analysis">
							Simply put, protocols can guarantee both correctness and information-theoretic security in the case when \(t\lt\frac n 3\) parties are <span class="load-definable" data-define="malicious adversary">malicious</span>. This paper additionally extends the cryptographic privacy on <span class="load-definable" data-define="passive adversary">passive adversaries</span>&mdash;\(t\lt\frac n 2\)&mdash;to information-theoretic multiparty computation. These two limits are not achievable simultaneously through the protocol presented.
						</p>
						<p class="rp_analysis">
							The authors provided privacy using a familiar verifiable secret sharing scheme based on finite fields. Their methodology for correctness is more clever; by ensuring the VSS scheme was constructed such that it had an <span class="load-definable" data-define="error-correcting code">error correcting code</span> (using the <span class="load-definable">Discrete Fourier Transform</span>), they reduced fault tolerance within the scheme to known algorithms for error correction.
						</p>
					</section>
					<section id="assumptions">
						<h2>Assumptions</h2>
						<p class="rp_analysis">
							This paper made a point of not relying on any cryptographic assumptions; its results are only based on the type of network, which is specified to be complete, <span class="load-definable" data-define="synchronous network">synchronous</span>, <span class="load-definable" data-define="secure network">secure</span>, and <span class="load-definable" data-define="authenticated network">authenticated</span>.
						</p>
					</section>
					<section id="defs">
						<h2>Definitions</h2>
						<a href="#appendix"><span class="rp_definition_header">Definition 1 - \(t\)-privacy</span></a>
						<p class="rp_original rp_definition">
							A protocol is \(t\)-<i>private</i> if any set of at most \(t\) players cannot compute after the protocol more than they could jointly compute solely from their set of privacy inputs and outputs.
						</p>
						<a href="#appendix"><span class="rp_definition_header">Definition 2 - \(t\)-resiliency</span></a>
						<p class="rp_original rp_definition">
							A protocol is \(t\)-<i>resilient</i> if no set of \(t\) or fewer players can influence the correctness of the outputs of the remaining players. For this to make sense, the function definition should be extended to specify what it is if some players neglect to give their inputs or are caught cheating (see <a href="#appendix">appendix</a>).
						</p>
					</section>
					<section id="theorems">
						<h2>Theorems</h2>
						<a href="#lemma1"><span class="rp_theorem_header">Lemma 1: (Linear Functional)</span></a>
						<p class="rp_original rp_theorem">
							For any \(t,\,(t\leq n-1)\), any linear functional $$F(x_0,\dots,x_{n-1})=a_0x_0+\cdots+a_{n-1}x_{n-1},$$ where each \(P_i\) has input \(x_i\) and the \(a_i\) are known constants, can be computed <span class="load-definable" data-define="t-private">\(t\)-privately</span>. 
						</p>
						<a href="corollary1"><span class="rp_theorem_header">Corollary 1: (Matrix Multiplication)</span></a>
						<p class="rp_original rp_theorem">
							Let \(A\) be a constant \(n\times n\) matrix, and let each \(P_i\) have an input variable \(x_i\). Let \(X=(x_0,\dots,x_{n-1})\) and define \(Y=(y_1,\dots,y_n)\) by $$Y=X\cdot A$$ then for any \(t,\,(t\leq n-1)\), we can <span class="load-definable" data-define="t-private">\(t\)-privately</span> compute the vector \(Y\) such that the only information given to \(P_i\) will be the value of \(Y_i\), for \(i=0,\dots,n-1\).
						</p>
						<a href="#theorem1"><span class="rp_theorem_header">Theorem 1:</span></a>
						<p class="rp_original rp_theorem">
							For every (probabilistic) function \(f\) and \(t\lt\frac n 2\) there exists a <span class="load-definable" data-define="t-private">\(t\)-private</span> protocol.
						</p>
						<a href="#theorem2"><span class="rp_theorem_header">Theorem 2:</span></a>
						<p class="rp_original rp_theorem">
							There are functions for which there are no \(\frac n 2\)-<span class="load-definable" data-define="t-private">private</span> protocols.
						</p>
						<a href="#theorem3"><span class="rp_theorem_header">Theorem 3:</span></a>
						<p class="rp_original rp_theorem">
							For every probabilistic function and every \(t\lt\frac n 3\) there exists a protocol that is both <span class="load-definable" data-define="t-resilient">\(t\)-resilient</span> and <span class="load-definable" data-define="t-private">\(t\)-private</span>.
						</p>
						<a href="#theorem4"><span class="rp_theorem_header">Theorem 4:</span></a>
						<p class="rp_original rp_theorem">
							There are functions for which there is no \(\frac n 3\)-<span class="load-definable" data-define="t-resilient">resilient</span> protocol.
						</p>
					</section>
					<section id="further">
						<h2>Further Reading</h2>
						<p class="rp_analysis">
							For a similar but differently presented take on information-theoretic computation within a finite field, see Chaum, Cr&eacute;peau, and Damg&aring;rd's <a href="34.html">work of the same year</a>.
						</p>
						<p class="rp_analysis">
							This paper is part of a series covering the completeness theorems on <u>tolerability of adversarial structures</u>:
						</p>
						<ol class="rp_analysis">
							<li><b><a href="81.html">How to Play Any Mental Game (1987)</a></b>: Cryptographic Security for Honest Majority, No Fault Tolerance</li>
							<li><b><a href="82.html">Multiparty Computation Ensuring Privacy... (1988)</a></b>: Information-Theoretic Security for One Party, Negligible Probability of Cheating</li>
							<li><b><a href="34.html">Multiparty Unconditionally Secure Protocols (1988)</a></b>: Information-Theoretic Security for \(2n/3\) Honest Parties, Negligible Probability of Cheating</li>
							<li><b><i>Completeness Theorems for Non-Cryptographic... (1988)</i></b>: Information-Theoretic Security for \(2n/3\) Honest Parties, Perfectly Fault Tolerant for \(2n/3\) Honest Parties</li>
							<li><b><a href="76.html">Verifiable Secret Sharing and Multiparty Protocols... (1989)</a></b>: Information-Theoretic Security for Honest Majority, Negligible Probability of Cheating</li>
						</ol>
					</section>
					<section id="ref">
						<h2>Referencing This Paper</h2>
						<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
						<p class="rp_self_reference">
							M. Ben-Or, S. Goldwasser, and A. Wigderson. Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation. <i>Proceedings of the Twentieth Annual ACM Symposium on Theory of Computing,</i> pages 1-10. ACM. 1988. 
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color3" id="annotated_paper">
                <div class="main_window main_fullwidth">
					<h1>Annotated Paper (extended Abstract)</h1>
                    <div class="main_toc"></div>
					<section id="abstract" data-section-number="0">
						<h2>Abstract</h2>
						<p class="rp_original">
							Every function of \(n\) inputs can be efficiently computed by a complete network of \(n\) processors in such a way that:
						</p>
						<ol class="rp_original">
							<li>If no faults occur, no set of size \(t\lt\frac n 2\) of players gets any additional information (other than the function value),</li>
							<li>Even if <span class="load-definable" data-define="Byzantine fault">Byzantine faults</span> are allowed, no act of size \(t\lt\frac n 3\) can either disrupt the computation or get additional information.</li>
						</ol>
						<p class="rp_original">
							Furthermore, the above bounds on \(t\) are tight!
						</p>
					</section>
                    <section id="sec1">
                        <h2>1. Introduction</h2>
						<p class="rp_original">
							The rapid development of distributed systems raised the natural question of what tasks can be performed by them (especially when faults occur). A large body of literature over the past ten years addressed this question. There are two approaches to this question, depending on whether a limit on the computational power of processors is assumed or not.
						</p>
						<p class="rp_original">
							The cryptographic approach, inaugurated by Diffie and Hellman<sup class="reference" data-citation="DH"></sup>, assumes the players are computationally bounded, and further assumes the existence of certain (one-way) functions, that can be computed but not inverted by the player.
						</p>
						<p class="rp_original">
							This simple assumption was postulated in <span class="reference" data-citation="DH"></span> in order to achieve the basic task of secure message exchange between two of the processors, but turned out to be universal! In subsequent years, ingenious protocols based on the same assumption were given for increasingly harder tasks such as contract signing, secret exchange, joint coin flipping, voting, and playing poker. These results culminated, through the definition of zero-knowledge proofs<sup class="reference" data-citation="GMR"></sup> and their existence for NP-complete problems<sup class="reference" data-citation="GMW1"></sup>, in completeness theorems for two-party<sup class="reference" data-citation="Y1"></sup> and multiparty<sup class="reference" data-citation="GMW2"></sup> cryptographic distributed computation. In particular the results of Goldreich, Micali, and Wigderson in <span class="reference" data-citation="GMW2"></span> were the main inspiration to our work. They show that, if (non-uniform) <span class="load-definable" data-define="one-way function">one-way functions</span> exist, then every (probabilistic) function of \(n\) inputs can be computed by \(n\) computationally bounded processors in such a way that: (1) If no faults occur, no subset of the players can compute any additional information, and (2) Even if <span class="load-definable" data-define="Byzantine fault">Byzantine faults</span> are allowed, no set of size \(t\lt\frac n 2\) can either disrupt the computation or compute additional information.
						</p>
						<p class="rp_original">
							The non-cryptographic (or <span class="load-definable" data-define="information theoretic security">information-theoretic</span>) approach does not limit the computational power of the processors. Here, the notion of privacy is much stronger - for a piece of data to be unknown to a set of players it does not suffice that they cannot compute it within a certain time bound from what they know, but simply that it cannot be computed at all!
						</p>
						<p class="rp_original">
							To facilitate the basic primitive of secret message exchange between a pair of players, we have <span class="load-definable" data-define="secure network">secure channels</span>. (For an excellent source of results and problems in the case no secure channels exist, see <span class="reference" data-citation="BL"></span>). Unlike the cryptographic case, very little was known about the capabilities of this model. Two main basic problems were studied and solved (in the synchronous case): Byzantine agreement<sup class="reference" data-citation="LPS"></sup><sup class="reference" data-citation="DS"></sup> and collective coin flipping<sup class="reference" data-citation="Y2"></sup>.
						</p>
						<p class="rp_original">
							This paper provides a full understanding of the power and limits of this model, by proving a few completeness theorems. Comparing these results to the cryptographic case of <span class="reference" data-citation="GMW2"></span>, one gets the impression that one-way functions are "more powerful" than secure channels. This should not be surprising, if one considers the case of \(n=2\). Clearly, here a secure channel is useless, and indeed two (non-fault) players can compute the OR function of their bits using cryptography, while the reader can be convinced (it will be proven later) that any protocol will leak information in the information-theoretic sense. The lower bounds we provide show that the same phenomenon is true for any value of \(n\). A similar situation arises in the Byzantine case where, using cryptography, one can allow \(t\lt\frac n 2\) fault players, but in the non-cryptographic case one must have \(t\lt\frac n 3\).
						</p>
						<p class="rp_original">
							As happened in the cryptographic case, the protocols are based on a new method for computing with shared secrets. Our constructions are based on Algebraic Coding Theory, particularly the use of generalized BCH codes.
						</p>
						<p class="rp_original">
							It is important to stress here that our main protocols require only a polynomial amount of work from the players. (In fact, they are efficient enough to be practical!). Putting no bound on the computational power serves only to allow the most stringent definition of privacy and the most liberal definition of faultiness, both of which we can handle.
						</p>
						<p class="rp_original">
							Essentially the same results we obtain here were independently discovered by Chaum, Cr&eacute;peau, and Damg&aring;rd<sup class="reference" data-citation="CCD"></sup>. We briefly point out the small differences of this work from ours. The simple case of no faults is almost identical. Their solution in the case of Byzantine faults is elementary and requires no error correcting codes. The error correction is achieved using a clever scheme of zero knowledge proofs. This has two consequences: They have to allow an exponentially small error probability for both correctness and privacy (we can guarantee them with no errors), and the frequent zero knowledge proofs increase the complexity of their protocols. In the solution of <span class="reference" data-citation="CCD"></span> the simulation is of Boolean operations while our solution allows direct simulation of arithmetic operations in large finite fields. Thus, for example, computing the product of two \(n\)-bit numbers using <span class="reference" data-citation="CCD"></span> calls for \(O(\log{n})\) communication rounds. This can be done in \(O(1)\) rounds using our solution.
						</p>
						<p class="rp_original">
							We mention that the above results already found application in the new constant expected number of rounds protocol for Byzantine agreement of Feldman and Micali<sup class="reference" data-citation="FM"></sup>.
						</p>
						<p class="rp_original">
							We proceed to define the model, state the results and prove them. In the full paper we mention generalizations and extensions of our results to other tasks (playing games rather than computing functions), to other model parameters (<span class="load-definable" data-define="synchronous network">synchrony</span>, communication networks), and other complexity measures (number of rounds).
						</p>
                    </section>
					<section id="sec2">
						<h2>2. Definitions and Results</h2>
						<p class="rp_original">
							For this abstract, we define the model and state the results on an intuitive level. Since even the formal definition of the notions of privacy and resiliency are nontrivial, we give them explicitly in <a href="#appendix">an appendix</a>.
						</p>
						<p class="rp_original">
							The model of computation is a complete <span class="load-definable">synchronous network</span> of \(n\) processors. The pairwise communication channels between players are <span class="load-definable" data-define="secure network">secure</span>, i.e. they cannot be read or tampered with by other players. In one round of computation each of the players can do an arbitrary amount of local computation, send a message to each of the players, and read all messages that were sent to it at this round.
						</p>
						<p class="rp_original">
							We shall be interested in the computational power of this model when imposing privacy and fault tolerance requirements. For simplicity, we restrict ourselves to the computation of (probabilistic) functions \(f\) from \(n\) inputs to \(n\) outputs. We assume that player \(i\) holds the \(i\)th input at the start of computation, and should obtain the \(i\)th output at the end, but nothing else.
						</p>
						<p class="rp_original">
							A protocol for computing a function is a specification of \(n\) programs, one for each of the players. We distinguish two kinds of faults: "Gossip" and "Byzantine". In the first, fault processors send messages according to their predetermined program, but try to learn as much as they can by sharing the information they received. In the second, they can use totally different programs, collaborating to acquire more information or even sabotage the computation.
						</p>
						<p class="rp_original">
							A protocol is <span class="load-definable" data-define="t-private">\(t\)-<i>private</i></span> if any set of at most \(t\) players cannot compute after the protocol more than they could jointly compute solely from their set of privacy inputs and outputs.
						</p>
						<p class="rp_original">
							A protocol is <span class="load-definable" data-define="t-resilient">\(t\)-<i>resilient</i></span> if no set of \(t\) or fewer players can influence the correctness of the outputs of the remaining players. For this to make sense, the function definition should be extended to specify what it is if some players neglect to give their inputs or are caught cheating (see <a href="#appendix">appendix</a>).
						</p>
						<p class="rp_original">
							We can now state the main results of this paper.
						</p>
						<span class="rp_theorem_header">Theorem 1:</span>
						<p class="rp_original rp_theorem">
							For every (probabilistic) function \(f\) and \(t\lt\frac n 2\) there exists a <span class="load-definable" data-define="t-private">\(t\)-private</span> protocol.
						</p>
						<span class="rp_theorem_header">Theorem 2:</span>
						<p class="rp_original rp_theorem">
							There are functions for which there are no \(\frac n 2\)-<span class="load-definable" data-define="t-private">private</span> protocols.
						</p>
						<span class="rp_theorem_header">Theorem 3:</span>
						<p class="rp_original rp_theorem">
							For every probabilistic function and every \(t\lt\frac n 3\) there exists a protocol that is both <span class="load-definable" data-define="t-resilient">\(t\)-resilient</span> and <span class="load-definable" data-define="t-private">\(t\)-private</span>.
						</p>
						<span class="rp_theorem_header">Theorem 4:</span>
						<p class="rp_original rp_theorem">
							There are functions for which there is no \(\frac n 3\)-<span class="load-definable" data-define="t-resilient">resilient</span> protocol.
						</p>
					</section>
					<section id="sec3">
						<h2>3. Proof of Theorem 1</h2>
						<p class="rp_original">
							Let \(P_0,\dots,P_{n-1}\) be a set of players, and let \(n\geq 2t+1\). Let \(F\) be the function which this set of players wants to compute <span class="load-definable" data-define="t-private">\(t\)-privately</span>, where each player holds some input variables to the function \(F\). Let \(E\) be some fixed finite field, with \(|E|\gt n\). Without loss of generality we may assume that all inputs are elements from \(E\) and that \(F\) is some polynomial (in the input variables) over \(E\), and that we are given some arithmetic circuit computing \(|F|\), using the operations \(+,\times\), and constants from \(E\).
						</p>
						<p class="rp_original">
							To simplify our explanation, we divide the computation into three stages.
						</p>
						<span class="rp_sub_header">Stage I</span>
						<p class="rp_original rp_sub">
							The input stage, where each player will enter his or her input variables to the computation using a secret sharing procedure.
						</p>
						<span class="rp_sub_header">Stage II</span>
						<p class="rp_original rp_sub">
							The computation stage, where the players will simulate the circuit computing \(F\), gate by gate, keeping the value of each computed gate as a secret shared by all players.
						</p>
						<span class="rp_sub_header">Stage III</span>
						<p class="rp_original rp_sub">
							The final stage, where the secret shares of the final values of \(F\) are revealed to one or all of the players.
						</p>
						<p class="rp_original">
							Stages I and III are very simple and we describe them below, and delay the details of the computation stage to the next section.
						</p>
						<section id="sec3.1">
							<h3>3.1. The Input Stage</h3>
							<p class="rp_original">
								Let \(a_0,\dots,a_{n-1}\) be some \(n\) distinct non-zero points in our field \(E\). (This is why we need \(|E|\gt n\).) Each player holding some input \(s\in E\), introduces the input to the computation by selecting \(t\) random elements \(a_i\in E\), for \(i=1,\dots,t\), setting $$f(x)=s+a_1x+\cdots+a_tx^t$$ and sending to each player \(P_i\) the value \(s_i=f(a_i)\).
							</p>
							<p class="rp_original">
								As in Shamir's<sup class="reference" data-citation="Sh"></sup> secret sharing scheme, the sequence \((s_0,\dots,s_{n-1})\) is a sequence of \(t\)-wise independent random variables uniformly distributed over \(E\), thus the value of the input is completely independent from the shares \(\{s_i\}\) that are given to any set of \(t\) players that does not include the player holding the secret.
							</p>
							<p class="rp_annotation">
								We proved the above (and otherwise discuss it further) in <a href="34.html#sec3">Chaum, Damg&aring;rd, and Cr&eacute;peau's paper</a> of the same year.
							</p>
						</section>
						<section id="sec3.2">
							<h3>3.2. The Final Stage</h3>
							<p class="rp_original">
								To keep the <span class="load-definable" data-define="t-private">\(t\)-privacy</span> condition, we will make sure that the set of messages received by any set of \(t\) players will be completely independent from all the inputs. During the whole computation each gate which evaluates to some \(s\in E\), will be "evaluated" by the players by sharing the secret value of \(s\) using a random polynomial \(f(x)\) of degree \(t\), completely independent from all the inputs, with the only restriction that \(f(0)=s\). In particular at the end of the computation we will have the value of \(F\) shared among the players in a similar manner. If we want to let just one player know the output value, all the players send their shares to that particular player. This player can compute the <span class="load-definable">interpolation</span> polynomial \(f(x)\) and use its free coefficient as the result.
							</p>
							<p class="rp_original">
								Note that there is a one-to-one correspondence between the set of all shares and the coefficients of the polynomial \(f(x)\). Since all the coefficients of \(f(x)\), except for its free coefficient, are uniform random variables that are independent of the inputs, the set of all shares does not contain any information about the inputs that does not follow from the value of \(f(x)\).
							</p>
						</section>
					</section>
					<section id="sec4">
						<h2>4. The Computation Stage</h2>
						<p class="rp_original">
							Let \(a,b\in E\) be two secrets that are shared using the polynomials \(f(x),\,g(x)\) respectively, and let \(c\in E,\;c\neq0\) be some constant. It is enough to show how one can "compute" \(c\cdot a,\,a+b\), and \(a\cdot b\).
						</p>
						<p class="rp_original">
							The two linear operations are simple and for their evaluation we do not need any communication between the players. This is because if \(f(x)\) and \(g(x)\) encode \(a\) and \(b\), then the polynomials \(h(x)=c\cdot f(x)\) and \(k(x)=f(x)+g(x)\) encode \(c\cdot a,\,a+b\) respectively. Thus to compute for example \(a+b\), each player \(P_i\) holding \(f(a_i)\), and \(g(a_i)\) can compute \(k(a_i)=f(a_i)+g(a_i)\). Likewise, since \(c\) is a known constant, \(P_i\) can compute \(h(a_i)=c\cdot f(a_i)\). Furthermore, \(h(x)\) is random if only \(f(x)\) was, and \(k(x)\) is random if only one of \(f(x)\) or \(g(x)\) was.
						</p>
						<p class="rp_original">
							As a corollary we immediately have
						</p>
						<span class="rp_theorem_header" id="lemma1">Lemma 1: (Linear Functional)</span>
						<p class="rp_original rp_theorem">
							For any \(t,\,(t\leq n-1)\), any linear functional $$F(x_0,\dots,x_{n-1})=a_0x_0+\cdots+a_{n-1}x_{n-1},$$ where each \(P_i\) has input \(x_i\) and the \(a_i\) are known constants, can be computed <span class="load-definable" data-define="t-private">\(t\)-privately</span>. 
						</p>
						<p class="rp_original">
							From the lemma we have
						</p>
						<span class="rp_theorem_header" id="corollary1">Corollary 1: (Matrix Multiplication)</span>
						<p class="rp_original rp_theorem">
							Let \(A\) be a constant \(n\times n\) matrix, and let each \(P_i\) have an input variable \(x_i\). Let \(X=(x_0,\dots,x_{n-1})\) and define \(Y=(y_1,\dots,y_n)\) by $$Y=X\cdot A$$ then for any \(t,\,(t\leq n-1)\), we can <span class="load-definable" data-define="t-private">\(t\)-privately</span> compute the vector \(Y\) such that the only information given to \(P_i\) will be the value of \(Y_i\), for \(i=0,\dots,n-1\).
						</p>
						<span class="rp_sub_header">Proof:</span>
						<p class="rp_original rp_sub">
							Matrix multiplication is just the evaluation of \(n\) linear functionals. By the Lemma, we can compute each linear functional \(Y_i\) independently, and reveal the outcome only to \(P_i\).
						</p>
						<section id="sec4.1">
							<h3>4.1. The Multiplication Step</h3>
							<p class="rp_original">
								The multiplication step is only a bit harder. Let \(a\) and \(b\) be encoded by \(f(x)\) and \(g(x)\) as above. We now assume that \(n\geq 2t+1\). Note that the free coefficient of the polynomial \(h(x)=f(x)g(x)\) is \(a\cdot b\). There are two problems with using \(h(x)\) to encode the product of \(a\) times \(b\). The first, and obvious, one is that the degree of \(h(x)\) is \(2t\) instead of \(t\). While this poses no problem with <span class="load-definable" data-define="interpolation">interpolating</span> \(h(x)\) from its \(n\) pieces since \(n\geq 2t+1\), it is clear that further multiplications will raise the degree, and once the degree passes \(n\) we will not have enough points for the <span class="load-definable">interpolation</span>. The second problem is more subtle. \(h(x)\) is not a <i>random</i> polynomial of degree \(2t\) (ignoring, of course, the free coefficient). For example, \(h(x)\), as a product of two polynomials, cannot be irreducible.
							</p>
							<p class="rp_annotation">
								To be more direct, this is a problem because the final share of the polynomial now no longer (necessarily) has a constant probability distribution, which means that \(2t\) shares may leak information: so if, by some odd coincidence, only one final share would make the polynomial reducible, it must be the final share.
							</p>
							<p class="rp_original">
								To overcome these two problems we will, in one step, randomize the coefficients of \(h(x)\), and reduce its degree while keeping the free coefficient unchanged. We first describe the degree reduction procedure and then combine it with the randomization of the coefficients.
							</p>
						</section>
						<section id="sec4.2">
							<h3>4.2. The degree reduction step</h3>
							<p class="rp_original">
								Let $$h(x)=h_0+h_1x+\cdots+h_{2t}x^{2t}$$ and let $$s_i=h(\alpha_i)=f(\alpha_i)g(\alpha_i),$$ for \(i=0,\dots,n-1\), be the "shares" of \(h(x)\). Each \(P_i\) holds an \(s_i\). Define the truncation of \(h(x)\) to be $$k(x)=h_0+h_1x+\cdots+h_tx^t,$$ and \(r_i=\)<span class="load-equation" data-equation="truncation">\(k(\alpha_i)\)</span>								for \(i=1,\cdots,n-1\).
							</p>
							<span class="rp_sub_header">Claim:</span>
							<p class="rp_original rp_sub">
								Let \(S=(s_0,\dots,s_{n-1})\) and \(R=(r_0,\dots,r_{n-1})\) then there is a constant \(n\times n\) matrix \(A\) such that $$R=S\cdot A.$$
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Let \(H\) be the \(n\)-vector $$H=(h_0,\dots,h_t,\dots,h_{2t},0,\dots,0)$$ and let \(K\) be the \(n\)-vector $$K=(h_0,\dots,h_t,0,\dots,0).$$
							</p>
							<p class="rp_original rp_sub">
								Let \(B=(b_{i,j})\) be the \(n\times n\) (<span class="load-definable" data-define="Vandermonde matrix">Vandermonde</span>) matrix, where \(b_{i,j}=\alpha_j^i\) for \(i,j=0,\dots,n-1\). Furthermore, let \(P\) be the linear projection $$P(x_0,\dots,x_{n-1})=(x_0,\dots,x_t,0,\dots,0).$$
							</p>
							<p class="rp_original rp_sub">
								We have $$H\cdot B=S$$ $$H\cdot P=K$$ and $$K\cdot B=R.$$
							</p>
							<p class="rp_original rp_sub">
								Since \(B\) is not <span class="load-definable" data-define="singular matrix">singular</span> (because the \(\alpha_i\)'s are distinct) we have $$S\cdot(B^{-1}PB)=R$$ but \(A=B^{-1}PB\) is some fixed constant matrix, proving our claim.
							</p>
						</section>
						<section id="sec4.3">
							<h3>4.3. The Randomization Step</h3>
							<p class="rp_original">
								As noted above, the coefficients of the product polynomial are not completely random, and likewise the coefficients of its truncation <span class="load-equation" data-equation="truncation">\(k(x)\)</span> may not be completely random. To randomize the coefficients, each player \(P_i\) randomly selects a polynomial \(q_i(x)\) of degree \(2t\) with a zero free coefficient, and distributes its shares among the player. By a simple generalization of the argument in Shamir's<sup class="reference" data-citation="Sh">[?]</sup> scheme, it is easy to see that knowing \(t\) values on this polynomial gives no information on the vector of coefficients of the monomials of \(x,x^2,\dots,x^t\) of \(q_i(x)\).
							</p>
							<p class="rp_annotation">
								This is also a simple generalization of the argument we make for the information-theoretic security of any \(k\leq x\) shares for any \(x\)-degree polynomial, <a href="34.html#sec3">here</a>.
							</p>
							<p class="rp_original">
								Thus instead of using \(h(x)\) in our reduction we can use $$\widetilde{h}(x)=h(x)+\sum\limits_{j=0}^{n-1}{q_j(x)}$$ which satisfies \(\widetilde{h}(0)=h(0)\) but the other coefficients of \(x^i,1\leq i\leq t\), are completely random. Since each player can evaluate his or her point \(\widetilde s_i = \widetilde h(\alpha_i)\), we can now apply the truncation procedure using the <a href="#corollary1">matrix multiplication lemma</a> to arrive at a completely random polynomial <span class="load-equation" data-equation="truncation">\(\widetilde k(x)\)</span> which satisfies both \(\operatorname{deg}\widetilde k(x)=t\) and \(\widetilde k(0)=a\cdot b\), and \(\widetilde k(x)\) is properly shared among all the players.
							</p>
							<p class="rp_annotation">
								Corrected "\(k(x)\) is shared properly" to "\(\widetilde k(x)\) is shared properly".
							</p>
						</section>
						<p class="rp_original">
							Thus (omitting many well known details, see <span class="reference" data-citation="GMW1">[?]</span>) we have proved
						</p>
						<span class="rp_theorem_header" id="theorem1">Theorem 1:</span>
						<p class="rp_original rp_theorem">
							For every (probabilistic) function \(f\) and \(t\lt\frac n 2\) there exists a <span class="load-definable" data-define="t-private">\(t\)-private</span> protocol.
						</p>
						<span class="rp_sub_header">Remarks:</span>
						<ol class="rp_original rp_sub">
							<li>The complexity of computing \(F\) \(t\)-privately is bounded by a factor polynomial in \(n\) multiplied by the complexity of computing \(F\).</li>
							<li>If \(F\) can be computed by an arithmetic circuit over some field using unbounded fan-in linear operations and bounded fan-in multiplication, in depth \(d\), then \(F\) can be computed \(t\)-privately in \(O(d)\) rounds of exchange of information.</li>
							<li>
								<p>
									In our construction we have to reduce the degree of our polynomial only when its degree is about to pass \(n-1\). Thus if \(t=\operatorname O(n^{1-\epsilon})\), for some fixed \(\epsilon\gt 0\), and we start with polynomials of degree \(t\), the players can simulate many steps of the computation before the degree comes close to \(n\), by doing the computation each on their own shares, without any communication(!). When the degree does get close to \(n\), we reduce the degree back to \(t\) in one randomizing, degree reducing step.
								</p>
								<p>
									Two simple examples are:
								</p>
								<ol type="a">
									<li>Any Boolean function \(F:\,\{0,1\}^n\;\rightarrow\;\{0,1\}\) can be represented as a multilinear polynomial over the field \(F\). Thus if \(t=\operatorname O(n^{1-\epsilon})\) we can compute <span class="load-definable" data-define="t-private">\(t\)-privately</span>, in parallel, all the monomials of \(F\) in \(\operatorname O(1)\) number of rounds and then use a big fan-in addition to evaluate \(F\). This procedure may use exponentially long messages but only constant number of rounds.</li>
									<li>The Boolean Majority function has a polynomial size \(\operatorname O(\log n)\) depth circuit, and thus for \(t\,=\,\operatorname O(n^{1-\epsilon})\), this function can be computed <span class="load-definable" data-define="t-private">\(t\)-privately</span> using only polynomically long messages in constant number of rounds.</li>
								</ol>
							</li>
						</ol>
						<p class="rp_original">
							For completeness we state the following simple result.
						</p>
						<span class="rp_theorem_header" id="theorem2">Theorem 2:</span>
						<p class="rp_original rp_theorem">
							There are functions for which there are no 	\(\frac n 2\)-<span class="load-definable" data-define="t-private">private</span> protocols.
						</p>
						<span class="rp_sub_header">Proof:</span>
						<p class="rp_original rp_sub">
							It is easy to see that two players, each holding one input bit, cannot compute the OR function of their bits without one of them leaking some information. This immediately generalizes to prove the theorem.
						</p>
						<p class="rp_annotation">
							Specifically, this is for the following reason: say that Alice has input 0. Bob must give Alice enough information to output his own bit; this by definition leaks information. This is, of course, not true if Alice has input bit 1&mdash;but without already knowing that Alice has bit 1 (which constitutes a leak), Bob must assume the worst case and give Alice a possibility of a leak.
						</p>
					</section>
					<section id="sec5">
						<h2>5. Sharing a Secret with Cheaters</h2>
						<p class="rp_original">
							Let \(n=3t+1\) and let \(P_0,\dots,P_{n-1}\) be a set of \(n\) players among which we want to share a secret such that:
						</p>
						<ol class="rp_original" type="A">
							<li>Any set of at most \(t\) players does not have any information about the secret and</li>
							<li>It is easy to compute the secret from all its shares even if up to \(t\) pieces are wrong or missing.</li>
						</ol>
						<p class="rp_original">
							The following scheme achieves both requirements:
						</p>
						<p class="rp_original">
							Let \(E\) be a finite field with a primitive \(n\)-th <span class="load-definable">root of unity</span>, \(\omega\in E,\,\omega^n=1\) and for all \(1\leq j\lt n,\,\omega^j\neq 1\). Without loss of generality we can assume that our secret \(s\) is in \(E\).
						</p>
						<p class="rp_annotation">
							While originally the above stated \(1\lt j\lt n\), we can expand this to \(1\leq j\) because, if \(\omega^1=1\), then obviously \(\omega=1\) and therefore the statement would be false for all \(j\).
						</p>
						<p class="rp_annotation">
							We note that the above requirement on \(E\)&mdash;that it have a primitive \(n\)th <span class="load-definable">root of unity</span>&mdash;is non-trivial. A finite field of order \(q\) has a primitive \(n\)th root of unity if and only if \(n\,|\,q-1\).<sup class="footnote" id="fref2" data-footnote="2"><a href="#footnote2">2</a></sup> We must therefore restrict ourselves to finite fields of order \(p^k\) such that \(n\,|\,p^k-1\). Since the statement \(n\,|\,p^k-1\) is equivalent to the statement \(p^k\equiv1\bmod n\), we can solve this congruency using the <span class="load-definable">Fermat-Euler theorem</span>: for any \(p\) coprime to \(n\), \(p^{\operatorname\phi(n)}\equiv1\bmod n\). Since \(p\) must be prime anyway, we come to the conclusion that we must use \(E=GF(p^{\phi(n)})\) for any \(p\in\mathbb P\) such that \(p\not|\;n\).  Notably, if \(n\) is even, \(p\) cannot be 2. For completeness, note that \(p^{\phi(n)}\) is always strictly greater than \(n\) for any valid choice of \(p\).<sup class="footnote" id="fref3" data-footnote="3"><a href="#footnote3">3</a></sup>
						</p>
						<p class="rp_original">
							Pick a random polynomial \(f(x)\in\)<span class="load-equation" data-equation="E[x]">\(E[x]\)</span>, of degree \(t\) such that \(f(0)=s\). That is, set \(\alpha_0=s\) and pick random \(a_i\in E\) for \(i=1\dots t\) and set $$f(x)=a_0+a_1x+\cdots+a_tx^t.$$ Define the share of \(P_i,\,i=0\dots n-1,\) to be \(s_i=f(\omega^i)\). As in <span class="reference" data-citation="Sh">[?]</span>, the \(s_i\)'s are \(t\)-wise independent random variables that are uniformly distributed over \(E\), and thus our first requirement (A) is met.
						</p>
						<p class="rp_original">
							Note that setting \(a_i=0\) for \(i\gt t\) makes our secret shares the <span class="load-definable">Discrete Fourier Transform</span> of the sequence \((a_0,\dots,a_{n-1})\). Let \(\hat f(x)=s_0+s_1x+\cdots+s_{n-1}x^{n-1}\). By the well known formula for the inverse transform $$a_i=\frac 1 n\hat f(\omega^{-i})$$ and in particular \(\hat f(\omega^{-i})=0\) for \(i=t+1,\dots,n-1\). Explicitly the \(s_i\) satisfy the linear equations $$\sum\limits_{i=0}^{n-1}\omega^{r\cdot i}\cdot s_i=0\;\text{for}\;r=1,\dots,2t.$$ Thus the polynomial \(g(x)\,=\,\prod\nolimits_{i=t+1}^{n-1}(x-\omega^{-i})\) divides the polynomial \(\hat f(x)\), which in the language of <span class="load-definable" data-define="error-correcting code">Error Correcting Codes</span> says that the vector \(s=(s_0,\dots,s_{n-1})\) is a codeword in the <span class="load-definable" data-define="cyclic code">Cyclic Code</span> of length \(n\) generated by \(g(x)\). By our choice of \(g(x)\), this <span class="load-definable">cyclic code</span> is the well known Generalized Reed-M&uuml;ller code. Such codes have a simple error correction procedure to correct \(\frac 1 2\operatorname{deg}g(x)=t\) errors. See for example <span class="reference" data-citation="PW">[?]</span>, page 283.
						</p>
						<p class="rp_annotation">
							Intuitively, we can see that \(g(x)\,|\,\hat f(x)\) since they share the same zeroes.
						</p>
						<p class="rp_annotation">
							Reed-M&uuml;ller codes and how to work with them is well outside the scope of this website; for more on working with them, we recommend <a href="http://mathworld.wolfram.com/Reed-MullerError-CorrectingCode.html">MathWorld</a>, an explanatory <a href="http://www-math.mit.edu/phase2/UJM/vol1/COOKE7FF.PDF">research paper</a> published by MIT, or the <a href="http://books.google.com/books?id=5kfwlFeklx0C&pg=PR6&lpg=PR6&dq=W.+W.+Peterson+and+E.+J.+Weldon,+Error+correcting+codes,+Second+Ed.&source=bl&ots=PZzgA2fcQJ&sig=wB6fNlB5CL4Pp45FOEXlH34M9RU&hl=en&sa=X&ei=C8vPU9--CZKqyASFqoKACA&ved=0CCwQ6AEwAg#v=onepage&q=W.%20W.%20Peterson%20and%20E.%20J.%20Weldon%2C%20Error%20correcting%20codes%2C%20Second%20Ed.&f=false">book</a> mentioned in the reference (on Google Books).
						</p>
					</section>
					<section id="sec6">
						<h2>6. Verifying a Secret</h2>
						<p class="rp_original">
							Assume that player \(P\) has distributed a secret in the manner described above. Before entering this shared secret into a computation, we wish to verify that the secret shares we are holding are shares of a real secret and not some \(n\) random numbers. We want to do so without revealing any information about the secret or any of its shares. This is easily done using the following <span class="load-definable" data-define="zero knowledge proof">Zero Knowledge proof</span> technique. We will later show how to verify a secret using a different technique that has absolutely no probability of error. We present this <span class="load-definable" data-define="zero knowledge proof">Zero Knowledge</span> technique because it is simpler, and uses fewer rounds of communication.
						</p>
						<section id="sec6.1">
							<h3>6.1. Simple Verification of a Secret</h3>
							<p class="rp_original">
								Let \(f_0\) be the original polynomial. Let \(f_1,\dots,f_m,\,m=3n\) be random polynomials of degree \(t\) generated by \(P\), and have \(P\) send to \(P_i\) the values \(f_j(\)<span class="load-equation" data-equation="omega">\(\omega^i)\)</span> for \(j=1,\dots,m\). Each \(P_i\) selects a random \(\alpha_i\neq 0\) from \(E\) and sends it to all the other players. After reaching agreement on the set of \(\alpha\)'s, the dealer broadcasts the set of polynomials \(f^\alpha=\sum\nolimits_{k=0}^m\alpha^kf_k\) to all players. Each player \(P_i\) checks that, at the point <span class="load-equation" data-equation="omega">\(\omega^i)\)</span>, the shares received satisfy the required equations for all the \(\alpha\)'s. If some \(P_i\) finds an error he or she broadcasts a complaint. If \(t+1\) or more players file a complaint, we decide that the dealer is faulty and take some default value, say 0, to be the dealer's secret (and pick 0 for all the needed shares).
							</p>
							<span class="rp_sub_header">Claim:</span>
							<p class="rp_original rp_sub">
								Let \(T\) be a set of good players that did not complain. Let \(f_i^T\) be the <span class="load-definable">interpolation</span> polynomial through the points in \(T\) of the original polynomial \(f_i\). Then, with probability at least $$1-\frac{m2^n}{|E|},$$ all the polynomials \(f_i^T\) are of degree \(t\).
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Omitted
							</p>
							<p class="rp_original">
								Keeping in mind the (polynomial) complexity of the players' computation, we can certainly allow \(|E|\geq 2^{2n}\). This makes the error probability exponentially small. (The case of small \(|E|\) is similar: Using a somewhat large \(m\), each player, using a different set of random polynomials, asks the dealer to reveal either \(f_i\) or \(f_0+f_i\).)
							</p>
							<p class="rp_original">
								Note that if \(n\geq5t+1\), then our secret sharing scheme can correct \(2t\) errors. If a secret is accepted, then at most \(t\) good players may have wrong values. This together with at most \(t\) more wrong values that may come from the bad players, gives altogether at most \(2t\) errors. Thus in this case the secret is uniquely defined and there is a simple procedure to recover its value using the error correcting procedure.
							</p>
							<p class="rp_original">
								To handle the case of \(n=3t+1\) we must make sure that all the pieces in the hands of the good players lie on a polynomial of degree \(t\). To achieve this we ask the dealer of the secret to make public all the values that were sent to each player who filed a complaint. We now repeat the test, using new random \(\alpha\)'s. Each player now checks at his or her own point and at all the points that were made public, and if there is an error he or she files a complaint. If by now more than \(t+1\) players have complained we all decide that the secret is bad and take the default zero polynomial. Otherwise,
							</p>
							<span class="rp_sub_header">Claim:</span>
							<p class="rp_original rp_sub">
								With very high probability, all good players are on a polynomial of degree \(t\).
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Omitted.
							</p>
							<p class="rp_original">
								Note that if the dealer is correct, then no good player's value will become public during the verification process. This, together with the fact that all the polynomials that the dealer reveals during this verification procedure are completely independent from the secret polynomial \(f_0\), ensures that the bad players will not gain any information about the dealer's secret. (Detailed proof omitted).
							</p>
						</section>
						<section id="sec6.2">
							<h3>6.2. Absolute Verification of a Secret</h3>
							<p class="rp_original">
								The verification procedure described above leaves an exponentially small probability of error. In this section we describe a secret verification procedure that leaves no probability of error.<sup class="footnote" id="fref1" data-footnote="1"><a href="#footnote1">1</a></sup>
							</p>
							<p class="rp_original">
								Instead of just sending the shares \(\{s_i\}\), the dealer of the secret selects \(n\) random polynomials \(f_0(x),\dots,f_{n-1}(x)\), with
							</p>
							<ol class="rp_original">
								<li>\(s_i=f_i(0)\) for \(i=0,\dots,n-1\), and</li>
								<li>\(\sum\nolimits_{i=0}^{n-1}\)<span class="load-equation" data-equation="omega">\(\omega^{r\cdot i}\)</span>\(f_i(x) = 0\) for \(r=1,\dots,2t\)</li>
							</ol>
							<p class="rp_original">
								In other words, the dealer selects a random polynomial \(f(x,y)\), of degree \(t\) in both variables \(x\) and \(y\), with the only restriction that \(f(0,0)=s\) (the secret to share). The dealer then sends the polynomials \(f_i(x)=f(x,\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\()\) and \(g_i(y)=f(\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\(,y)\) to player \(P_i\), for \(i=0,\dots,n-1\). The real share is just \(s_i=f_i(0)\), but for the purpose of its verification, the dealer also sends the polynomials \(f_i(x)\) and \(g_i(y)\). At this point, each player \(P_i\) sends \(s_{i,j}=f_i(\)<span class="load-equation" data-equation="omega">\(\omega^j\)</span>\()=f(\)<span class="load-equation" data-equation="omega">\(\omega^j,\omega^i\)</span>\()=g_j(\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\()\) to each player \(P_j\).
							</p>
							<p class="rp_original">
								Note that if the dealer is correct, then when a good player \(P_j\) is looking at the sequence \(SS_j=(s_{0,j},s_{i,j},\dots,s_{n-1,j})\), then all these points should be on \(P_j\)'s known polynomial \(g_j(y)\). Therefore \(P_j\) can compare the incoming values with that polynomial and find out which values are wrong. Furthermore it is clear that in this case no good player will have to correct any value coming from other good players.
							</p>
							<p class="rp_original">
								On the other hand we have
							</p>
							<span class="rp_theorem_header">Lemma:</span>
							<p class="rp_original rp_theorem">
								If no correct player has to correct a value given by a correct player, then there is a polynomial of degree \(t\) that passes through the interpolation points of all the correct players.
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Simple algebra. Omitted.
							</p>
							<p class="rp_original">
								To make sure that the condition of this lemma is satisfied, each player \(P_j\) broadcasts a request to make public the coordinates \((i,j)\) that were incorrect. If \(P_j\) detects more than \(t\) wrong incoming values, or had to correct his or her own value, the dealer is clearly faulty. In such a case \(P_j\) broadcasts a request to make both \(f_j(x)\) and \(g_j(y)\) public. At this point the dealer broadcasts the (supposedly true) values \(s_{i,j}\) at all these points, and the polynomials that were to be made public. Note that making \(f_j\) and \(g_j\) public makes all the \(s_{k,j}\) and \(s_{j,k}\) public for \(0\leq k\lt n\), for that particular \(j\).
							</p>
							<p class="rp_original">
								Now if some \(P_i\) observes that some new public \(s_{i,j}\) contradicts the polynomials in that player's possession, or finds out that the public information already contradicts itself, he or she broadcasts a request to make all of his or her information public. Here once more, the dealer makes public all the requested information. Finally, each \(P_i\) checks all the public and private information received from the dealer. If any \(P_i\) finds an inconsistencies, the player broadcasts a complaint by asking all his  or her private information to be made public.
							</p>
							<p class="rp_original">
								If all this point \(t+1\) or more players have asked to make their information public, the dealer is clearly faulty and all the players pick the default zero polynomial as the dealer's polynomial. Likewise, if the dealer did not answer all the broadcasted requests, the dealer is declared faulty. On the other hand, if \(t\) or fewer players have complained, then there are at least \(t+1\) good players who are satisfied. These uniquely define the polynomial \(f(x,y)\) and they conform with all the information that was made public. In this case, the complaining players take the public information as their share.
							</p>
							<p class="rp_original">
								Note that if the dealer has distributed a correct secret then no piece of information of any good player was revealed during the verification process. If however the dealer was bad, we do not have to protect the privacy of the secret, and the verification procedure ensures us that all the good players values lie on some polynomial of degree \(t\).
							</p>
						</section>
					</section>
					<section id="sec7">
						<h2>7. Some More Tools</h2>
						<p class="rp_original">
							Before going into the computation stage, we need two more tools.
						</p>
						<ol class="rp_original" type="I">
							<li>Generating (and verifying) a random polynomial of degree \(2t\), with a zero free coefficient.</li>
							<li>Allowing a dealer to distribute three secrets, \(a,\,b\), and \(c\), and verifying that \(c=a\cdot b\).</li>
						</ol>
						<p class="rp_original">
							Both of these are not needed when \(n\geq4t+1\), but are required to handle the \(n=3t+1\) case.
						</p>
						<section id="sec7.1">
							<h3>7.1. Generating Polynomials of Degree \(2t\)</h3>
							<p class="rp_original">
								Let each player \(P_i\) distribute \(t\) random (including the free coefficient) polynomials \(g_{i,k}(x),\,k=1,\dots,t\), of degree \(t\). Define \(f_i(x)\) by $$f_i(x) = \sum\limits_{k=1}^t{x^k\cdot g_{i,k}}$$ and let the players evaluate from their points on the \(g_{i,k}\)'s their corresponding point on \(f_i(x)\).
							</p>
							<p class="rp_original">
								After we have verified that indeed \(\operatorname{deg}g_{i,k}\leq t\), it is clear that \(\operatorname{deg}f_i(x)\leq 2t\), and \(f_i(0)=0\). (It is also clear that the vector of coefficients of the monomials of \(x^i,\,i=1,\dots,t\), in \(f_i(x)\) are uniformly distributed and are completely independent from the information held by any set of at most \(t\) players that does not include \(P_i\).)
							</p>
							<p class="rp_original">
								Finally, as our random polynomial we take $$f(x)=\sum\limits_{i=0}^{n-1}{f_i(x)}.$$
							</p>
						</section>
						<section id="sec7.2">
							<h3>7.2. Verifying that \(c=a\cdot b\)</h3>
							<p class="rp_original">
								Let the player \(P\) distribute \(a\) and \(b\) using the polynomials \(A(x)\) and \(B(x)\) respectively. We want \(P\) to also distribute a random polynomial encoding \(c=a\cdot b\), in such a way that the players can all verify that indeed \(c=a\cdot b\). Let $$D(x)=A(x)\cdot B(x)=c+c_1x+\dots+c_{2t}x^{2t}$$ and let $$\begin{align}D_t(x)&=r_{t,0}+r_{t,1}x+\dots+r_{t,t-1}x^{t-1}+c_{2t}x^t\\D_{t-1}(x)&=r_{t-1,0}+\dots+r_{t-1,t-1}x^{t-1}+[c_{2t-1}-r_{t,t-1}]x^t\\\vdots\quad&\quad\vdots\\D_1(x)&=r_{1,0}+\dots+r_{1,t-1}x^{t-1}+[c_t-r_{t,1}-r_{t-1,2}-\dots-r_{2,t-1}]x^t\end{align}$$ where the \(r_{i,j}\) are random elements from \(E.\;P\) selects the \(D_i(x)\) and distributes their shares to all the players. After verifying that \(A(x),\,B(x)\) and all the \(D_i(x)\) are of degree \(t\), define $$C(x)=D(x)-\sum\limits_{i=1}^tx^i\cdot D_i(x).$$ and verify that \(C(x)\) is also of degree \(t\). From the construction of \(C(x)\) it is clear that \(C(x)\) is a random polynomial of degree \(t\) with the only restriction that \(C(0)=a\cdot b\).
							</p>
						</section>
					</section>
					<section id="sec8">
						<h2>8. Proof of Theorem 3</h2>
						<p class="rp_original">
							We separate again the computation to its Input, Computation, and Final stages. At the input stage, we let all players enter their inputs to the computation using our secret sharing scheme, while verifying that each secret shared is indeed some polynomial of degree \(t\). The secret verification assures that the inputs of any Byzantine player is well defined, but does not ensure that it is in the domain of our function. For example, in a 0-1 vote, we must verify that the input is 0 or 1. We defer this type of verification to the computation stage.
						</p>
						<p class="rp_original">
							The final stage is exactly the same <a href="#sec3.2">as in the proof of Theorem 1</a>. When we have simulated the circuit, and the players are holding the pieces of a properly shared secret encoding the final output, they send all the pieces to one or all the players. As at most \(t\) pieces are wrong, each player can use the error correcting procedure and recover the result.
						</p>
						<section id="sec8.1">
							<h2>8.1. The Computation Stage - Byzantine Case</h2>
							<p class="rp_original">
								Let \(a\) and \(b\) be properly encoded by \(f(x)\) and \(g(x)\) respectively, where by "properly encoded" we mean that all the pieces of the good players are on some polynomial of degree \(t\). Since \(f(x)\) and \(g(x)\) are properly encoded, the polynomials \(f(x)+g(x)\) and \(c\cdot f(x)\) properly encode \(a+b\) and \(c\cdot a\) for any constant \(c\in E\). The same argument of <a href="#theorem1">Theorem 1</a> implies that we can do the computation of any linear operation with no communication at all.
							</p>
							<p class="rp_original">
								Here again, the multiplication step is more involved. To repeat the procedure of theorem 1 using the degree reduction step, via the <a href="#corollary1">Matrix Multiplication Lemma</a>, we must make sure that all the players use, as input to this procedure, their correct point on the product polynomial \(h(x)=f(x)g(x)\). To guarantee that this indeed happens, we use the <span class="load-definable" data-define="error-correcting code">Error Correcting Codes</span> again.
							</p>
							<p class="rp_original">
								Let \(a_i=f(\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\(),\,b_i=g(\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\()\) and \(c_i=h(\)<span class="load-equation" data-equation="omega">\(\omega^i\)</span>\()=a_i\cdot b_i\) be the points of \(P_i\) on these polynomials. We ask each \(P_i\) to pick a random polynomial of degree \(t,\,A_i(x)\), such that \(a_i=A_i(0)\), and use this polynomial to distribute \(a_i\) as a secret to all the players. Similarly, \(P_i\) distributes \(b_i\) using \(B_i(x)\). We also ask \(P_i\) to distribute \(c_i\) using the polynomial \(C_i(x)\), while verifying that \(A_i(x),\,B_i(x),\,C_i(x)\) are all of degree \(t\), and that \(C_i(0)=A_i(0)B_i(0)\).
							</p>
							<p class="rp_original">
								We want to verify that the free coefficients of the polynomials \(C_i(x)\) are all points on the product polynomial \(h(x)\). It is enough to verify that all the free coefficients of the \(A_i(x)\) and \(B_i(x)\) are on \(f(x)\) and \(g(x)\) respectively. We do this as follows.
							</p>
							<p class="rp_original">
								The free coefficients of the \(A_i(x)\)'s are a code word with at most \(t\) errors. By our assumption, all the \(A_i(x)\) are properly distributed. We can therefore use them to compute any linear functional. In particular, using the same \(A_i(x)\)'s we can compute the polynomials $$S_r(x)=\sum\limits_{i=0}^{n-1}{\omega^{r\cdot i}A_i(x)}$$ for \(r=1,\dots,2t\). At this point, all the players reveal their points on the polynomials \(S_r(x)\), enabling all the players to recover the value of \(s_r=S_r(0)\), for \(r=1,\dots,2t\).
							</p>
							<p class="rp_original">
								Note that if all the \(A_i(0)\) are correct (i.e. on a polynomial of degree \(t\)) then \(s_r=0\) for all \(r\). Thus the computed value of the \(s_r\) are just a function of the errors introduced by the Byzantine players. In particular, this implies that the value of the \(s_r\) does not reveal any information that is held in the hands of the good players!
							</p>
							<p class="rp_original">
								Since at most \(t\) of the \(A_i(0)\) can be wrong, the value of the \(s_r\)'s, the so-called Syndrome Vector, is the only information needed by the error correction procedure to detect which coordinates \(A_i(x)\) encode a wrong \(A_i(0)\), and give the correct value. Therefore if some \(s_r\neq 0\), all the players compute the wrong coordinates, the correct value of \(f\)(<span class="load-equation" data-equation="omega">\(\omega^i\)</span>), and use the constant polynomial with this value, instead of \(A_i(x)\).
							</p>
							<p class="rp_original">
								In a similar way we can check and correct the \(B_i(x)\). We can, therefore, also check (and correct) the \(C_i(x)\), so we are sure that all the inputs to the linear computation we have to do in the degree reduction procedure are correct.
							</p>
							<p class="rp_original">
								Note that much of this is not needed when \(n\geq 4t+1\), because then we can still correct up to \(t\) errors on polynomials of degree \(2t\). In this case we can do the error correction on the points of \(h(x)\) directly.
							</p>
							<p class="rp_original">
								As in the proof of <a href="#theorem 1">Theorem 1</a>, we have,
							</p>
							<span class="rp_theorem_header" id="theorem3">Theorem 3:</span>
							<p class="rp_original rp_theorem">
								For every probabilistic function and every \(t\lt\frac n 3\) there exists a protocol that is both <span class="load-definable" data-define="t-resilient">\(t\)-resilient</span> and <span class="load-definable" data-define="t-private">\(t\)-private</span>.
							</p>
							<p class="rp_original">
								For completeness we state,
							</p>
							<span class="rp_theorem_header" id="theorem4">Theorem 4:</span>
							<p class="rp_original rp_theorem">
								There are functions for which there is no \(\frac n 3\)-<span class="load-definable" data-define="t-resilient">resilient</span> protocol.
							</p>
							<span class="rp_sub_header">Proof:</span>
							<p class="rp_original rp_sub">
								Follows immediately from the lower bound for Byzantine Agreement in this model. We note that even if we allow broadcast as a primitive operation, theorem 4 remains true. This is because we can exhibit functions for three players that cannot be computed <span class="load-definable" data-define="t-resilient">resiliently</span>, when one player is bad. This generalizes immediately to \(\frac n 3\).
							</p>
							<span class="rp_sub_header">Remark:</span>
							<p class="rp_original rp_sub">
								All the remarks following the statement of <a href="#theorem1">theorem 1</a> also apply to theorem 3.
							</p>
						</section>
					</section>
                </div>
            </div>
			<div class="main_toplevel main_section main_color5" id="appendix">
				<div class="main_window main_fullwidth">
					<h1>Appendix</h1>
					<section id="appendixnotation">
						<h3>Formal Notation</h3>
						<p class="rp_original">
							Let \(F\) be a field. Let \(U=F^n\) denote the standard \(n\)-dimensional vector space over \(F\) and \(M_n(F)\) the ring of \(n\times n\) matrices over \(F\).
						</p>
						<p class="rp_original">
							Let \(R\) be a random variable with distribution \(D\) over \(F\). Then \(R^k\,(R^*)\) denotes \(k\) (finitely many) independent draws from \(D\).
						</p>
						<span class="rp_sub_header">Comment:</span>
						<p class="rp_original rp_sub">
							Unless otherwise specified, \(F\) will be finite, and \(D\) the uniform distribution over \(F\).
						</p>
					</section>
					<section id="appendix1.1">
						<h3>The Basic Model</h3>
						<p class="rp_original">
							Fix \(n\gt 0\) and a field \(F\). Intuitively, an \((n,F)\)-<i>network</i> is a complete synchronous network of \(n\) probabilistic machines (players) \(P_0,P_1,\dots,P_{n-1}\). At every round each players can send one message (element of \(F\)) to each other player, receive a message from each other player, and perform arbitrary computation.
						</p>
						<p class="rp_original">
							If we assume for convenience that players send messages to themselves too, a round of communication is neatly described by a matrix \(M\in M_n(F)\), where each \(P_i\) sent the \(i\)-th row of \(M\), and receives the \(i\)-th column of \(M\). (This formalizes the security of private channels).
						</p>
						<p class="rp_original">
							Formally, a \(T\) round \((n,F)\)-<i>network</i> is a set of players \(\{P_0,P_1,\dots,P_{n-1}\}\). Each \(P_i\) is a tuple $$P_i=\left\langle Q_i,q_i^{(0)},R_i,\delta_i\right\rangle,$$ where \(Q_i\) is a set of states, \(q_i^{0}\) the initial state, \(R_i\) is a random variable over \(F\) (distributed like \(R\)) and $$\delta_i:\,[T]\times Q_i\times F^n\times R_i^*\rightarrow Q_i\times F^n$$ is a transition function that, given a round number, state, previous round input, and private coin tosses, computes the next state and this round's output.
						</p>
						<p class="rp_original">
							A <i>protocol</i> is simply \(\delta=\left\langle\delta_0,\delta_1,\dots,\delta_{n-1}\right\rangle\), the transition functions prescribing to each player what to do in each round.
						</p>
						<p class="rp_original">
							A <i>run</i> \(M\) of a protocol \(\delta\) is a sequence \((M_1,M_2,\dots,M_T),\,M_j\in M_n(F)\) of matrices describing the communication in rounds \(j=1,2,\dots,T\). Note that \(M\) is a random variable, depending on \(\{w_i^{(0)}\}\), the initial states, and \(\{R_i^*\},\,(=R^*)\), the random draws from \(D\).
						</p>
						<p class="rp_original">
							A <i>(probabilistic) function</i> is a function \(f\), $$f:\;F^n\times R^m\rightarrow F^n.$$
						</p>
						<p class="rp_original">
							Intuitively, a protocol <i>computes</i> a function \(f\) if, for all \(v\in F^n\), if \(P_i\) is given \(v_i\in F\) before round 1, then after round \(T\) it knows \(u_i\), such that \(u=\left\langle u_0,u_1,\dots,u_{n-1}\right\rangle\) is distributed exactly like \(f(v\times R^m)\). For convenience we denote a vector \(\left\langle a_0,a_1,\dots,a_{n-1}\right\rangle\) by \(\langle a_i\rangle\). Also, \(q_i^{(j)}\) denotes the state of \(P_i\) after round \(j\).
						</p>
						<p class="rp_original">
							To formally define what it means for a protocol to compute a function, we assume fixed input and output functions, \(I_i,O_i:\,Q_i\rightarrow F\) for each player \(P_i\). Now \(\delta\) computes \(f\), if for every choice of \(\left\langle q_i^{(0)}\right\rangle\), we have \(\left\langle O_i\left(q_i^{(T)}\right)\right\rangle=\operatorname f\left(I_i(q_i^{(0)})\times R^m\right)\) (as random variables).
						</p>
					</section>
					<section id="appendix1.2">
						<h3>Some Intuition</h3>
						<p class="rp_original">
							The bad players in our model can completely coordinate their actions. Hence, for a bad set (coalition) \(C\subseteq[n]=\{0,1,2,\dots,n-1\}\), the transition functions \(\delta_i,\,i\in C\) are replaced by arbitrary functions \(\delta_i'\) that compute the next state and messages of \(P_i\) from the joint information of the current state, previously received messages and random choices of all \(\{P_i\},\,i\in C\). We denote any protocol in which a set of \(C\) is bad (in this sense) by \(\delta_C\).
						</p>
						<p class="rp_original">
							We distinguish two types of bad behavior. The benign (gossip) kind, in which bad players send messages according to the original protocol \(\delta\), but try to learn as much as they can from it by joining their forces. The malign (Byzantine) kind puts no restrictions on the bad players, i.e. the \(\delta_i'\) can really be arbitrary.
						</p>
						<p class="rp_original">
							To formalize the benign kind of bad behavior we need the following definition: Two protocols \(\delta\) and \(\delta'\) <i>look alike</i> if their runs have the same distribution, i.e. \(M=M'\) as random variables, for every fixed initial state \(\left\langle q_i^{(0)}\right\rangle\) of all players.
						</p>
						<p class="rp_original">
							A bad coalition \(C\) is called <i>gossip</i> if the protocol \(\delta_C\) looks like \(\delta\), otherwise it is called <i>Byzantine</i>.
						</p>
						<p class="rp_original">
							In the case of gossip, we don't have to worry about the correctness of computing \(f\)&mdash;this follows from the definition "look alike". Here all we shall have to prevent is leakage of information. In case of Byzantine faults, we will have to guarantee also the correctness of the computation. We proceed now to define the important notions of Privacy and Correctness.
						</p>
					</section>
					<section id="appendix1.3">
						<h3>Privacy (preliminary):</h3>
						<p class="rp_original">
							Intuitively, a coalition \(C\) did not learn anything from a protocol for computing \(f\), if whatever it can compute after the protocol (from its final states), it could compute only from its input (initial states) and its components of the function values.
						</p>
						<p class="rp_original">
							Let \(Q_C=\prod\nolimits_{i\in C}Q_i\) and \(A\) be an arbitrary set. Also, if \(u=\left\langle u_0,u_1,\dots,u_{n-1}\right\rangle,\,u_C\) denotes the sub-vector of \(u\) that contains \(u_i,\,i\in C\). Formally a set \(C\) is <i>ignorant</i> in a protocol \(\delta\) (for computing \(f\)), if for every set of initial states \(\left\langle q_i^{(0)}\right\rangle\), every protocol \(\delta_C\) that looks like \(\delta\), and every function \(g':\;Q_C\rightarrow A\) there exists a function \(g:\;Q_C\times F^{|C|}\rightarrow A\) satisfying $$g'\left(q_C^{(T)}\right)=g\left(q_C^{(0)},\,f\left(\left\langle I_i(q_i^{(0)})\right\rangle\right)_C\right)\quad\quad(*)$$
						</p>
						<p class="rp_annotation">
							The above was corrected; originally, a function \(d\) was defined, but never used, while \(g\) was used, but never defined. There was additionally an extra comma after \(f\) which made the function poorly-defined.
						</p>
						<p class="rp_original">
							A protocol \(\delta\) (for computing \(f\)) is <span class="load-definable" data-define="t-private">\(t\)-<i>private</i></span> if every coalition \(C\) with \(|C|\leq t\) is ignorant.
						</p>
					</section>
					<section id="appendix1.4">
						<h3>Correctness:</h3>
						<p class="rp_original">
							This issue is problematic, since some of the bad players can obliterate their initial inputs, and the function value is not well defined (a simple example is Byzantine agreement). To ignore bad inputs for every set \(B\subseteq[n]\), we need a (sub)function of \(f\) that depends on the input coordinates of only \([n]\backslash B\). (A special case is assigned default values to input coordinates in \(B\)).
						</p>
						<p class="rp_original">
							So now by \(f\) we mean a family of functions \(\{f_B:\;F^{n\backslash B}\times R^m\rightarrow F^n\}\;B\subseteq[n]\), with \(f_\varnothing\) being the original function \(f\). Typically, (as in Byzantine agreement) this exponential size family is very succinctly described.
						</p>
						<p class="rp_original">
							So now, a computation is correct if all good players compute a function \(f_B\), where \(B\) is a subset of the bad players.
						</p>
						<p class="rp_original">
							More formally, a coalition \(C\) is <i>harmless</i> if, for every set of initial states \(\left\langle q_i^{(0)}\right\rangle\) and every protocol \(\delta_C\), $$\left\{\left\langle O_i\left(q_i^{(T)}\right)\right\rangle\right\}_{[n]\backslash C}\;=\;f_B\left(\left\{\left\langle I_i\left(q_i^{(0)}\right)\right\rangle\right\}_{[n]\backslash B}\right)_{[n]\backslash C}$$ for some \(B\subseteq C\).
						</p>
						<p class="rp_original">
							A protocol is <span class="load-definable" data-define="t-resilient">\(t\)-<i>resilient</i></span> if every coalition \(C\) with \(|C|\leq t\) is harmless.
						</p>
					</section>
					<section id="appendix1.5">
						<h3>Privacy Revisited:</h3>
						<p class="rp_original">
							For the case of <span class="load-definable" data-define="Byzantine fault">Byzantine faults</span>, the assumption that \(\delta_C\) looks like \(\delta\) is invalid. For any harmless coalition \(C\) we can remove this assumption from the definition of ignorance, and replace \(f\) in \((*)\) above, by \(f_B\), the function that will actually be computed by the good players.
						</p>
						<p class="rp_original">
							Now the notion of a protocol that is both <span class="load-definable" data-define="t-resilient">\(t\)-resilient</span> and <span class="load-definable" data-define="t-private">\(t\)-private</span> is well defined.
						</p>
					</section>
				</div>
            </div>
			<div class="main_toplevel main_section main_color7" id="footnotes">
				<div class="main_fullwidth">
					<h1>Footnotes</h1>
					
					<ol id="footnotelist">
						<li id="footnote1" class="rp_original">
							Our original protocol was simplified by Paul Feldman who independently observed that the verification procedure can be accomplished in a constant number of communication rounds.
						</li>
						<li id="footnote2" class="rp_annotation_footnote">
							Claim: \(GF(q)\) has a primitive \(n\)th <span class="load-definable">root of unity</span> if and only if \(n\,|\,q-1\). To quickly demonstrate this, assume we have a primitive \(n\)th root of unity \(\omega\) for \(GF(q)\) where \(n\not|\;q-1\). Take any generator \(g\) in this field: by definition of a generator, there exists an \(a\) such that \(g^a=\omega\). Since the field is a multiplicative ring, \(g^{q-1}=g^0=1\). But \(g^{an}=1\), and by definition of a primitive root of unity, there is no smaller (non-zero) exponent such that this is true. So \(g^{an}=g^{q-1}\) therefore implies \(an=q-1\), clearly contradicting our assumption that \(n\not|\;q-1\).
						</li>
						<li id="footnote3" class="rp_annotation_footnote">
							Claim: \(p^{\phi(n)}\gt n\) for any \(n\in\mathbb Z^{\gt2},\;p\in\mathbb P,\,p\not|\;n\). This follows simply from the lower bound on \(\operatorname \phi(n)\): for any \(n\geq3,\,\phi(n)\geq\frac{n}{e^\gamma\log{\log n}}+\operatorname O\left(\frac{n}{(\log{\log n})^2}\right)\). The lower bound on \(p\) is clearly 2, so we simply need to prove that \(2^{\operatorname\phi(n)}\gt n\). Since we are minimizing \(\phi(n)\) anyway, for simplicity we can assume the big-oh is 0, leaving us with: <span style="font-size:200%">$$2^{\frac{e^{-\gamma}n}{\log{\log n}}}\geq n.$$</span> The left side clearly dominates the right side (both intuitively and through analysis of their derivatives), and the left is greater than the right starting at \(n=5\), so we are left only to demonstrate that \(p^{\phi(n)}\gt n\) for 3 (\(2^2\gt 3\)) and for 4 (\(3^2\gt 4\)). With the exception of \(n=4\) (where we must use \(p=3\) but without weakening our claim) we have demonstrated that, for the lowest possible \(p,\,p^{\phi(n)}\gt n.\quad\blacksquare\)  
						</li>
					</ol>
				</div>
            </div>
            <div class="main_toplevel main_section main_color8" id="references">
				<div class="main_fullwidth">
					<h1>References</h1>
					<ol id="referencelist">
						<li id="BL">M. Ben-Or and N. Linial, Collective coin flipping, <i>FOCS86</i>.</li>
						<li id="CCD">D. Chaum, C. Cr&eacute;peau, and I. Damg&aring;rd. Multiparty unconditionally secure protocols. These proceedings.</li>
						<li id="DH">W. Diffie and M. E. Helman, New directions in cryptography, <i>IEEE Trans. Inform. Theory</i>, Vol. IT-22, pp.644-654, 1976.</li>
						<li id="DS">D. Dolev and R. Strong. Polynomial algorithms for multiple processor agreement. <i>STOC82</i>.</li>
						<li id="FM">P. Feldman and S. Micali, Optimal algorithms for Byzantine agreement. These proceedings</li>
						
						<li id="GMW1">O. Goldreich, S. Micali, and A. Wigderson. Proofs that yield nothing but the validity of the assertion, and a methodology of cryptographic protocol design. <i>FOCS86</i>, pp. 174-187.</li>
						<li id="GMW2">O. Goldreich, S. Micali, and A. Wigderson. How to play any mental game. <i>STOC87</i>, pp.218-229.</li>
						<li id="GMR">S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity of interactive proof systems. <i>STOC85</i>, pp. 291-304.</li>
						<li id="PSL">M. Pease, R. Shostak, and L. Lamport. Reaching agreement in the presence of faults, <i>JACM</i>. Vol. 27, pp. 228-234. 1980.</li>
						<li id="PW">W. W. Peterson and E. J. Weldon, Error correcting codes, Second Ed., MIT Press. 1972.</li>
						
						<li id="Sh">A. Shamir, How to share a secret. <i>CACM 22</i>, pp. 612-613. 1979.</li>
						<li id="Y1">A. C. Yao, How to generate and exchange secrets. <i>STOC86</i>.</li>
						<li id="Y2">A. C. Yao, On the succession problem for Byzantine Generals, manuscript. 1983.</li>
					</ol>
				</div>
			</div>
            <div class="main_toplevel main_section main_color9">
                <div class="rp_problems">
                    <p><a href="mailto:multipartycomputationorg+17@gmail.com">Problem with this page?</a></p>
                </div>
                <p>Created by Nicolas Schank 2014, Brown University</p>
				<p>All original work is free for any use by anyone whatsoever.</p>
				<p>For more information about liability and licensing Yao's original paper, see <a href="../liability.html">Liability</a>.</p>
            </div>
        </div>
    </body>
</html>
<!--
4. Headings
5. Transcribe paper
7. Annotate paper
	7.0. proofread
	7.1. copy assumptions
	7.2. copy theorems
	7.3. copy definitions
	7.4. mark definitions
	7.5. mark equations
	7.6. link to previous research
8. Write protocol descriptions 
9. Check previous research for places to link
10. Write intro, goals, results
11. Tags
12. Consider implementations
13. Find reference
-->