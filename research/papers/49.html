<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Protocols for Secure Computation - Andrew Yao, 1982</title>
		<link rel="stylesheet" type="text/css" href="../../style/main.css">
		<link rel="stylesheet" type="text/css" href="../../style/equation.css">
		<link rel="stylesheet" type="text/css" href="../../style/ref.css">
		<link rel="stylesheet" type="text/css" href="../../style/glossary.css">
		<link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
		<link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
		<script type="text/javascript" src="../../script/difficulty.js"></script>
		<script type="text/javascript" src="../../script/ref.js"></script>
		<script type="text/javascript" src="../../script/fnote.js"></script>
		<script type="text/javascript" src="../../script/equation.js"></script>
		<script type="text/javascript" src="../../script/glossary.js"></script>
		<script type="text/javascript" src="../../script/def.js"></script>
		<script type="text/javascript" src="../../script/toc.js"></script>
		<script type="text/javascript" src="../../script/authorlist.js"></script>
		<script type="text/javascript" src="../../script/authorload.js"></script>
		<script type="text/javascript"
				src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>
		<script type="text/javascript">
			<!--
				function fill(box)
			{
				switch (box)
				{
					case "1/e":
						return {difficulty: 2, blockName: "oneovere", info: [{type: "p", content: "The main point to draw from this is that \\(\\frac1e\\) is <span class=\"load-definable\">transcendental</span>."}]};
					case "cartesianproduct":
						return {difficulty: 2, blockName: "cartesianproduct", info: [{type: "p", content: "Read: <i>the Cartesian product of V and W.</i>"}, {type: "p", content: "The Cartesian product of two sets is the set of all ordered pairs formed by taking an element from the first set followed by an element from the second set. As an example, a full deck of playing cards can be described as {A,2,3,4...K}\\(\\times\\){♠, ♥, ♦, ♣}"}, {type: "p", content: "A function with domain \\(V\\times W\\) can be rephrased as a function \\(f(v,w\\) where the domain of \\(v\\) is \\(V\\) and the domain of \\(w\\) is \\(W\\)."}]};
					case "Eax":
						return {difficulty: 1, blockName: "Eax", info: [{type: "p", content: "The encryption of the \\(N\\)-bit integer \\(x\\) under Alice's public key."}]};
					case "fx1xm":
						return {difficulty: 1, blockName: "fx1xm", info: [{type: "p", content: "Any function on \\(m\\) integer inputs. All of the inputs must fall into a particular range. The output of the function must be an integer."}]};
					case "NbitZ+":
						return {difficulty: 1, blockName: "NbitZ", info: [{type: "p", content: "All integers between 0 and \\(2^{N}-1\\). For example, if \\(N=3\\), then all numbers from \\(0 = 000_b\\) to \\(7 = 111_b\\)."}]};
					case "pij":
						return {difficulty: 3, blockName: "pij", info: [{type: "p", content: "If Alice calculates the probability distribution on some element \\(x\\) <i>after</i> the protocol, the probability that Bob's input \\(j=x\\) is at most some constant factor of \\(\\epsilon\\) more likely than it would have been had Alice just been given the answer to the protocol and no other information."}]};
					case "quartic":
						return {difficulty: 3, blockName: "quartic", info: [{type: "p", content: "The number of bits exchanged is lower-bounded by the product of the quartic roots of the cardinality of the domain. In this case, the domain of the entire function is being represented by the product of the domains of each individual variable."}]};
					case "search":
						return {difficulty: 2, blockName: "search", info: [{type: "p", content: "\\(2^N-1\\) is the maximum value that an encryption under \\(E_a\\) can take."},{type:"p",content:"We must check every \\(p\\)-th number within that bound in each search, for a total of \\(\\frac{2^N-1}{p}\\) items to search for each \\(z_u\\) value."},{type:"p",content:"We must additionally check each \\(z_u+1\\) value, doubling the search space."}]};
					case "T(A)":
						return {difficulty: 4, blockName: "Ta", info: [{type: "p", content: "The maximum number of bits exchanged in protocol \\(A\\)."}]};
					case "th2":
						return {difficulty: 2, blockName: "th2", info: [{type: "p", content: "Read: <i>the runtime of that algorithm is in big-oh \\(C(f)\\) times the log of the inverse of epsilon times delta</i>."}, {type: "p", content: "Basically, the privacy constraint increases the complexity of the algorithm by at most \\(\\log{\\frac{1}{\\epsilon\\cdot\\delta}}\\). This value grows from 1 (when both variables are 1 and offer no security) to \\(\\infty\\) the closer either or both values get to 0 (complete security). Logarithms grow <u>slowly</u>, so you can get pretty close to zero before this increase in complexity is particularly large."}, {type: "p", content: "You can look at this function <a href=\"http://www.wolframalpha.com/input/?i=z%3Dlog%281%2F%28epsilon+*+delta%29%29+from+epsilon+%3D+0+to+1%3B+delta+%3D+0+to+1\">on WolframAlpha</a>."}]};
					case "yu":
						return {difficulty: 1, blockName: "yu", info: [{type: "p", content: "The decryption of ten values under Alice's private key."}]};
					default:
						return {difficulty: 5, blockName:"default", info: [{type: "p", content: "No info on this equation yet."}]};
				}
			}

			self_def["(e,d)-privacy constraint"] = {title: "(\\(\\epsilon,\\delta\\))-privacy constraint", difficulty: 5, blockName: "49ed", def: [{type: "span", className: "rp_definition_header", href: "#def1", content: "Definition 1"}, {type: "p", content: "A protocol is said to satisfy the \\((\\epsilon,\\delta)\\)-privacy constraint for some fixed \\(\\epsilon,\\delta&gt;0\\) if:"}, {type: "ol", content: [{type: "li", content: [{type: "p", content: "Alice's calculated probability distribution on \\(j\\),<span class=\"load-equation\" data-equation=\"pij\">\\(p_i(j)=\\frac{1}{|G_i|}(1+\\operatorname O(\\epsilon))\\)</span> for \\(j \\in G_i\\), and 0 otherwise, where \\(G_i\\) is the set of \\(j\\) for which \\(f(i,j)=v\\),"}]}, {type: "li", content: [{type: "p", content: "if Alice tries afterwards to perform more calculations with no more than \\(\\operatorname O(N^k)\\) encryptions and decryptions, with probability at least \\(1-\\delta\\) she will still get the above distribution on \\(j\\), and"}]}, {type: "li", content: [{type: "p", content: "the above requirement is also true for Bob."}]}]}]};
			self_def["successful cheating"] = {title: "successful cheating", difficulty: 3, blockName: "49successful", def: [{type: "span", className: "rp_definition_header", content: "Definition 2", href: "#def2"}, {type: "p", content: "An instance of an execution of a protocol in which a party does not behave consistently with any possible input, yet any other party is unable to detect it."}]};
			self_def["robust"] = {title: "robust", def: [{type: "p", difficulty: 3, blockName: "49robust", content: "A robust bit-producing protocol is one in which the bit produced has the correct <span class=\"load-definable\">bias</span> even if someone has cheated."}]};
			//-->
		</script>
	</head>
	<body>
		<div class="main_foreground">
			<div class="main_toplevel main_header">
				<h1>Multiparty Computation</h1>
			</div>
			<div class="main_toplevel main_navigation">
				<a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
				<a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
				<a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
				<a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
				<a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
				<a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
			</div>
			<div class="main_toplevel main_section main_color1">
				<div class="main_section_nav_container">
					<div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
					<div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
					<div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
					<div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
				</div>
				<div class="main_window main_fullwidth">
					<section class="top_section" id="overview" data-section-name="Overview">
						<div class="rp_linkbox"><a href="pdf/49.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
						<span class="rp_title">Protocols for Secure Computations</span>
						<span class="rp_info">1982<span class="rp_author">Andrew C. Yao</span></span>

						<div class="rp_snippet">
							&ldquo;Suppose \(m\) people wish to compute the value of a function <span class="load-equation" data-equation="fx1xm">\(f(x_1, x_2, x_3,&hellip;, x_m)\)</span>, which is an integer-valued function of \(m\) integer variables \(x_i\) of bounded range. Assume initially person \(P_i\) knows the value of \(x_i\) and no other \(x\)'s. Is it possible for them to compute the value of \(f\), by communicating among themselves, without unduly giving away any information about the values of their own variables?&rdquo;
						</div>
						<h1>Overview</h1>

						<div class="main_toc"></div>
						<section id="intro" data-section-name="Introduction">
							<h2>Introduction</h2>
							<p class="rp_analysis">
								<b>Protocols for Secure Computations</b> is a short 1982 research paper by Andrew Yao that is known for defining the Millionaires' Problem, and for being the first paper to pose the problem of multiparty computation. Its results were mostly foundational: only a few very general theorems were offered, all without proof, and the vast majority of the paper is spent describing (the not-then named) multiparty computation as a whole, as opposed to defining any particular problems, perspectives, or contexts.
							</p>
							<p class="rp_analysis">
								The main exception to that indefiniteness is the basic problem and protocol he detailed, now commonly known as the Millionaires' Problem (and Protocol). Perhaps the most common illustration of multiparty computation, its simplicity and brevity make it an excellent case study into secure two-party computation (as can be seen in the <a href="../../learn/ch1.html#sec1">tutorial page</a> that focuses on it). While Yao mentioned other application cases, some of which were frankly even better candidates for such popularity, the Millionaires' Problem nonetheless remains the most common example of multiparty computation to date.
							</p>
							<p class="rp_analysis">
								The significance of this particular paper to this field is difficult to overstate. Despite its shortcomings (namely, its lack of proof and its limited direct application), its focus on defining a general problem as opposed to being limited to a specific one ultimately vaulted it into the realm of influence, and most research into multiparty computation which followed it can be framed within the definitions Yao presented here.
							</p>
						</section>
						<section id="goals" data-section-name="Goals and Results">
							<h2>Goals and Results</h2>
							<p class="rp_analysis">
								Yao's main goal was to lay the groundwork for later research by outlining the framework of a few different basic types of problems, as well as citing a few basic applications. He defined the problem of multiparty computation in terms of:
							</p>
							<ul class="rp_analysis">
								<li><b>The limitations of privacy and security constraints.</b> Yao cited two extreme examples to display the difference. On the extreme privacy side, he gave the Millionaires' Problem as an example, in which it is assumed that no saboteurs are on the line, but in which both parties want the other to learn nothing about their own input. On the extreme security side, he cited any basic encryption/decryption scheme in which a message needs to be sent over an insecure line from one party to the other. Multiparty computation protocols can be private, secure, or both, and all in varying degrees.</li>
								<li><b>Deterministic vs. probabilistic computation.</b> Yao mentions that both are possible, though the latter is rather obviously more difficult to prove secure, especially if the probability density of the inputs is not constant.</li>
								<li><b>Number of parties.</b> Yao assumes the two-party case for the majority of the paper, but expands the ideas to any \(m\) parties near his conclusions. The \(m\) party case is generally more difficult to deal with due to <span class="load-definable" data-define="collusion">collusions</span> that are impossible in the two-party case; however, Yao states that it is possible to create a protocol for any \(m\) parties with any function.</li>
								<li><b>Trust, cheating, and collusion.</b> Parties may not trust that the other parties are following the protocol correctly, and that must be built into some protocols in order to ensure that the results are still viable. Cheating (as opposed to sabotage, below) may affect correctness, privacy, or both. Collusion is a particular subset of cheating under which multiple cheaters work together. Yao states that any computable function \(f\) can be turned into a protocol with an upper-bounded probability of successful cheating.</li>
								<li><b>Sabotage and eavesdropping.</b> Parties may not be able to communicate without interference or eavesdropping by outside parties, affecting correctness, security, or both. Yao mentions these as issues to be discussed elsewhere, and in general sabotage and eavesdropping are both dealt with by using cryptographic primitives rather than as a part of the protocol.</li>
							</ul>
							<p class="rp_analysis">
								Yao specifically mentions, as an aside, that his theorems prove that <span class="load-definable">mental poker</span> can be played with any public-key system, a generalization of previous research.
							</p>
						</section>
						<section id="assumptions" data-section-name="Assumptions">
							<h2>Assumptions</h2>
							<p class="rp_analysis">
								Some of Yao's results are dependent on the existence of <span class="load-definable" data-define="one-way function">one-way functions</span>. His Millionaires' Problem protocol, for one. Since this extended abstract only briefly explains most of his theorems, we must assume that Theorems 1-5 and 9 depend on the existence of such functions. Theorem 6 determines a lower bound, and 7 and 8 are impossibility results, so we can safely assume that they do not.
							</p>
						</section>
						<section id="defs" data-section-name="Definitions">
							<h2>Definitions</h2>
							<a href="#def1"><span class="rp_definition_header">Definition 1 - \((\epsilon,\delta)\)-Privacy Constraint</span></a>
							<p class="rp_original rp_definition">
								Let \(\epsilon,\delta > 0\), and \(f(i,j)\) be a \(0-1\) valued function. Assume that initially all pairs of \((i,j)\) values are equally likely. Suppose Bob and Alice carry out the computation faithfully according to the protocol. At the end, Alice can in principle, from her computed value \(v\) of the function and the strings in her possession, compute a probability distribution of the values of \(j\); call this \(p_i(j)\). A protocol is said to satisfy the \((\epsilon,\delta)\)-privacy constraint if the following conditions are satisfied:
							</p>
							<ol class="rp_original rp_definition">
								<li><span class="load-equation" data-equation="pij">\(p_i(j)=\frac{1}{|G_i|}(1+\operatorname O(\epsilon))\)</span> for \(j \in G_i\), and \(0\) otherwise, where \(G_i\) is the set of \(j\) for which \(f(i,j)=v\),</li>
								<li>if Alice tries afterwards to perform more calculations with no more than \(O(N^k)\) evaluations of \(E\)'s and \(D\)'s, then with probability at least \(1-\delta\) she will still get the above distribution on \(j\), and</li>
								<li>the above requirement is also true for Bob. 	</li>
							</ol>
							<a href="#def2"><span class="rp_definition_header">Definition 2 - Successful Cheating</span></a>
							<p class="rp_definition">
								Consider an instance in the execution of a protocol. We will consider it to be a successful cheating by Alice, if Alice does not behave consistently with any value of \(i\) and yet Bob does not detect it. A successful cheating by Bob is defined similarly.
							</p>
						</section>
						<section id="theorems" data-section-name="Theorems">
							<h2>Theorems</h2>
							<p class="rp_original">
								Let \(A\) be a protocol, let <span class="load-equation" data-equation="T(A)">\(T(A)\)</span> denote the maximum number of bits exchanged between Alice and Bob when \(A\) is used.
							</p>
							<a href="#theorem1"><span class="rp_theorem_header">Theorem 1</span></a>
							<p class="rp_original rp_theorem">
								For any \(\epsilon,\delta > 0\) and any function \(f\), there exists a protocol for computing \(f\) that satisfies the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span>.
							</p>
							<a href="#theorem2"><span class="rp_theorem_header">Theorem 2</span></a>
							<p class="rp_original rp_theorem">
								Let \(1 > \epsilon,\delta > 0\) and \(f(i,j)\) be a \(0-1\) function. If \(f\) can be computed by a boolean circuit of size \(C(f)\), then there is a protocol \(A\) computing \(f\) satisfying the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span> such that <span class="load-equation" data-equation="T(A)">\(T(A)\)</span><span class="load-equation" data-equation="th2">\(\in\operatorname O(C(f)\log{\frac{1}{\epsilon\cdot\delta}})\)</span>.
							</p>
							<a href="#theorem3"><span class="rp_theorem_header">Theorem 3</span></a>
							<p class="rp_original rp_theorem">
								Let \(\frac{1}{5} > \epsilon,\delta > 0\) be fixed. Let \(F_n\) be the family of 0-1 valued function \(f(i,j)\) with \(i\) and \(j\) being \(n\)-bit integers. Let \(f\) be a random element of \(F_n\), then any protocol \(A\) that computes \(f\) with <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span> must have <span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(\gt2^\frac{n}{2}\) for all large \(n\).
							</p>
							<a href="#theorem4"><span class="rp_theorem_header">Theorem 4</span></a>
							<p class="rp_original rp_theorem">
								Let \(1\gt\gamma\gt0\). Under the same assumption of <a href="#theorem2">Theorem 2</a>, there exists a protocol \(A\) for computing \(f\) such that
							</p>
							<ol class="rp_original rp_theorem">
								<li><span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(\in\operatorname O\left(C(f)\log{\frac{1}{\epsilon\cdot\delta\cdot\gamma}}\log{\frac{1}{\gamma}}\right)\), and</li>
								<li>if one participant behaves according to \(A\), the probability of a <span class="load-definable">successful cheating</span> by the other participant is at most \(\gamma\)</li>
							</ol>
							<a href="#theorem5"><span class="rp_theorem_header">Theorem 5</span></a>
							<p class="rp_theorem rp_annotation">
								Let \(K'\) be defined such that the set \(\{P_i\;|\;i \in K'\}\) is the set of people who are attempting to collude with each other in order to cheat.
							</p>
							<p class="rp_original rp_theorem">
								For any \(\epsilon,\delta,\gamma\gt0\), there exists a protocol \(A\) for computing \(f\) which satisfies the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-private constraint</span> and which has the property that, for any \(K' \neq \{1,&hellip;,m\}\), the probability for \(K'\) to have a successful cheating can not be more than \(\gamma\).
							</p>
							<a href="#theorem6"><span class="rp_theorem_header">Theorem 6</span></a>
							<p class="rp_original rp_theorem">
								There exist functions \(f\) for which any protocol \(A\) satisfying the conditions in <a href="#theorem5">Theorem 5</a> must have <span class="load-equation" data-equation="T(A)">\(T(A)\)</span><span class="load-equation" data-equation="quartic">\(\in \operatorname\Omega\left((|X_1|\cdot |X_2|\cdot\cdots\cdot|X_m|)^\frac{1}{4}\right)\)</span>.
							</p>
							<a href="#theorem7"><span class="rp_theorem_header">Theorem 7</span></a>
							<p class="rp_original rp_theorem">
								No protocol \(A\) with finite <span class="load-equation" data-equation="T(A)">\(T(A)\)</span> which generates a bit with a <span class="load-definable">transcendental</span> <span class="load-definable">bias</span> \(\alpha\) can be <span class="load-definable">robust</span>.
							</p>
							<a href="#theorem8"><span class="rp_theorem_header">Theorem 8</span></a>
							<p class="rp_annotation rp_theorem">
								Suppose Alice and Bob wish to exchange a pair of solutions \(x, y\) with \(\operatorname E_a(x) = 1\) and \(\operatorname E_b(y) = 1\).
							</p>
							<p class="rp_original rp_theorem">
								Let \(A\) be any protocol for exchanging [such] secrets. Then either Alice or Bob will be able to doublecross successfully with probability at least &frac12;.
							</p>
							<a href="#theorem9"><span class="rp_theorem_header">Theorem 9</span></a>
							<p class="rp_original rp_theorem">
								Let \(\epsilon\gt0\) be fixed. There is a protocol \(A\) with polynomial (in \(N\)) running time which exchanges secrets \(\operatorname D_b(w)\) and \(\operatorname D_a(u)\), and under which the probability of anyone double-crossing successfully is bounded by \(\epsilon\).
							</p>
						</section>
						<section id="protocols" data-section-name="Protocols">
							<h2>Protocols</h2>
							<h3><a href="#sec3.1">Millionaires' Protocol</a></h3>
							<ul class="rp_analysis">
								<li><b>Number of parties: </b>2</li>
								<li><b>Function(s): </b>Comparisons between \(x_0\) and \(x_1\) (i.e. \(\lt,\gt,\leq,\geq\)). Two honest parties will get the same output.</li>
								<li><b>Privacy constraints: </b><span class="load-definable" data-define="negligible">Negligible probability</span> that \(P_i\) learns more about \(x_{(1-i)}\) than offered by the computed function.</li>
								<li><b>Cheating: </b>One <span class="load-definable">malicious adversary</span> in the protocol can change the outcome of the protocol to a value of their choosing.</li>
								<li><b>Subprotocols: </b>A <span class="load-definable">trapdoor permutation</span> for encryption/decryption. Assumed to run in \(\operatorname O(N)\) time.</li>
								<li><b>Bits exchanged: </b>\(\operatorname O(Nn)\) where \(N\) is the bit-length of \(i\) and \(j\), and \(n\) is their range.</li>
								<li><b>Runtime:</b> \(\operatorname O(Nn)\), where \(n\) is the range of \(i\) and \(j\)</li>
								<li><b>Assumptions:</b> Existence of <span class="load-definable" data-define="trapdoor function">trapdoor functions</span>.</li>
								<li><b>Implementations: </b>We have our own version in Java <a href="../../nextsteps/codeViewer.html#code/src/nschank/crypto/mpc/millionaire_y82/LessThan.java">here</a>.</li>
							</ul>
						</section>
						<section id="further" data-section-name="Further Reading">
							<h2>Further Reading</h2>
							<p class="rp_analysis">
								For more about the Millionaires' Problem, see the related <a href="../../learn/ch1.html#sec1">tutorial section</a>.
							</p>
							<p class="rp_analysis">
								For more about exchanging secrets as in Theorems <a href="#theorem8">8</a> and <a href="#theorem9">9</a>, or for a deep explanation of <a href="#theorem2">Theorem 2</a>, see Yao's follow-up paper <a href="24.html">How to Generate and Exchange Secrets</a>.
							</p>
						</section>
						<section id="ref" data-section-name="Referencing This Paper">
							<h2>Referencing This Paper</h2>
							<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
							<p class="rp_self_reference">
								A.C. Yao. Protocols for Secure Computations (extended abstract). <i>Proceedings of the 23rd Annual IEEE Symposium on the Foundations of Computer Science,</i> pages 160-164. IEEE. 1982.
							</p>
						</section>
					</section>
				</div>
			</div>
			<div class="main_toplevel main_section main_color5">
				<div class="main_window main_fullwidth">
					<section class="top_section" id="annotated_paper" data-section-name="Annotated Paper (extended abstract)">
						<h1>Annotated Paper (extended abstract)</h1>
						<div class="main_toc"></div>
						<section id="sec1" data-section-name="Introduction">
							<h2>1. Introduction</h2>
							<p class="rp_original">
								Two millionaires wish to know who is richer; however, they do not want to find out inadvertently any additional information about each other's wealth. How can they carry out such a conversation?
							</p>

							<p class="rp_original">
								This is a special case of the following general problem. Suppose \(m\) people wish to compute the value of a function <span class="load-equation" data-equation="fx1xm">\(f(x_1, x_2,\dots, x_m)\)</span>, which is an integer-valued function of \(m\) integer variables \(x_i\) of bounded range. Assume initially person \(P_i\) knows the value of \(x_i\) and no other \(x\)'s. Is it possible for them to compute the value of \(f\), by communicating among themselves, without unduly giving away any information about the values of their own variables? The millionaire's problem corresponds to the case when \(m = 2\) and \(f(x_1, x_2) = 1\) if \(x_1\lt x_2\), and 0 otherwise. In this paper, we will give precise formulation of this general problem and describe three ways of solving it by use of <span class="load-definable" data-define="one-way function">one-way functions</span>. These results have applications to secret voting, private querying of database, oblivious negotiation, playing <span class="load-definable">mental poker</span>, etc. We will also discuss the complexity question "How many bits need to be exchanged for the computation", and describe methods to prevent participants from cheating. Finally, we study the question "What cannot be accomplished with one-way functions".
							</p>
							<p class="rp_original">
								Before describing these results, we would like to put this work in perspective by first considering a unified view of secure computation in the next section.
							</p>
						</section>
						<section id="sec2" data-section-name="A Unified View of Secure Computation">
							<h2>2. A Unified View of Secure Computation</h2>
							<p class="rp_original">
								Since <span class="load-definable" data-define="one-way function">one-way functions</span> were first proposed in 1976 <sup class="reference" data-citation="DH">[1]</sup>, they have been used in two kinds of applications. The first kind is concerned with the <span class="load-definable">encryption</span> and transmission of messages to make them unreadable and unalterable for eavesdroppers and saboteurs <sup class="reference" data-citation="DH">[1]</sup><sup class="reference" data-citation="GM">[2]</sup><sup class="reference" data-citation="Ra">[3]</sup><sup class="reference" data-citation="RSA">[4]</sup>. The second kind of applications includes "<span class="load-definable">mental poker</span>"<sup class="reference" data-citation="SRA">[5]</sup>, in which two players deal cards by communicating over a telephone line, and "<span class="load-definable" data-define="coin flip">coin flipping</span>" <sup class="reference" data-citation="Bl">[6]</sup>, in which two mutually suspecting parties are to generate an <span class="load-definable" data-define="bias">unbiased</span> bit. It would be desirable to have a unified framework where all these applications can be related, and where common proof techniques can be developed for proving the security of protocols. More fundamentally, such a framework is essential if we are ever to understand the intrinsic power and limitation of <span class="load-definable" data-define="one-way function">one-way functions</span>. For example, without a precise model it would be hard to answer a question such as "Is it possible for three mutually suspecting parties to interactively generate a bit with <span class="load-definable">bias</span> <span class="load-equation" data-equation="1/e">\(\frac{1}{e}\)</span>?"
							</p>
							<p class="rp_annotation">
								Yao answers this question in <a href="#theorem7">Theorem 7</a>, which states that <span class="load-definable">transcendental</span> <span class="load-definable" data-define="bias">biases</span> are not achievable <span class="load-definable" data-define="robust">robustly</span>.
							</p>
							<p class="rp_original">
								In response to this need, we propose to adopt the following view. Two parties Alice and Bob, in possession of private variables \(i\) and \(j\) respectively, wish to communicate so that Alice can evaluate a function \(f(i, j)\), and Bob a function \(g(i, j)\). There may be some eavesdroppers or saboteurs on the communication line. The purpose of a protocol would be to design an <span class="load-definable">algorithm</span> for Alice and Bob to follow, such that certain <span class="load-definable" data-define="security constraint">security constraints</span> (against saboteur) and <span class="load-definable" data-define="privacy constraint">privacy constraints</span> (Alice may not wish to reveal the exact value of \(i\)) can be satisfied.
							</p>
							<p class="rp_original">
								In one extreme, when the computation component is trivial, e.g. if \(f\) = constant and \(g(i, j) = i\), then we get the first kind of applications mentioned before, in which the basic concern is eavesdropping and sabotage. In the other extreme, when such external threats can be ignored, but the computation of \(f\) and \(g\) is nontrivial, then we get the problem which is to be studied in this paper. (<span class="load-definable" data-define="mental poker">Mental poker</span> and <span class="load-definable" data-define="coin flip">coin flipping</span> represent a <span class="load-definable">stochastic</span> version of this problem which will also be discussed.) Note that, although we have used Alice and Bob in the above description, all discussions can be extended to the case of \(m\) parties communicating.
							</p>
							<p class="rp_annotation">
								The 'unified view of secure computation' as defined in the above two paragraphs is perhaps the most general useful definition that can be applied to the whole of multiparty computation. In the spirit of that unification, and considering this paper is the formative paper for the field, a slightly reworded version of this very definition is the one used in the tutorials and across the site in order to link specific papers and protocols to the more general problem.
							</p>
							<p class="rp_original">
								It would be natural to discuss these two special cases together. However, due to length consideration, we will report here only the results corresponding to the computation-intense case with no outside saboteurs. Results on the other case will be reported elsewhere.
							</p>
							<p class="rp_annotation">
								There is soon to be a <a href="../../learn/ch3.html">tutorial section</a> dealing with adversaries and saboteurs, as it is one of the most varied and well-studied aspects of cryptography.
							</p>
						</section>
						<section id="sec3" data-section-name="Deterministic Computations">
							<h2>3. Deterministic Computations</h2>
							<section id="sec3.1" data-section-name="Solutions to the Millionaires' Problem">
								<h3>3.1. Solutions to the Millionaires' Problem</h3>

								<p class="rp_original">
									In this abstract, we will describe in detail only one of the three solutions we have.
								</p>
								<p class="rp_annotation">
									It should be noted that, to our knowledge, no complete version of this paper was ever released. If Yao ever published his other two solutions, it was likely in a different paper.
								</p>
								<p class="rp_annotation">
									We have an animation of the below protocol as a demonstration in the <a href="../../learn/ch1.html#sec1">tutorial</a> section.
								</p>
								<p class="rp_original">
									For definiteness, suppose Alice has \(i\) millions and Bob has \(j\) millions, where \(1 \leq i,j \leq 10\). We need a protocol for them to decide whether \(i\lt j\), such that this is also the only thing they know in the end (aside from their own values). Let \(M\) be <span class="load-equation" data-equation="NbitZ+">the set of all \(N\)-bit nonnegative integers</span>, and \(Q_N\) be the set of all <span class="load-definable" data-define="permutation">1-1 onto functions</span> from \(M\) to \(M\). Let \(\operatorname E_a\) be the public key of Alice, generated by choosing a random element from \(Q_N\).
								</p>
								<p class="rp_annotation">
									Firstly, it should be noted that in the original paper, Yao put that \(1\lt i,j\lt10\); however, the protocol is not in any way affected by allowing \(i\) or \(j\) to be \(1\) or \(10\), and the additional restriction wastes bits.
								</p>
								<p class="rp_original">
									The protocol proceeds as follows:
								</p>
								<ol class="rp_original">
									<li>Bob picks a random \(N\)-bit integer \(x\) and computes privately the value of <span class="load-equation" data-equation="Eax">\(\operatorname E_a(x)\)</span>; call the result \(k\).</li>
									<li>Bob sends Alice the number \(k−j+1\).</li>
									<li>Alice computes privately the values of <span class="load-equation" data-equation="yu">\(y_u=\operatorname D_a(k−j+u)\)</span> for \(u = 1,2,\dots,10\).</li>
								</ol>
								<p class="rp_annotation">
									Alice now has the original value of \(x\), since \(y_j=\operatorname D_a(k-j+j)=\operatorname D_a(k)=x\). However, since \(\operatorname E_a\) was chosen randomly, she views each \(y\) as being \(x\) with equal probability.
								</p>
								<ol class="rp_original">
									<li value="4">Alice generates a random prime \(p\) of \(N/2\) bits, and computes the values \(z_u = y_u\pmod p\) for all \(u\); <del>if all \(z_u\) differ by at least 2 in the \(\bmod p\) sense, stop; otherwise generates another random prime and repeat the process until all \(z_u\) differ by at least 2; let \(p, z_u\) denote this final set of numbers.</del></li>
								</ol>
								<p class="rp_annotation">
									In this step, Yao originally made a mistake. The restriction that no two \(z_u\) have a difference less than \(2\) allows Bob to learn something about \(i\) in some cases. We will now demonstrate that, for any positive minimum distance, Bob may be able to learn something. Let's say we require some minimal difference of \(\delta\gt0\) between all \(z_u\) in the \(\bmod p\) sense. Since \(\delta\) is the minimum distance, it is valid to select a \(p\) such that \(\exists\;u_1,u_2\) where \(u_1\leq i\lt u_2\) and \(z_{u_1}=z_{u_2}+\delta\). According to the next step of the protocol, Alice will send Bob \(z_{u_1}\) and \(z_{u_2}+1\) (along with a number of other values). From Bob's perspective, there are three possibilities:
								</p>
								<ol class="rp_annotation" type="i">
									<li>Alice sent him \(z_{u_1}\) and \(z_{u_2}\): however, this is not possible, because the difference between the numbers is \(\delta-1\), while violates the rule.</li>
									<li>Alice sent him \(z_{u_1}+1\) and \(z_{u_2}+1\): we reach an identical problem here.</li>
									<li>Alice sent him \(z_{u_1}\) and \(z_{u_2}+1\): this is the only possible option, as (by our assumptions) it did not originally break the rule.</li>
								</ol>
								<p class="rp_annotation">
									Since Alice only adds 1 to a \(z_u\) if \(u\gt i\), Bob can infer that \(u_1\leq i\lt u_2\). This breaks our privacy constraints on the protocol, so our requiring a minimal distance must have been in error. We have shown the minimum difference requirement breaks the protocol, but we must also demonstrate that <i>not</i> having a minimum difference requirement <i>does not</i> do so. We analyze that very question <a href="#def1">below</a>.
								</p>
								<ol class="rp_original">
									<li value="5">Alice sends the prime \(p\) and the following 10 numbers to Bob: \(z_1,z_2,\dots,z_{i}\) followed by \(z_{i+1}+1,\dots,z_{10}+1\); the above numbers should be interpreted in the \(\bmod{p}\) sense.</li>
								</ol>
								<p class="rp_annotation">
									There was an error in the original document that had an extra term (\(z_i+1\)) after \(z_i\), but this clearly is not 10 numbers, and clearly does not fit with the remainder of the protocol.
								</p>
								<p class="rp_annotation">
									This protocol can be simply altered to calculate \(i\leq j\) instead of \(i\lt j\) by changing \(z_i\) to \(z_i+1\) (and accordingly changing \(\geq\) and &lt; in the next step to &gt; and \(\leq\) respectively). The statements \(i\gt j\) and \(i\geq j\) are the negations of \(i\leq j\) and \(i\lt j\), so can obviously be calculated the same way but negating the answer.
								</p>
								<ol class="rp_original">
									<li value="6">Bob looks at the \(j\)th number (not counting \(p\)) sent from Alice, and decides that \(i \geq j\) if it is equal to \(x \bmod{p}\), and \(i \lt j\) otherwise.</li>
								</ol>
								<p class="rp_annotation">
									To reiterate, the \(j\)th number is either \(z_j\pmod{p}=x\pmod{p}\), as discussed above, or \(z_j+1\pmod{p}=x+1\pmod{p}\). It is only the former if she has not added one, which is only true if \(i\geq j\).
								</p>
								<ol class="rp_original">
									<li value="7">Bob tells Alice what the conclusion is</li>
								</ol>
								<p class="rp_annotation">
									We have a working implementation of this protocol in the implementation section. You can find it <a href="../../nextsteps/codeViewer.html#code/src/nschank/crypto/mpc/millionaire_y82/LessThan.java">here</a>.
								</p>
								<p class="rp_original">
									This protocol clearly enables Alice and Bob to decide correctly who is the richer person. To show that it meets the requirement that they cannot get any more information about the wealth of the other party, we need to define a precise model which will be done in <a href="#sec3.2">Section 3.2</a>. Here we will informally argue why the requirement is met.
								</p>
								<p class="rp_original">
									Firstly, Alice will not know anything about Bob's wealth \(j\), except for the constraint on \(j\) implied by the final result that Bob told her, because the only other information coming from Bob is that Bob knows the value of \(\operatorname D_a(s)\) for some \(s\) between \(k-j+1\) to \(k-j+10\). As the function \(\operatorname E_a\) is random all the 10 possibilities are equally likely.
								</p>
								<p class="rp_original">
									What does Bob know? He knows \(y_j\) (which is \(x\)) and hence \(z_j\). However, he has no information about the values of other \(z_u\), and by looking at the numbers Alice sent him, he cannot tell if they are \(z_u\) or \(z_u+1\).
								</p>
								<p class="rp_original">
									This has not finished the argument yet, as Alice or Bob might try to figure out the other person's value by making more calculations. For example, Bob might try to randomly choose a number \(t\) and check if \(\operatorname E_a(t)=k-j+9\); if he succeeds, he then knows the value \(y_9\) to be \(t\), and knows the value of \(z_9\), which enables him to find out whether \(i \geq 9\). That would be an extra piece of information that Bob is not supposed to find out, if \(i \geq 9\) has been the outcome of the previous conclusion. Thus, one also has to include in the formal definition that not only the participants do not gain information as a result of the exchange specified by the protocol, but also they cannot perform calculation within a reasonable amount of time to gain this information. In the formal definition to be given in <a href="#sec3.2">Section 3.2</a>, we will define this precisely.
								</p>
								<p class="rp_annotation">
									This precise example will be addressed in the annotations, because Yao does not return to it. As a quick summary, neither party could perform enough calculations to learn something extra in polynomial time. Alice, in particular, cannot possibly learn anything, whereas Bob only has an \(\operatorname O\left(\frac{\operatorname{poly}(n)}{2^N}\right)\) <sup class="footnote" id="frefprob" data-footnote="prob"><a href="#footnoteprob">1</a></sup> probability of learning something, where \(n\) is the range of \(i,j\).
								</p>
								<p class="rp_original">
									One may have noticed the possibility that some party may cheat in the process, by deviating from the agreed protocol. For example, Bob may lie to Alice in the final step and tell Alice the wrong conclusion. Is there a way of designing a protocol such that the chance of a <span class="load-definable">successful cheating</span> becomes vanishingly small, without revealing the values of \(i\) and \(j\)? We will show that this is possible in <a href="#sec3.3">Section 3.3</a>. (Note that this is a stronger requirement than the verifiability requirement used in the <span class="load-definable">mental poker</span> protocol in Shamir et. al. <sup class="reference" data-citation="SRA">[5]</sup>).
								</p>
								<p class="rp_original">
									We have two other solutions to the millionaires' problem based on different principles. The first of them assumes that Alice and Bob each owns a private <span class="load-definable">one-way function</span>, where these functions satisfy the <span class="load-definable">commutativity</span> property, i.e. \(\operatorname E_a\operatorname E_b(x)=\operatorname E_b\operatorname E_a(x)\). The other solution makes use of a probabilistic <span class="load-definable">encryption</span> method invented by Goldwasser and Micali <sup class="reference" data-citation="GM">[2]</sup>.
								</p>
								<p class="rp_annotation" data-broken-link=true>
									To our knowledge, neither has been released by Yao.
								</p>
							</section>
							<section id="sec3.2" data-section-name="Model for the General Problem">
								<h3>3.2. Model for the General Problem</h3>
								<p class="rp_original">
									As these three solutions base their security on different assumptions, a precise model has to be specified in detail for each solution. In this abstract, we will only give the model that corresponds to the first solution.
								</p>
								<p class="rp_original">
									For simplicity, we will only give the definitions and results for the case when \(f\) is 0-1 valued and \(m\)=2 (Alice and Bob). Generalization of the results to general \(m\) will be briefly discussed in <a href="#sec5">Section 5</a>.  The proofs for the general case involve additional technical complications, and there are extra security considerations such as possible "<span class="load-definable" data-define="collusion">collusions</span>" that are absent in the 2-person case.
								</p>
								<h4>Protocol</h4>
								<p class="rp_original">
									Assume Alice has a public one-way function \(\operatorname E_a\), whose inverse function \(\operatorname D_a\) is known only to Alice; similarly Bob has a public \(\operatorname E_b\), and a private inverse \(\operatorname D_b\). Assume that \(\operatorname E_a\) and \(\operatorname E_b\) are independently and randomly drawn from \(Q_N\), the set of all the possible <span class="load-definable" data-define="permutation">1-1 onto functions</span> on \(N\)-bit integers. A protocol \(A\) for computing a function \(f(i,j)\) specifies exactly how Alice and Bob should communicate as follows. Alice and Bob send strings to each other alternately. Each time after Bob has finished transmission, Alice examines the information so far in her possession, which consists of some sequence of strings \(\alpha_1,\alpha_2,\dots,\alpha_t\), and some relations among the strings (e.g. \(\operatorname E_b(\alpha_3)=\alpha_9\), \(\alpha_8\) has an odd number of 1's); based on the bits that have so far been transmitted between her and Bob, the protocol specifies how she should compute in private strings \(\alpha_{t+1},\alpha_{t+2},\dots,\alpha_s\) where each new string \(\alpha_u\) is a function of the earlier strings, or of the form \(E_a(y)\), \(E_b(y)\) or \(\operatorname D_a(y)\) where y is a string already obtained. The choice of which function to apply or whether to evaluate \(\operatorname E_b\) or \(\operatorname D_a\) is in general probabilistic, i.e. she will decide to evaluate \(\operatorname E(\alpha_4)\), or to compute \(\alpha_2 + 3\alpha_8\) based on the outcomes of some <span class="load-definable" data-define="coin flip">coin tosses</span>. After she has finished this computation, she will send a string to Bob, and again the string is chosen probabilistically. Now it is Bob's turn to compute strings and send a string according to the protocol. We agree that there is a special symbol whose appearance means the end of the execution of the protocol. By that time, the protocol has an instruction for each participant to compute the function value \(f\) in private. Finally, we require that, in a protocol, the total number of evaluations of \(\operatorname E\)'s and \(\operatorname D\)'s by Bob and Alice be bounded by \(\operatorname O(N^k)\), where \(k\) is an integer chosen in advance.
								</p>
								<p class="rp_annotation">
									While not mentioned, it is important to note that random (or pseudorandom) number generation must also be allowed, even just for the above millionaires' protocol.
								</p>
								<h4>Privacy Constraint</h4>
								<span class="rp_definition_header" id="def1">Definition 1 - \((\epsilon,\delta)\)-privacy Constraint</span>
								<p class="rp_definition">
									Let \(\epsilon,\delta\gt0\), and \(f(i,j)\) be a \(0-1\) valued function. Assume that initially all pairs of \((i,j)\) values are equally likely. Suppose Bob and Alice carry out the computation faithfully according to the protocol. At the end, Alice can in principle, from her computed value \(v\) of the function and the strings in her possession, compute a probability distribution of the values of \(j\); call this \(p_i(j)\). A protocol is said to satisfy the \((\epsilon,\delta)\)-privacy constraint if the following conditions are satisfied:
								</p>
								<ol class="rp_definition">
									<li><span class="load-equation" data-equation="pij">\(p_i(j)=\frac{1}{|G_i|}(1+\operatorname O(\epsilon))\)</span> for \(j \in G_i\), and 0 otherwise, where \(G_i\) is the set of \(j\) for which \(f(i,j)=v\),</li>
								</ol>
								<p class="rp_annotation">
									More informally, if Alice iterates through all of the \(j\) that Bob could have had in order to produce \(v\) (here called the set \(G_i\)), she will not find any of them significantly (by a constant factor of \(\epsilon\)) more likely than the other possibilities.
								</p>
								<ol class="rp_definition">
									<li value="2">if Alice tries afterwards to perform more calculations with no more than \(\operatorname O(N^k)\) evaluations of \(\operatorname E\)'s and \(\operatorname D\)'s, then with probability at least \(1-\delta\) she will still get the above distribution on \(j\), and</li>
									<li>the above requirement is also true for Bob.</li>
								</ol>
								<p class="rp_annotation">
									Let's quickly see what \(\epsilon\) and \(\delta\) we can apply to the millionaires' protocol. For added generality, we will generalize from \(i,j\in\{1,10\}\) to any range of size \(n\) starting at 1. Without loss of generality, assume that Bob has more money (e.g. \(i\lt j\) and therefore \(f(i,j)=1\)). Fixing \(i,j\), we'll first look at what Alice can learn.
								</p>
								<p class="rp_annotation">
									Obviously, she knows that \(p_i(x)=0\) for \(x\leq i\). For the remainder of possible \(u=j\)'s, however, she can decrypt \(k-j+u\)'s using her private key, producing \(n-i\) possible \(x\) values. Since \(x\) was chosen randomly, she cannot possibly figure out which one Bob chose. \(G_i=\{i+1,i+2,\dots,n\}\) and, with no way of choosing between them, \(p_i(j)=\frac{1}{|G_i|}=\frac{1}{n-i}\) for \(j\in G_i\). Bob's information is <span class="load-definable" data-define="information theoretic security">information theoretically secure</span>.
								</p>
								<p class="rp_annotation">
									Bob, conversely, knows that \(i\) must be within \(G_j=\{1,2,\dots,j-1\}\). He has slightly more information from Alice, and can try to guess what another value of \(y_u\) was in order to further restrict \(i\)&mdash;information that would drastically alter his probability distribution. He knows \(p\), the random prime Alice has used to \(\bmod {y_u}\), and he knows either \(y_i\pmod{p}\) or \(y_i+1\pmod{p}\) for all of \(i\in G_j\). He must correctly guess a value \(g\) such that \(\operatorname E_a(g)\) or \(\operatorname E_a(g+1)\) is \(k+j-u\) for some \(u\lt j\).
								</p>
								<p class="rp_annotation">
									This is likely why Yao attempted to specify that no two \(y_u\)'s be within 2 of each other, to force Bob's search space within \((\mathbb{Z}/p\mathbb{Z})^*\) to be of size \(2(j-1)\). This restriction is not necessary, however: assume the very worst case, which is that \(z_u\) is a sequence of only one number repeated (and noting that that would tell Bob nothing about \(i\) by itself), so Bob has a search space of only 2 within \((\mathbb{Z}/p\mathbb{Z})^*\). Since each \(y_u\) could be between 0 and \(2^N-1\), and \(p\) is of maximum size \(2^{\frac{N}{2}}\), this leaves a minimal total search space of \(2*\frac{2^N}{2^{N/2}}=2^{\frac{N}{2}+1}\). Since Bob has no extra information which would allow him to choose from the search space better than randomly, finding a single value which would give him any information has expected runtime \(\operatorname O(2^N)\). Since this is the minimal search space, it is the best case for Bob, and therefore the probability of him finding any information through extra calculation is <span class="load-definable">negligible</span>.
								</p>
								<p class="rp_annotation">
									We can set \(\epsilon\) arbitrarily low, since neither party can calculate a probability distribution better than \(\frac{1}{|G|}\).
								</p>
								<p class="rp_annotation">
									We can calculate \(\delta\) a bit more precisely. The probability of Bob changing his probability distribution is \(\frac{\operatorname O(N^k)}{2^{N/2+1}}\) best case, so for fixed \(k\) we can set \(\delta\leq \frac{\operatorname O(N^k)}{2^{N/2+1}}\), which <a href="http://www.wolframalpha.com/input/?i=plot+%28N%5Ek%29%2F%282%5E%28N%2F2%2B1%29%29+on+k%3D0..8%2C+N%3D128..256">rapidly</a> approaches \(0\) as \(N\) increases.
								</p>
								<span class="rp_theorem_header" id="theorem1">Theorem 1</span>
								<p class="rp_original rp_theorem">
									For any \(\epsilon,\delta\gt0\) and any function \(f\), there exists a protocol for computing \(f\) that satisfies the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span>.
								</p>
								<p class="rp_annotation">
									Yao did not present a proof for this theorem in this paper. 
								</p>
								<p class="rp_original">
									It is possible to consider the more general case when the initial distribution of \((i,j)\) is nonuniform. We will not go into that here. In <a href="#sec4">Section 4</a>, that becomes a special case of probabilistic computations.
								</p>
							</section>
							<section id="sec3.3" data-section-name="Additional Requirements">
								<h3>3.3. Additional Requirements</h3>
								<h4>Complexity</h4>
								<p class="rp_original">
									The solution given earlier for the millionaires' problem will become impractical if the range \(n\) of \(i,j\) become large, since the number of bits transmitted is proportional to \(n\). An interesting question is then to determine the minimum number of bits needed by any protocol to compute \(f\) that satisfies the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span>. Conceivably, there are functions that are easily computable without the privacy requirement, but become infeasible with the extra privacy constraint. Fortunately, we can prove that this is not the case. Let \(A\) be a protocol, let <span class="load-equation" data-equation="T(A)">\(T(A)\)</span> denote the maximum number of bits exchanged between Alice and Bob when \(A\) is used.
								</p>
								<p class="rp_annotation">
									If we set \((\epsilon,\delta)=(1,1)\)&mdash;that is, if we don't require privacy at all&mdash;then the only information that needs to be sent is \(i\) to Bob, followed by \(f(i,j)\) back to Alice, meaning <span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(=\log_2{i}+1\leq N+1\); this is the lowest bound possible (<span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(\in\operatorname\Omega(N)\)). This would be increased further by the need for security, of course.
								</p>
								<span class="rp_theorem_header" id="theorem2">Theorem 2</span>
								<p class="rp_original rp_theorem">
									Let \(1\gt\epsilon,\delta\gt0\) and \(f(i,j)\) be a \(0-1\) function. If \(f\) can be computed by a boolean circuit of size \(C(f)\), then there is a protocol \(A\) computing \(f\) satisfying the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span> such that <span class="load-equation" data-equation="T(A)">\(T(A)\)</span><span class="load-equation" data-equation="th2">\(\in\operatorname O\left(C(f)\log{\frac{1}{\epsilon\cdot\delta}}\right)\)</span>.
								</p>
								<p class="rp_annotation">
									Yao would later go on to develop this theorem into another pivotal work in multiparty computation, <a href="24.html">How to Generate and Exchange Secrets</a>. The basic idea is that one can use a construction called a "garbled circuit" in order to securely transfer the outcome of an entire circuit, one gate at a time. Note that this is only secure against <span class="load-definable" data-define="passive adversary">passive adversaries</span>.
								</p>
								<p class="rp_original">
									In fact, if \(f\) can be computed by a <span class="load-definable">Turing machine</span> in time \(S\), then the protocol can be implemented such that both Alice and Bob have <span class="load-definable">Turing machine</span> <span class="load-definable" data-define="algorithm">algorithms</span> to execute the protocol with a time bound \(\operatorname O\left(S\log{\frac{1}{\epsilon\cdot\delta}}\right)\).
								</p>
								<p class="rp_original">
									However, there exist functions that need exponentially many bits transmitted between Bob and Alice with the privacy constraint. Let \(F_n\) be the family of \(0-1\) valued function \(f(i,j)\) with \(i\) and \(j\) being \(n\)-bit integers. Clearly, at most \(n\) bits of transmitted information can compute \(f\), in the absence of the privacy constraint. (See <span class="reference" data-citation="Yao">[7]</span> for further discussion).
								</p>
								<p class="rp_annotation">
									Yao is referring to the lower bound mentioned above, though does not include in the calculation the final bit exchanged which would exchange the answer.
								</p>
								<span class="rp_theorem_header" id="theorem3">Theorem 3</span>
								<p class="rp_original rp_theorem">
									Let \(\frac{1}{5}\gt\epsilon,\delta\gt0\) be fixed. Let \(f\) be a random element of \(F_n\), then any protocol \(A\) that computes \(f\) with <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy</span> constraint must have <span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(\gt 2^\frac{n}{2}\) for all large \(n\).
								</p>
								<p class="rp_annotation">
									We are yet uncertain what to make of this theorem: in particular, whether Yao means to indicate something significant about the value \(\frac{1}{5}\), or to specify a particular property of members of \(F_n\).
								</p>
								<h4>Mutually-Suspecting Participants</h4>
								<p class="rp_original">
									So far the discussions have assumed that Bob and Alice observe the rules specified by an agreed protocol. What if either of them might cheat in order to gain additional information or to mislead the other party to receive a wrong answer? It is true that with our protocol, any cheating will be discovered if there is a verification stage afterwards where both parties are required to reveal all their private computation. However, that will force both parties to reveal their variables. As will become clear in the applications to be given later, this sometimes can be a serious drawback. The following results will show that one can thwart cheating, without asking either to reveal the variable.
								</p>
								<p class="rp_original">
									Since a protocol can never prohibit Alice (or Bob) from behaving as if she had a different variable value \(i'\), the most that a protocol can achieve is to make sure that this is the only cheating that Alice (or Bob) can do.
								</p>
								<p class="rp_annotation">
									So, in particular, Alice and Bob can never:
								</p>
								<ol class="rp_annotation">
									<li>Start with one \(i\), then change to another \(i'\) at a different time during the computation.</li>
									<li>Start with an invalid \(i\), although this is sometimes impossible to do at all (as with Alice in the millionaires' protocol)</li>
								</ol>
								<span class="rp_definition_header" id="def2">Definition 2 - Successful Cheating</span>
								<p class="rp_original rp_definition">
									Consider an instance in the execution of a protocol. We will consider it to be a successful cheating by Alice, if Alice does not behave consistently with any value of \(i\) and yet Bob does not detect it. A successful cheating by Bob is defined similarly.
								</p>
								<span class="rp_theorem_header" id="theorem4">Theorem 4</span>
								<p class="rp_original rp_theorem">
									Let \(1\gt\gamma\gt0\). Under the same assumption of <a href="#theorem2">Theorem 2</a>, there exists a protocol \(A\) for computing \(f\) such that
								</p>
								<ol class="rp_original rp_theorem">
									<li><span class="load-equation" data-equation="T(A)">\(T(A)\)</span>\(\in \operatorname O\left(C(f)\log{\frac{1}{\epsilon\cdot\delta\cdot\gamma}}\log{\frac{1}{\gamma}}\right)\), and</li>
									<li>if one participant behaves according to \(A\), the probability of a <span class="load-definable">successful cheating</span> by the other participant is at most \(\gamma\)</li>
								</ol>
								<p class="rp_annotation">
									Cheating and colluding are addressed in a <span data-broken-link=true>tutorial section</span>, or under the tags <a href="../tag.html#research:tag:Collusion">Collusion</a> and <a href="../tag.html#research:tag:DishonestParties">Dishonest Parties</a> in the research-by-category section.
								</p>
							</section>
							<section id="sec3.4" data-section-name="Applications">
								<h3>3.4. Applications</h3>

								<h4>Secret Voting</h4>
								<p class="rp_original">
									Suppose a committee of \(m\) members wish to decide on a yes-no action. Each member is to write an opinion \(x_i\), and the final action can be regarded as a function \(f(x_1, x_2, x_3,\dots, x_m)\). The results obtained in this paper means that it is possible to agree on the final action \(f\), without anyone knowing the opinion of any other member's. Furthermore, the protocol makes the probability of anyone having a <span class="load-definable">successful cheating</span> very remote.
								</p>

								<p class="rp_annotation">
									Definitely the most relatable and understandable use of multiparty computation mentioned! A basic coverage of voting is dealt with in the <a href="../../learn/ch1.html#sec2">first tutorial</a>, and further research can be found under the <a href="../tag.html#research:tag:Voting">Voting</a> tag.
								</p>

								<h4>Oblivious Negotiation</h4>
								<p class="rp_original">
									Suppose that Alice is trying to sell Bob a house. In principle, each one has a strategy of negotiation in mind. If we number all the possible strategies of Alice as \(A_1,A_2,\dots,A_t\), and those of Bob' as \(B_1,B_2,\dots,B_u\), then the outcome (no deal, or sell at \(x\) dollars,&hellips;) will be decided once the actual strategies \(A_i, B_j\) used have been determined. Write the outcome as \(f(i, j)\), then it is possible to carry out the negotiation obliviously, in the sense that Alice will not gain any information on Bob's negotiation tactics except that it is consistent with the outcome, and vice versa.
								</p>

								<h4>Private Querying of a Database</h4>
								<p class="rp_original">
									The theorems we have proved can be extended to the case when each person \(P_i\) is computing a different function \(f_i\). In particular, Alice may wish to compute a function \(f(i, j)\) and Bob wishes to compute a trivial function \(g(i, j) =\) constant, meaning that Bob will know nothing about \(i\) in the end. If we regard Bob as a database query system with \(j\) the state of the database, and Alice is asking query number \(i\), then Alice can get answer to the query without knowing anything else about the data in it, while the database system does not know what Alice has queried.
								</p>

								<p class="rp_annotation">
									An abstract but definitely extremely useful category of multiparty computation that is also a subproblem of <span class="load-definable" data-define="oblivious transfer">Oblivious Transfer</span>.
								</p>
							</section>
						</section>
						<section id="sec4" data-section-name="Probabilistic Computations">
							<h2>4. Probabilistic Computations</h2>
							<p class="rp_original">
								Let us consider the case with two parties Bob and Alice \((m = 2)\). Let \(V\) and \(W\) be finite sets. A function \(p\) from <span class="load-equation" data-equation="cartesianproduct">\(V \times W\)</span> to the interval \([0, 1]\) is called a <span class="load-definable" data-define="probability density function">probability density</span> if the sum of \(p(v,w)\) over \(v\) and \(w\) is equal to \(1\). Let \(P(V,W)\) be the set of all such <span class="load-definable" data-define="probability density function">probability densities</span>.
							</p>

							<p class="rp_original">
								Let \(I, J\) be finite sets of integers. Let \(F = \{f_{ij} | i \in I, j \in J\} \subseteq P(V,W)\) be a family of probability densities. Initially, Alice knows the value of \(i \in I\), and Bob knows \(j \in J\); the values of \((i, j)\) obey a certain initial probability density \(q \in P(I, J)\). They wish to send messages between them, so that at the end Alice will obtain a value \(v \in V\) and Bob a value \(w \in W\) with probability \(f_{ij}(v,w)\). The privacy constraint is that the information Alice can obtain about \(j\) and \(w\) is no more than what can be inferred from her values of \(i\) and \(v\) (plus a corresponding constraint on Bob). This statement can be made precise in terms of \(q\) and \(F\); we omit its full generality here but simply give an illustration for the special case \(q\) = constant. In this special case, the distribution \(h(w)\) that Alice can infer from the computation she has done, according to the privacy constraint, is equal to
							</p>

							<p style="font-size:150%">
								$$\frac{1}{|J|}\sum\limits_{j\in J}\frac{f_{ij}(v,w)}{\sum\nolimits_{x\in W} f_{ij}(v,x)}$$
							</p>

							<p class="rp_annotation">
								Keep in mind that this is the probability of \(w\) given a particular \(i\) and \(v\); Bob's equation would be the same, but with \(j\) and \(v\) instead. Since \(q\) is constant, the probability of each \(j\) is equally likely to any other, so we can simply add all \(|J|\) probabilities together and divide by \(|J|\) at the end.
							</p>
							<p class="rp_original">
								For example, <span class="load-definable">mental poker</span> would correspond to the following situation: \(I = J = {0}\), \(q\) is a constant, \(V = W\) is the set of all 5-element subsets of \({1, 2,\dots, 52}\), \(f_{00}(v,w)\) is \(0\) if \(v\) and \(w\) are not disjoint and equal to a constant otherwise.
							</p>

							<p class="rp_original">
								The results in <a href="#sec3">Section 3</a> have generalizations to the probabilistic case. Basically, a reasonable probabilistic computation remains feasible when the privacy constraints are imposed. We will not give the details here.
							</p>

							<p class="rp_original">
								One interesting corollary of our results is that mental poker can be played with any general public-key system. It differs from Shamir et. al's solution<sup class="reference" data-citation="SRA">[5]</sup> in that we do not require the <span class="load-definable" data-define="one-way function">one-way functions</span> used to be <span class="load-definable" data-define="commutativity">commutative</span>, and that we can play it with a public-key system (instead of using private keys). (A solution with a special <span class="load-definable">one-way function</span> with publicized keys for playing <span class="load-definable">mental poker</span> was known in <span class="reference" data-citation="GM">[2]</span>, but that solution depends on the special properties of the <span class="load-definable">one-way function</span> involved.) Moreover, the present solution uses much fewer bits as the number of cards becomes greater. Suppose we have a deck of \(n\) cards, and Alice and Bob each want to draw a random card from the deck in turn. All the previously known solutions transmit \(cn\) bits of information between Bob and Alice, while our scheme only needs about \(c(\log{n})^2\) bits.
							</p>
						</section>
						<section id="sec5" data-section-name="Generalization to \(m\)-Party Case">
							<h2>5. Generalization to \(m\)-Party Case</h2>
							<p class="rp_original">
								When \(m\) parties \(A_1,A_2,\dots,A_m\) collaborate to compute a function <span class="load-equation" data-equation="fx1xm">\(f(x_1, x_2,\dots,x_m)\)</span>, more than one parties may <span class="load-definable" data-define="collusion">collude</span> to cheat. We will show that even the most severe constraint can be met in the following sense: No matter how many participants may <span class="load-definable" data-define="collusion">collude</span>, any cheating act will be detected and identified by all the honest parties (even if as many as \(m−1\) dishonest guys try to help cover up). We now make it precise.
							</p>

							<p class="rp_annotation">
								Remember, however, that some <span class="load-definable" data-define="collusion">collusions</span> and types of cheating are impossible to fight against: Yao is only referring to <span class="load-definable" data-define="collusion">collusions</span> and cheating which involve inconsistencies in input variables. As an example, if ten people are trying to compute the sum of their private variables securely, but nine of them <span class="load-definable" data-define="collusion">collude</span> in order to determine the tenth's private variable, the protocol will not make a difference: they need only share those nine values and follow the protocol correctly, and they will all know the tenth value as well, by subtracting from the total sum. The guarantee Yao is making is that none of those people could convince someone they did the protocol correctly if they actually used changing random numbers throughout.
							</p>

							<p class="rp_original">
								Let \(V\) be the range of the function \(f(x_1, x_2,\dots,x_m)\), where \(x_i \in X_i\). For any nonempty \(K \subseteq \{1, 2,\dots,m\}\), define \(H_K = X_{t_1} \times X_{t_2} \times \cdots \times X_{t_{|K|}}\) , where \(\{t_1, t_2,\dots, t_{|K|}\} = K\). Let \(K' = \{1, 2,\dots,m\} − K\), and define \(H_{K'}\) similarly. For any \(i \in H_{K'}\) and \(v \in V\) , let \(G_i(v) \subseteq H_K\) be the set of all \(j \in H_K\) such that the (unique vector) \(x = (x_1, x_2,\dots, x_m)\), whose projection on \(H_{K'}\) and \(H_K\) equals \(i\) and \(j\) respectively, satisfies \(f(x) = v\). Let \(q_{i,v}(j) = \frac{1}{|G_i(v)|}\) for \(j \in G_i(v)\) and 0 otherwise. (If all the participants \(A_r\) with \(r \in K'\) <span class="load-definable" data-define="collusion">collude</span> to infer the probability distribution of the variable values of other participants, and if the only information available, in addition to their only variable values \(i\), is that the function \(f\) has value \(v\), then \(q_{i,v}(j)\) is the distribution they can infer.) Let \(\epsilon,\delta\gt0\). A protocol \(A\) is said to <i>satisfy the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-private constraint</span></i> if for every nonempty \(K\), even if the participants in \(K\) are allowed to perform in private an amount of calculation polynomial in <span class="load-equation" data-equation="T(A)">\(T(A)\)</span>, they will still infer, with probability at least \(1−\delta\), that the distribution on \(j\) is equal to \(q_{i,v}(j)(1+\operatorname O(\epsilon))\). A <span class="load-definable">successful cheating</span> by \(K'\) (with respect to a protocol \(A\)) is an instance of the execution of \(A\), in which at least one participant \(A_r\) with \(r \in K'\) behaves inconsistently with any \(x_r \in X_r\) without being detected by all the participants of \(K\).
							</p>

							<p class="rp_annotation">
								The above paragraph is extremely dense, so let's clarify a bit. \(K\) is the set of all honest parties, while \(K'\) is the set of all dishonest parties. The <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-privacy constraint</span> is defined by specifying that all members of \(K\) (and therefore all honest parties) are only able to infer the probability distribution \(q_{i,v}(j)(1+\operatorname O(\epsilon))\). A <span class="load-definable">successful cheating</span> is defined by specifying that <i>all</i> of \(K'\) together was able to trick <i>at least one</i> member of \(K\) into not realizing they had behaved inconsistently with at least one value of \(x\).
							</p>
							<span class="rp_theorem_header" id="theorem5">Theorem 5</span>
							<p class="rp_original rp_theorem">
								For any \(\epsilon,\delta,\gamma\gt0\), there exists a protocol \(A\) for computing \(f\) which satisfies the <span class="load-definable" data-define="(e,d)-privacy constraint">\((\epsilon,\delta)\)-private constraint</span> and which has the property that, for any \(K' \neq \{1,\dots,m\}\), the probability for \(K'\) to have a <span class="load-definable">successful cheating</span> can not be more than \(\gamma\).
							</p>

							<p class="rp_original">
								The value of <span class="load-equation" data-equation="T(A)">\(T(A)\)</span> in the above theorem is \(\operatorname O(|X_1|\cdot |X_2|\cdot\cdots\cdot|X_m|\cdot|V|)\), which is almost optimal in general as the next theorem shows.
							</p>

							<span class="rp_theorem_header" id="theorem6">Theorem 6</span>
							<p class="rp_original rp_theorem">
								There exist functions \(f\) for which any protocol \(A\) satisfying the conditions in Theorem 5 must have <span class="load-equation" data-equation="T(A)">\(T(A)\)</span><span class="load-equation" data-equation="quartic">\(=\Omega((|X_1|\cdot |X_2|\cdot\cdots\cdot|X_m|)^\frac{1}{4})\)</span>
							</p>

							<p class="rp_annotation">
								We should take a second to notice that this is an unreasonably high lower bound for a lot of real world applications. As an example, if there are \(m\) parties trying to calculate \(f\) on \(n\)-digit numbers, then that leaves a lower bound of \(\operatorname\Omega(2^{\frac{nm}{4}})\).
							</p>

							<p class="rp_original">
								In special cases protocols can be designed with better running time than the bound given in Theorem 5. For example, the parity function <span class="load-equation" data-equation="fx1xm">\(f(x_1, x_2,\dots, x_m)\)</span> = \(x_1 \bigoplus x_2 \bigoplus \cdots \bigoplus x_m\) and the tally function \(f(x_1, x_2,\dots, x_m) =\) # of 1's in the \(x\)'s (the \(x\)'s are boolean variables) both have protocols satisfying <a href="#theorem5">Theorem 5</a> with running time polynomial in \(m\).
							</p>

							<p class="rp_original">
								The security measure as we considered above is a strong one. For some purposes, less stringent measures would be adequate. (For example, one may only require that no subset \(K'\) be able to force the outcome of the computation to be a certain value.) Sometimes protocols with better running time can be designed under such less stringent requirements. For example, there is a protocol with running time \(\operatorname O(p(m) \log{q})\), where \(p(m)\) is a polynomial, for \(m\) parties to compute the function <span class="load-equation" data-equation="fx1xm">\(f(x_1, x_2,\dots, x_m)\)</span> = \(x_1 +x_2 +\cdots+x_m\pmod{q}\), under a security criterion only slightly relaxed from that given in <a href="#theorem5">Theorem 5</a>.
							</p>
						</section>
						<section id="sec6" data-section-name="What Cannot Be Done?">
							<h2>6. What Cannot Be Done?</h2>
							<p class="rp_original">
								There are security constraints that can not be achieved by any protocols. We will only mention two results here.
							</p>

							<p class="rp_original">
								The first impossibility result is valid for all three models given in this paper. Suppose \(m\) people try to generate a bit with bias \(\alpha\). It is easy to see how it can be done for \(m\gt2\). For example, A generates a random <span class="load-definable" data-define="bias">unbiased</span> bit \(\alpha_1\) and sends it to B, B generates a random \(\alpha_2\) and sends it to C, C generates a random \(\alpha_3\) and sends it to A. Now let \(\alpha = \alpha_1 + \alpha_2 + \alpha_3\), and we get an <span class="load-definable" data-define="bias">unbiased</span> \(\alpha\) with the property that it remains unbiased even if one of the persons cheats by generating a <span class="load-definable" data-define="bias">biased</span> bit. Let us call a protocol for generating a bit with <span class="load-definable">bias</span> \(\alpha\) <span class="load-definable">robust</span>, if the <span class="load-equation" data-equation="">bias</span> remains correct if somebody has cheated.
							</p>

							<span class="rp_theorem_header" id="theorem7">Theorem 7</span>
							<p class="rp_original rp_theorem">
								No protocol \(A\) with finite <span class="load-equation" data-equation="T(A)">\(T(A)\)</span> which generates a bit with a <span class="load-definable">transcendental</span> bias \(\alpha\) can be <span class="load-definable">robust</span>.
							</p>

							<p class="rp_original">
								The second result is valid for the model defined in <a href="#sec3.2">Section 3.2</a>. Suppose Alice and Bob wish to exchange a pair of solutions \(x, y\) with \(\operatorname E_a(x) = 1\) and \(\operatorname E_b(y) = 1\). Is there a protocol such that an honest party will not be doublecrossed, i.e. swindled out of its secret without getting the secret from the other party?
							</p>

							<span class="rp_theorem_header" id="theorem8">Theorem 8</span>
							<p class="rp_original rp_theorem">
								Let \(A\) be any protocol for exchanging secrets. Then either Alice or Bob will be able to double-cross successfully with probability at least &frac12;.
							</p>

							<p class="rp_original">
								It is of interest to mention that a different type of exchanging secrets is possible in the same model. Suppose Alice wants to know the solution \(y\) to \(\operatorname E_b(y) = w\) and Bob wants to know the solution \(x\) to \(\operatorname E_a(x) = u\), but Bob does not know the value of \(w\) and Alice does not know \(u\). Let \(N\) be the number of bits that the encryption functions \(\operatorname E_a\) and \(\operatorname E_b\) operate on.
							</p>

							<span class="rp_theorem_header" id="theorem9">Theorem 9</span>
							<p class="rp_original rp_theorem">
								Let \(\epsilon\gt0\) be fixed. There is a protocol \(A\) with polynomial (in \(N\)) running time which exchanges secrets \(\operatorname D_b(w)\) and \(\operatorname D_a(u)\), and under which the probability of anyone double-crossing successfully is bounded by \(\epsilon\).
							</p>

							<p class="rp_annotation">
								As a short summary of theorems 8 and 9, when viewed together: either Alice or Bob can double-cross the other easily assuming that they know the value they are decrypting. If they do not know the value they are decrypting, their ability to double-cross can be bounded.
							</p>

							<p class="rp_original">
								Different kinds of exchanging secrets have been considered previously. Blum<sup class="reference" data-citation="Bl">[6]</sup> showed that it is possible to exchange factors of large composite numbers (a special type of secrets) with vanishing chance for cheating. Even (private communication, 1981) also devised some protocols for exchanging secrets.
							</p>
						</section>
					</section>
				</div>
			</div>
			<div class="main_toplevel main_section main_color7">
				<div class="main_fullwidth">
					<section class="top_section" id="footnotes" data-section-name="Footnotes">
						<h1>Footnotes</h1>
						<ol id="footnotelist">
							<li id="footnoteprob" class="rp_annotation_footnote">We have defined \(n\) to be the range of \(i,j\), fixed by the participants before the run of the protocol. Bob only sees the decryption of some \(n\) values under Alice's encryption scheme; in order for Bob to learn information, he must guess some value that encrypts to one of those values. By the definition of a <span class="load-definable">permutation</span>, there are only \(n\) values that Bob could guess correctly; this means there is a \(\frac n{2^N}\) probability that Bob will learn any information on each guess he makes. As such, the probability of Bob getting any information is \(\operatorname O\left(\frac{\operatorname{poly}(n)}{2^N}\right)\).</li>
						</ol>
					</section>
				</div>
			</div>
			<div class="main_toplevel main_section main_color8">
				<div class="main_fullwidth">
					<section class="top_section" id="references" data-section-name="References">
						<h1>References</h1>
						<ol class="rp_original" id="referencelist">
							<li id="DH">Whitfield Diffie and Martin E. Hellman. New directions in cryptography. <i>IEEE Transactions on Information Theory</i>, IT-22(6):644–654, 1976.</li>
							<li id="GM">S. Goldwasser and S. Micali. Probabilistic encryption and how to play mental poker keeping secret all partial information. In <i>Proceedings of the 14th ACM Symposium on Theory of Computing (STOC'82)</i>, pages 365–377, San Francisco, CA, USA, May 1982.</li>
							<li id="Ra">M. O. Rabin. Digitalized signatures and public-key functions as intractable as factorization. Technical Report LCS/TR-212, Massachusetts Institute of Technology, 1979.</li>
							<li id="RSA">R. L. Rivest, Adi Shamir, and Leonard M. Adleman. A method for obtaining digital signatures and publickey cryptosystems. <i>Communications of the ACM</i>, 21(2):120–126, February 1978.</li>
							<li id="SRA">Adi Shamir, R. L. Rivest, and Leonard M. Adleman. Mental poker. Technical Report LCS/TR-125, Massachusetts Institute of Technology, April 1979.</li>
							<li id="Bl">Manuel Blum. Three applications of the oblivious transfer: Part I: Coin flipping by telephone; part II: How to exchange secrets; part III: How to send certified electronic mail. Technical report, University of California, Berkeley, CA, USA, 1981.</li>
							<li id="Yao">Andrew C. Yao. Some complexity questions related to distributive computing. In <i>Conference Record of the 11th ACM Symposium on Theory of Computing (STOC'79)</i>, pages 209–213, Atlanta, GA, USA, April 1979.</li>
						</ol>
						<p class="rp_annotation">
							His previous research on the minimum number of bits exchanges is an interesting read, but is not necessary to understand this paper. It is much more about minimizing the <i>amount</i> of information exchanged (in a more information theoretical way) than about privacy, so has much less bearing here.
						</p>
					</section>
				</div>
			</div>
			<div class="main_toplevel main_section main_color9">
				<div class="rp_problems">
					<p><a href="mailto:multipartycomputationorg+49@gmail.com">Problem with this page?</a></p>
				</div>
				<p>Created by Nicolas Schank 2014, Brown University</p>
				<p>All original work is free for any use by anyone whatsoever.</p>
				<p>For more information about liability and licensing Yao's original paper, see <a href="../liability.html">Liability</a>.</p>
			</div>
		</div>
	</body>
</html>