<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Adaptively Secure Multiparty Computation - Ran Canetti, Uri Feige, Oded Goldreich, Moni Naor, 1996</title>
        <link rel="stylesheet" type="text/css" href="../../style/main.css">
        <link rel="stylesheet" type="text/css" href="../../style/equation.css">
        <link rel="stylesheet" type="text/css" href="../../style/ref.css">
        <link rel="stylesheet" type="text/css" href="../../style/glossary.css">
        <link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
        <link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
        <script type="text/javascript" src="../../script/equation.js"></script>
        <script type="text/javascript" src="../../script/ref.js"></script>
        <script type="text/javascript" src="../../script/glossary.js"></script>
        <script type="text/javascript" src="../../script/def.js"></script>
		<script type="text/javascript" src="../../script/toc.js"></script>
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/javascript">
			<!--
            function fill(box)
			{
				switch (box)
				{
					default:
						return "No info on this equation yet.";
				}
			}

			function authorLink(ref)
			{
				switch (ref)
				{
					default:
						return "#";
				}
			}

			self_def["non-general word"] = "definition";
			//-->
        </script>
    </head>
    <body>
        <div class="main_foreground">
            <div class="main_toplevel main_header">
                <h1>Multiparty Computation</h1>
            </div>
            <div class="main_toplevel main_navigation">
                <a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
                <a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
                <a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
                <a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
                <a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
                <a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
            </div>
            <div class="main_toplevel main_section main_color1" id="overview">
                <div class="main_section_nav_container">
                    <div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
                    <div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
                    <div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
                    <div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
                </div>
                <div class="main_window main_fullwidth">
                    <div class="rp_linkbox"><a href="pdf/5.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
					
                    <span class="rp_title">Adaptively Secure Multiparty Computation</span>
                    <span class="rp_info">1996
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a class="rp_author" href="../authors/Ran Canetti.html">Ran Canetti</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a class="rp_author" href="../authors/Uri Feige.html">Uri Feige</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a class="rp_author" href="../authors/Oded Goldreich.html">Oded Goldreich</a> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a class="rp_author" href="../authors/Moni Naor.html">Moni Naor</a>
					</span>
					
					<div class="rp_snippet">
						&ldquo;&rdquo;
					</div>
					
					THIS PAGE IS UNDER CONSTRUCTION
					<h1>Overview</h1>
                    <div class="main_toc"></div>
						
                    <section id="intro">
						<h2>Introduction</h2>
						<p class="rp_analysis">
							<b>Paper Title</b> is...
						</p>
					</section>
					<section id="goals">
						<h2>Goals and Results</h2>
						<p class="rp_analysis">
							Some goals that they had.
						</p>
						<p class="rp_analysis">
							Don't forget some results, too!
						</p>
					</section>
					<section id="assumptions">
						<h2>Assumptions</h2>
					</section>
					<section id="defs">
						<h2>Definitions</h2>
						<a href="#def1"><span class="rp_definition_header">Definition 1 - </span></a>
						<p class="rp_original rp_definition">
							A definition 
						</p>
					</section>
					<section id="theorems">
						<h2>Theorems</h2>
						<p class="rp_original">Some general definitions used by several theorems</p>
						<a href="#theorem1"><span class="rp_theorem_header">Theorem 1</span></a>
						<p class="rp_original rp_theorem">
							A theorem
						</p>
					</section>
					<section id="protocol">
						<h2>Protocols</h2>
						<h3><a href="#secxx">Some Protocol Defined</a></h3>
						<ul class="rp_analysis">
							<li><b>Number of parties: </b></li>
							<li><b>Function(s): </b></li>
							<li><b>Privacy constraints: </b></li>
							<li><b>Cheating: </b></li>
							<li><b>Bits exchanged: </b></li>
							<li><b>Subprotocols: </b></li>
							<li><b>Runtime: </b></li>
							<li><b>Assumptions: </b></li>
							<li><b>Implementations: </b></li>
							<li><b>Notes: </b></li>
						</ul>
					</section>
					<section id="further">
						<h2>Further Reading</h2>
					</section>
					<section id="ref">
						<h2>Referencing This Paper</h2>
						<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
						<p class="rp_self_reference">
							A reference for this paper
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color5" id="annotated_paper">
                <div class="main_window main_fullwidth">
					<h1>Annotated Paper</h1>
					<div class="main_toc"></div>
					<section id="abstract">
						<h2>Abstract</h2>
						<p class="rp_original">
							A fundamental problem in designing secure multiparty protocols is how to deal with adaptive adversaries (i.e. adversaries that may choose the corrupted parties during the course of the computation), in a setting where the channels are insecure and secure communication is achieved by cryptographic primitives based on the computational limitations of the adversary. 
						</p>
						<p class="rp_original">
							It turns out that the power of an adaptive adversary is greatly affected by the amount of information gathered upon the corruption of a party. This amount of information models the extent to which uncorrupted parties are trusted to carry out instructions that cannot be externally verified, such as erasing records of past configurations. It has been shown that if the parties are trusted to erase such records, then adaptively secure computation can be carried out using known primitives. However, this total trust in parties may be unrealistic in many scenarios. An important question, open since 1986, is whether adaptively secure multiparty computation can be carried out in the 'insecure channel' setting, even if no party is thoroughly trusted.
						</p>
						<p class="rp_original">
							Our main result is an affirmative resolution of this question for the case where even uncorrupted parties may deviate from the protocol by keeping record of all past configurations. We first propose a novel property of encryption protocols and show that if an encryption protocol enjoying this property is used, instead of a standard encryption scheme, then known constructions become adaptively secure. Next we construct, based on the standard RSA assumption, an encryption protocol that enjoys this property. 
						</p>
						<p class="rp_original">
							We also consider parties that, even when uncorrupted, may internally deviate from their protocols in arbitrary ways, as long as no external test can detect fault behavior. We show that in this case no non-trivial protocol can be proven adaptively secure using black-box simulation. This holds even if the communication channels are totally secure.
						</p>
					</section>
					<section id="sec1">
						<h2>1. Introduction</h2>
						<p class="rp_original">
							Consider a set of parties who do not trust each other, nor the channels by which they communicate. Still, the parties wish to correctly compute some common function of their local inputs, while keeping their local data as private as possible. This, in a nutshell, is the problem of secure multiparty computation. The parties' distrust in each other and in the network is usually modeled via an adversary that corrupts some of the parties. Once a party is corrupted it follows the instructions of the adversary. In particular, all the information known to this party becomes known to the adversary.
						</p>
						<p class="rp_original">
							An important parameter, which is the focus of this work, is the way in which the corrupted parties are chosen. In the case of <i>non-adaptive</i> adversaries, the set of corrupted parties is arbitrary, but fixed before the computation starts. (Still, the uncorrupted parties do not know the identities of the corrupted parties.) A more general case is where the adversary chooses to corrupt parties during the course of the computation, based on the information gathered so far. We call such adversaries <i>adaptive</i>.
						</p>
						<p class="rp_original">
							The difference between adaptive and non-adaptive adversaries may be best demonstrated via an example. Consider the following secret sharing protocol, run in the presence of an adversary that may corrupt \(t=O(n)\) out of the \(n\) parties. <i>A dealer \(D\) chooses at random a small set \(S\) of \(m=\sqrt t\) parties, and shares its secret among the parties using an \(m\)-out-of-\(m\) sharing scheme. In addition, \(D\) publicizes the set \(S\).</i> Intuitively, this scheme lacks in security since \(S\) is public and \(|S|\ll t\). Indeed, an adaptive adversary can easily find \(D\)'s secret, <i>without corrupting \(D\)</i>, by corrupting the parties in \(S\). However, any non-adaptive adversary that does not corrupt \(D\) learns \(D\)'s secret only if \(S\) happens to be identical to the pre-defined set of corrupted parties. This happens only with exponentially small probability. Consequently, this protocol is secure in the presence of non-adaptive adversaries.
						</p>
						<p class="rp_original">
							Protocols for securely computing any function, in several computation models, have been known for a while: Goldreich, Micali, and Wigderson have shown how to securely compute any function in the <i>computational</i> setting<sup class="reference" data-citation="GMW">[?]</sup>. (In the <i>computational</i> setting, all the communication between the parties is seen by the adversary. All parties, as well as the adversary, are restricted to probabilistic polynomial time). Ben-Or, Goldwasser, and Wigderson, and independently Chuam, Cr&eacute;peau, and Damg&aring;rd, have shown how to securely compute any function in the <i>secure channels</i> setting<sup class="reference" data-citation="BGW">[?]</sup><sup class="reference" data-citation="CCD">[?]</sup>. (In the <i>secure channels</i> setting the adversary cannot eavesdrop on the communication between uncorrupted parties, and is allowd unlimited computational power.) These constructions can be shown secure in the presence of non-adaptive adversaries. In contrary to folklore beliefs, problems are encountered when attempted to prove <i>adaptive</i> security of protocols, <i>even in the secure channels setting</i>. Additional problems are encountered in the computational setting. Demonstrating, clarifying, and (partially) solving these problems is the focus of this work.
						</p>
						<p class="rp_original">
							We first pose the following question: To what extent can uncorrupted parties be trusted to carry out instructions that cannot be externally verified, such as erasing local data, or making random choices? This question is intimately related to the power of an adaptive adversary, in both of the above settings, since the adversary may gather additional information when corrupting parties that have locally deviated from the protocol (say, by not erasing data that is supposed to be erased). If uncorrupted parties are trusted to carry out even unverifiable instructions such as erasing local data, then adaptively secure computation can be carried out using known primitives<sup class="reference" data-citation="F">[?]</sup><sup class="reference" data-citation="BH">[?]</sup>. However, this trust may be unrealistic in many scenarios. We thus consider parties that, even wen uncorrupted, internally deviate slightly from their protocols. We call such parties <i>semi-honest</i>. Several degrees of internal deviation from the protocol are examined with the main focus on parties which follow their protocol with the exception that they keep record of the entire computation. We seek protocols that are secure even in the uncorrupted parties are semi-honest rather than honest.
						</p>
						<p class="rp_original">
							We discuss the problems encountered in the secure channels setting, and state the amount of internal deviation from the protocol under which adaptively secure protocols are known to exist. (In particular, under the conditions the <span class="reference" data-citation="BGW">[?]</span><sup class="reference" data-citation="CCD">[?]</sup> protocols can be proven adaptively secure.)
						</p>
						<p class="rp_original">
							Finally we concentrate on the computational setting, and on semi-honest parties that follow their protocols with the exception that no internal data is ever erased. Is adaptively secure computation possible in this scenario? This question has remained open since the result of <span class="reference" data-citation="GMW">[?]</span> (Even for the case in which the adversary only gather information from corrupted parties and does not make them deviate any further from the protocol).
						</p>
						<p class="rp_original">
							We answer this question in the affirmative. The problems encountered, and our solution, are presented via the following transformation. It is a folklore belief that any secure protocol in the secure channels setting can be transformed into a secure protocol in the computational setting, by encrypting each message using a standard semantically secure encryption scheme. This belief can indeed be turned into a proof, provided that only <i>non-adaptive</i> adversaries are considered. Trying to prove this belief in the presence of adaptive adversaries encounters major difficulties. We show how these difficulties are overcome if a novel encryption protocol is used, instead of standard encryption. We call such encryption protocols <i>non-committing</i> (Standard encryption schemes are not non-committing.)
						</p>
						<p class="rp_original">
							Non-committing encryption can be roughly described as follows. Traditional encryption schemes have the extra property that the ciphertext may serve as a <i>commitment</i> of the sender to the encrypted data. That is, suppose that after seeing the ciphertext, a third party requests the sender to <i>reveal</i> the encrypted data, and show how it was encrypted and decrypted. Using traditional encryption schemes it may be infeasible (or even impossible) for the sender to demonstrate that the encrypted data was any different than what was indeed transmitted. (In fact, many times encryption is explicitly or implicitly used for commitment.) In a <i>non-committing</i> encryption scheme, the ciphertext cannot be used to commit the sender (or the receiver) to the transmitted data. That is, a non-committing encryption protocol allows a simulator to generate <i>dummy ciphertexts</i> that look like genuine ones, and can be later "opened" as encryptions of either 1 or 0, at wish. We note that communication over absolutely secure channels is trivially non-committing, since the third party sees no "ciphertext".
						</p>
						<p class="rp_original">
							We present several constructions of non-committing encryption protocols. All constructions consist of a 'key distribution' stage which is independent of the transmitted data, followed by a single message sent from the sender to the receiver. In our most general construction, based on a primitive called common-domain trapdoor system, the key distribution stage requires participation of all parties (and is valid as long as at least <i>one</i> party remains uncorrupted). We also present two alternative constructions, based on the RSA and the Diffie-Hellman assumptions respectively, where the key distribution stage consists of one message sent fro mthe receiver to the sender.
						</p>
						<section id="sec1.1">
							<h3>1.1. Related Work</h3>
							<p class="rp_original">
								Independently of our work, Beaver has investigated the problem of converting, in the computational setting, protocols which are adaptively secure against eavesdropping adversaries into protocols adaptively secure against Byzantine adversaries<sup class="reference" data-citation="Be2">[?]</sup>. No protocols adaptively secure against eavesdropping adversaries were known prior to our work, nor are such protocols suggested in <span class="reference" data-citation="Be2">[?]</span>. We believe that the problem of adaptive security retains its difficulty even if only eavesdropping adversaries are considered. Following our work, and motivated by the "Incoercible Voting" Problem, Canetti et. al.<sup class="reference" data-citation="CDNO">[?]</sup> introduced a stronger type of non-committing encryption protocol as well as an implementation of it based on any trapdoor permutation.
							</p>
						</section>
						<section id="sec1.2">
							<h3>1.2. Organization</h3>
							<p class="rp_original">
								The rest of this paper is organized as follows. In <a href="#sec2">Section 2</a> we discuss the problem of adaptive security and our solution to it in more detail. We keep the presentation informal throughout this section. Precise definitions are given in <a href="#sec3">Section 3</a>. Our constructions for the non-erasing and honest-looking cases are presented in Sections <a href="#sec4">4</a> and <a href="#sec5">5</a>, respectively.
							</p>
						</section>
					</section>
					<section id="sec2">
						<h2>2. Semi-honesty and Adaptive Security</h2>
						<p class="rp_original">
							In this section we discuss the problem of adaptive security and our solution to it in more detail. We keep the presentation informal throughout this section. Precise definitions are given in <a href="#sec3">Section 3</a>. In <a href="#sec2.1">Subsection 2.1</a> we discuss the question of what can be expected from an honest party, and present several notions of semi-honest parties. In <a href="#sec2.2">Subsection 2.2</a> we describe the problems encountered when trying to prove adaptive security of protocols <i>in the secure channels setting</i>, and state existing solutions. In <a href="#sec2.3">Subsection 2.3</a> we present the additional problems encountered when trying to prove adaptive security of protocols <i>in the computational setting</i>, and sketch our solution.
						</p>
						<section id="sec2.1">
							<h3>2.1. Semi-honest Parties</h3>
							<p class="rp_original">
								The problem of adaptively secure computation is intimately related to the following question: To what extend can uncorrupted parties be trusted to carry out instructions that cannot be externally verified, such as erasing local data, or using randomness as instructed? Honest parties internally deviate from their protocol in many real-life scenarios, such as users that keep record of their passwords, stock-market brokers that keep records of their clients' orders, <i>operating systems</i> that "free" old memory instead of erasing it or take periodic snapshots of the memory (for error recovery purposes), and computers that use pseudorandom generators as their source of randomness instead of truly random bits. Consider for example a protocol in which party \(A\) is instructed to choose a random string \(r\) for party \(B\), hand \(r\) to \(B\), and then <i>erase \(r\)</i> from its own memory. Can \(B\) be certain that \(A\) no longer knows \(r\)? Furthermore, can \(A\) now convince a third party (or an adversary that later decides to corrupt \(A\)) that he no longer knows \(r\)?
							</p>
							<p class="rp_original">
								To address this issue we introduce the motion of a <i>semi-honest</i> party. Such a party "appears as honest" (i.e. seems to be following its protocol) from the point of view of an outside observer; however, internally, it may somewhat deviate from the protocol. For instance, a semi-honest party may fail to erase some internal data, or use randomness not as instructed. (However, semi-honest parties do <i>not</i> collaborate.) We wish to have protocols that are secure even when parties are not thoroughly trusted, or in other words when the uncorrupted parties are semi-honest rather than honest. We say that a protocol \(\pi'\) is a <i>semi-honest protocol</i> for a protocol \(\pi\) if a party running \(\pi'\) "appears as" an honest party running \(\pi\). We want the requirements from \(\pi\) to be satisfied <i>even if the uncorrupted parties are running any semi-honest protocol for \(\pi\)</i>. (In the sequel we use the terms 'semi-honest parties' and 'semi-honest protocols' interchangeably.)
							</p>
						</section>
					</section>
				</div>
            </div>
			<div class="main_toplevel main_section main_color7" id="footnotes">
                <h1>Footnotes</h1>
				
                <ol id="footnotes">
                    <li id="footnote1">
						<a href="#fref1">[^]</a>
					</li>
                </ol>
            </div>
            <div class="main_toplevel main_section main_color8" id="references">
                <h1>References</h1>
                <ol id="referencelist">
                    <li id="citation1">A citation</li>
                </ol>
            </div>
            <div class="main_toplevel main_section main_color9">
                <div class="rp_problems">
                    <p><a href="mailto:multipartycomputationorg+5@gmail.com">Problem with this page?</a></p>
                </div>
                <p>Created by Nicolas Schank 2014, Brown University</p>
				<p>All original work is free for any use by anyone whatsoever.</p>
				<p>For more information about liability and licensing of the original paper, see <a href="../liability.html">Liability</a>.</p>
            </div>
        </div>
    </body>
</html>
<!--
4. Transcribe paper
5. References
6. Annotate paper
	7.0. proofread
	7.1. copy assumptions
	7.2. copy theorems
	7.3. copy definitions
	7.4. mark definitions
	7.5. mark equations
	7.6. link to previous research
7. Write protocol descriptions 
8. Check previous research for places to link
9. Write intro, goals, results
10. Tags
11. Consider implementations
12. Find reference
-->