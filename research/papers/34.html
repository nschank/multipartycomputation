<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Multiparty Unconditionally Secure Protocols - Chaum, Crépeau, Damgård, 1988</title>
        <link rel="stylesheet" type="text/css" href="../../style/main.css">
        <link rel="stylesheet" type="text/css" href="../../style/equation.css">
        <link rel="stylesheet" type="text/css" href="../../style/ref.css">
        <link rel="stylesheet" type="text/css" href="../../style/glossary.css">
        <link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
        <link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
        <script type="text/javascript" src="../../script/equation.js"></script>
        <script type="text/javascript" src="../../script/ref.js"></script>
        <script type="text/javascript" src="../../script/def.js"></script>
        <script type="text/javascript" src="../../script/glossary.js"></script>
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/javascript">
			<!--
            function fill(box)
			{
				switch (box)
				{
					default:
						return "No info on this equation yet.";
				}
			}

			function authorLink(ref)
			{
				switch (ref)
				{
					default:
						return "#";
				}
			}

			self_def["non-general word"] = "definition";
			//-->
        </script>
    </head>
    <body>
        <div class="main_foreground">
            <div class="main_toplevel main_header">
                <h1>Multiparty Computation</h1>
            </div>
            <div class="main_toplevel main_navigation">
                <a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
                <a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
                <a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
                <a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
                <a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
                <a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
            </div>
            <div class="main_toplevel main_section main_color1">
                <div class="main_section_nav_container">
                    <div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
                    <div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
                    <div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
                    <div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
                </div>
                <div class="main_window main_fullwidth" id="_A"></a>
                    <div class="rp_linkbox"><a href="pdf/34.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
					
                    <span class="rp_title">Multiparty Unconditionally Secure Protocols</span>
                    <span class="rp_info">1988
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                        <a class="rp_author" href="../authors/David Chaum.html">David Chaum</a>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Claude Crépeau.html">Claude Crépeau</a>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Ivan Damgård.html">Ivan Damgård</a>
					</span>
					
					<div class="rp_snippet">
						&ldquo;[U]nder the assumption that each pair of participants can communicate secretly, any reasonable function can be computed if at least \(\frac{2n}{3}\) of the participants are honest...&rdquo;
					</div>
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a>
								<ol>
									<li><a href="#intro">Introduction</a></li>
									<li><a href="#goals">Goals and Results</a></li>
									<li><a href="#assumptions">Assumptions</a></li>
									<li><a href="#defs">Definitions</a></li>
									<li><a href="#theorems">Theorems</a></li>
									<li><a href="#protocols">Protocols</a></li>
									<li><a href="#further">Further Reading</a></li>
									<li><a href="#ref">Referencing This Paper</a></li>
								</ol>
							</li>
                            <li><a href="#_B">Annotated Extended Abstract</a></li>
                        </ol>
                    </div>
					
                    <h1>Overview</h1>					
                    <section id="intro">
						<h2>Introduction</h2>
						<p class="rp_analysis">
							<b>Multiparty Unconditionally Secure Protocols</b> is...
						</p>
					</section>
					<section id="goals">
						<h2>Goals and Results</h2>
						<p class="rp_analysis">
							Some goals that they had.
						</p>
						<p class="rp_analysis">
							This paper, along with a similar one <a href="17.html">the next year</a>, demonstrated the most malicious adversaries possible to thwart within a particular (but very common) framework of multiparty computation. Specifically, the <span class="definable">information theoretic security</span> of <i>any</i> function is demonstrated in an <span class="definable" data-define="authenticated network">authenticated</span> <span class="definable" data-define="secrecy network">secrecy</span> network, with or without a <span class="definable">broadcast channel</span>.
						</p>
					</section>
					<section id="assumptions">
						<h2>Assumptions</h2>
						<p class="rp_analysis">
							The authors are quick to note that information-theoretic security is only offered under the assumption that communication between parties is information-theoretically secure in the first place. As such, we must assume the existence of networks which are <span class="definable" data-define="authenticated network">authenticated</span>, <span class="definable" data-define="secrecy network">secret</span>, and unconditionally secure.
						</p>
					</section>
					<section id="defs">
						<h2>Definitions</h2>
						<a href="#def1"><span class="rp_definition_header">Definition 1 - </span></a>
						<p class="rp_original rp_definition">
							A definition 
						</p>
					</section>
					<section id="theorems">
						<h2>Theorems</h2>
						<p class="rp_original">Some general definitions used by several theorems</p>
						<a href="#theorem1"><span class="rp_theorem_header">Theorem 1</span></a>
						<p class="rp_original rp_theorem">
							A theorem
						</p>
					</section>
					<section id="protocol">
						<h2>Protocols</h2>
						<h3><a href="#secxx">Some Protocol Defined</a></h3>
						<ul class="rp_analysis">
							<li><b>Number of parties: </b></li>
							<li><b>Function(s): </b></li>
							<li><b>Privacy constraints: </b></li>
							<li><b>Security constraints: </b></li>
							<li><b>Cheating: </b></li>
							<li><b>Bits exchanged: </b></li>
							<li><b>Runtime:</b></li>
						</ul>
					</section>
					<section id="further">
						<h2>Further Reading</h2>
					</section>
					<section id="ref">
						<h2>Referencing This Paper</h2>
						<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
						<p class="rp_self_reference">
							A reference for this paper
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color5" id="_B">
                <div class="main_window main_fullwidth">
					<h1>Annotated Paper (extended abstract)</h1>
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a></li>
                            <li>
                                <a href="#_B">Annotated Paper</a>
                                <ol>
									<li value="0"><a href="#abstract">Abstract</a></li>
                                    <li>
										<a href="#sec1">Introduction</a>
										<ol>
											<li><a href="#sec1.1">Results</a></li>
											<li><a href="#sec1.2">Algorithm</a></li>
											<li><a href="#sec1.3">Related Works</a></li>
										</ol>
									</li>
									<li><a href="#sec2">The Model</a></li>
									<li><a href="#sec3">Implementing Blobs using Secret Sharing</a></li>
									<li><a href="#sec4">VSS and Fault Tolerant Blobs</a></li>
									<li><a href="#sec5">Multiparty Computations</a></li>
									<li><a href="#sec6">Generalizations</a></li>
									<li><a href="#sec7">Acknowledgements</a></li>
                                </ol>
                            </li>
                        </ol>
                    </div>
					<h1>Multiparty Unconditionally Secure Protocols</h1>
					<section id="abstract">
						<h2>Abstract</h2>
						Assume \(n\) participants \(P_1,P_2,\dots,P_n\) share the knowledge of a multivariable function \(F\) and that they want to publicly compute \(z=F(x_1,x_2,\dots,x_n)\), where \(x_i\) is a secret input provided by \(P_i\). The difficulty is to simultaneously provide the secrecy of each \(x_i\) and to guarantee the correctness of the common result \(z\). Such a task has been accomplished in <span class="reference" data-citation="1"><a href="#citation1">[1]</a></span> under the assumption that <span class="definable" data-define="trapdoor permutation">trapdoor permutations</span> exist. The result we propose in this extended abstract is that, under the assumption that each pair of participants can communicate secretly, any reasonable function can be computed if at least \(\frac{2n}{3}\) of the participants are honest and this is proved without any cryptographic assumption. Our result is based on a non-cryptographic verifiable secret-sharing protocol that we also introduce in this paper.
					</section>
                    <section id="sec1">
                        <h2>1. Introduction</h2>
						
						<p class="rp_original">
							The problem of multiparty function computation is as follows: \(n\) participants \(P_1,P_2,\dots,P_n\) sharing the knowledge of a multivariable function \(F\) want to publicly compute \(z=F(x_1,x_2,\dots,x_n)\), where \(x_i\) is a secret input provided by \(P_i\). The goal is to preserve the maximum privacy of the \(x_i\)'s and to simultaneously guarantee the correctness of the common result \(z\). Intrinsically, the value of \(z\) will reveal some information about the secret inputs. We say that input value \(x_i\) is cryptographically secure in this context if it is believed hard to determine in polynomial time more information about \(x_i\) than what is necessarily given by \(z\).
						</p>
						<p class="rp_original">
							The problem of achieving secure multiparty function computation in a public key cryptographic setting, was first posed by Yao<sup class="reference" data-citation="2"><a href="#citation2">[2]</a></sup>. He also asked for which functions this problem admitted a solution. The answer to these questions was found by Goldreich, Micali, and Wigderson<sup class="reference" data-citation="1"><a href="#citation1">[1]</a></sup> who showed that a solution, based on the existence of <span class="definable" data-define="trapdoor permutation">trapdoor one-way permutations</span>, exists no matter what the function is. They exhibited a "compiler" that transforms any multiparty function computation problem into a multiparty cryptographically secure protocol.
						</p>
						<p class="rp_original">
							Inspired by their work, Chaum, Damgård, and Van de Graaf presented a more direct and practical solution<sup class="reference" data-citation="3"><a href="#citation3">[3]</a></sup> based on a specific trapdoor function. Their protocol had the advantage that one \(x_i\) was unconditionally secure, i.e. no information at all is available about it, other than the amount released by \(z\). All these constructions rely on trapdoor one-way functions, and therefore must assume essentially that public key cryptography is possible.
						</p>
						<p class="rp_original">
							A much weaker assumption is to assert the existence of <span class="definable" data-define="authenticated network">authenticated</span> <span class="definable" data-define="secrecy network">secrecy</span> channels, i.e. a way of communicating in which the identity of the sender is known (authentication) and the data transferred is revealed only to the single person it is designed for (secrecy). Such channels are very practical and can be implemented very easily: for example, this channel can be obtained by writing down messages on pieces of paper and physically handing them out to the other parties. They can also be implemented using conventional cryptography (secret key systems). Two fundamental questions remain: Which protocol problems can be solved assuming only the existence of these authenticated secrecy channels between pairs of participants, and can all parties have their secrets unconditionally secure?
						</p>
						<section id="sec1.1">
							<h3>1.1. Results</h3>
							<p class="rp_original">
								In this paper, we show that essentially any multiparty protocol problem can be solved under the assumption of the existence of <span class="definable" data-define="authenticated network">authenticated</span> <span class="definable" data-define="secrecy network">secrecy</span> channels between pairs of participants and that each party's secrets can be unconditionally secure. As explained below, under such a model it is required that less than one third of the participants deviate from the protocol. The number of cheaters tolerated by our solution is therefore optimal.
							</p>
							<p class="rp_original">
								The techniques presented do not rely on any cryptographic assumptions; they provide secrecy and correctness by means of a new non-cryptographic verifiable secret sharing (VSS) scheme. These schemes were introduced in the cryptographic setting in <span class="reference" data-citation="4"><a href="#citation4">[4]</a></span>. To this day, all previous solutions relied on public key cryptography. We introduce the first VSS scheme that does not rely on such assumptions. Sections <a href="#sec3">3</a> and <a href="#sec4">4</a> are devoted to the construction of this new scheme and to its application toward achieving our goal.
							</p>
						</section>
						<section id="sec1.2">
							<h3>1.2. Algorithm</h3>
							<p class="rp_original">
								The general structure of the algorithms is similar to the ones of <span class="reference" data-citation="1"><a href="#citation1">[1]</a></span> and <span class="reference" data-citation="3"><a href="#citation3">[3]</a></span> in the sense that it takes place in two steps: Commitment and Computation. First the participants enter a stage in which they commit to their inputs. This commitment is performed using the VSS, so that every participant gets a share of everybody else's secret. If some participants are trying to commit to something improper or are simply not collaborating, this first phase will identify them and the remaining participants will take the actions relevant to this situation. This is the very best we can hope for. What else could you do with someone who does not want to participate? Once everyone has committed to their inputs, the second phase is the actual evaluation of the function. The computation is performed locally by each participant on the shares he or she got from the others.
							</p>
							<p class="rp_original">
								Our construction achieves the following properties:
							</p>
							<ul class="rp_original">
								<li>
									Unconditional Secrecy: In both stages, it is not possible for any subset of less than \(\frac{n}{3}\) participants to gain any information about the remaining people's inputs.
								</li>
								<li>
									Built-In Fault Tolerance: In the second phase, no such subset will be able to prevent the honest participants from completing correctly the secret evaluation of the function (see <a href="#sec5">Section 5</a>).
								</li>
							</ul>
							<p class="rp_original">
								Again, we mean that our solution does not depend on some restrictions of the computing power of the participants. Earlier solutions relied on cryptographic assumptions both for secrecy of the inputs and correctness of the computation. If in the best case these assumptions turned out to be true, the secrecy and correctness would still be dependent on the limitations in computing power of the participants.
							</p>
						</section>
						<section id="sec1.3">
							<h3>1.3. Related Works</h3>
							<p class="rp_original">
								Our work has drawn inspiration from and relies on a number of earlier contributions. The Byzantine Generals problem proposed and solved by <span class="reference" data-citation="5"><a href="#citation5">[5]</a></span> can be thought of as underlying our work. Also, the type of so-called secret sharing schemes proposed by <span class="reference" data-citation="6"><a href="#citation6">[6]</a></span> and <span class="reference" data-citation="7"><a href="#citation7">[7]</a></span> are basic building blocks. The usefulness of their homomorphic structure was observed by <span class="reference" data-citation="8"><a href="#citation8">[8]</a></span>, who proposed techniques very similar to ours.
							</p>
							<p class="rp_original">
								Other work has been able to provide unconditional privacy in multiparty protocols. A poker protocol<sup class="reference" data-citation="9"><a href="#citation9">[9]</a></sup> used a model similar to ours, but was unable to tolerate active cheaters. The dining cryptographers problem<sup class="reference" data-citation="10"><a href="#citation10">[10]</a></sup>, also based on a similar model, provided unconditional untraceability of messages and was able to tolerate active disruption. The present work stems from that of <span class="reference" data-citation="3"><a href="#citation3">[3]</a></span>, where general multiparty protocols were provided based on <span class="definable" data-define="trapdoor one-way function">trapdoor one-way functions</span> that can offer unconditional privacy to one participant. It was also shown there that unconditional protection of a single designated participant is all that can be achieved under that model.
							</p>
							<p class="rp_original">
								Some concurrent and independent work<sup class="reference" data-citation="11"><a href="#citation11">[11]</a></sup> has also been performed on this topic: during discussions with Shafi Goldwasser and Avi Wigderson, we learned that, together with Michael Ben-Or, they were working on results similar to ours. At that time, all of us had results in a very early stage. Finally, by the time of submission to this conference, both groups have ended up getting almost identical results by quite different means.
							</p>
							<p class="rp_annotation">
								Ben-Or, Goldwasser, and Wigderson's work can be found <a href="17.html">here</a>.
							</p>
						</section>
                    </section>
					<section id="sec2">
						<h2>2. The Model</h2>
						<p class="rp_original">
							For convenience, the number of participants will be called \(n\), which can always be written as \(n=3d+a\), where \(a=\) 1, 2, or 3. Let \(P_1,P_2,\cdots,P_n\) be the participants.
						</p>
						<p class="rp_original">
							Our assumptions about at least \(2d+a\) of the participants are that:
						</p>
						<ul class="rp_original">
							<li>They do not leak secret information to other participants; and</li>
							<li>They send the correct messages defined by the protocol</li>
						</ul>
						<p class="rp_original">
							We call a participant satisfying the above properties <i>reliable</i>. At the start of the protocol, it is of course not generally agreed which participants are reliable. Our basic assumptions about the communication between reliable participants \(P_A\) and \(P_B\) are that:
						</p>
						<ul class="rp_original">
							<li>When \(P_A\) sends a message to \(P_B\), nobody else can learn anything about its content;</li>
							<li>When \(P_B\) receives a message from \(P_A\), \(P_B\) can be certain that nobody but \(P_A\) could have sent the message; and</li>
							<li>Messages sent will be received in a timely manner.</li>
						</ul>
						<p class="rp_original">
							Finally, we complete our model by assuming the following:
						</p>
						<ul class="rp_original">
							<li>All participants agree on the protocols to be followed; and</li>
							<li>Participants can determine whether messages sent to them were sent before deadlines set in the protocol.</li>
						</ul>
						<p class="rp_original">
							Our protocols ensure that all reliable participants obtain the correct result. It is proved constructively in <span class="reference" data-citation="5"><a href="#citation5">[5]</a></span>, under a model like ours, that a necessary and sufficient condition for all reliable participants to agree on a message&mdash;such as the result of a protocol&mdash;is that at least \(2d+a\) of the participants are reliable. Hence, our two-thirds assumption is optimal. A polynomial algorithm solving this problem is presented in <span class="reference" data-citation="12"><a href="#citation12">[12]</a></span>. Their construction allows us to obtain an efficient <span class="definable" data-define="broadcast channel">"broadcast" channel</span>: a means allowing any participant to make a message known to all participants, in such a way that all reliable participants will obtain the same value of the message. (Assuming a broadcast channel, moreover, would not enable us to weaken our other requirements, but remains interesting in some other context, as explained in <a href="#sec6">Section 6</a>.)
						</p>
						<p class="rp_original">
							For simplicity in the following descriptions, we use the terminology of information theory because we make the assumption that the channels are unconditionally secure. Notice however that in fact we get protocols as strong as the secrecy and authentication of the channels used. If the channels were not unconditionally secure, for example, the protocol would not be unconditionally secure for all participants but its correctness would still be guaranteed.
						</p>
					</section>
					<section id="sec3">
						<h2>3. Implementing Blobs using Secret Sharing</h2>
						<p class="rp_original">
							In <span class="reference" data-citation="13"><a href="#citation13">[13]</a></span>, a fundamental protocol primitive is described: <i>the blob</i>. The purpose of blobs is to allow a participant \(P_A\) to <i><span class="definable" data-define="commitment">commit</span></i> to a bit in such a way that he or she cannot later change his or her mind about the bit, but nobody else can discover it without the participant's help. The defining properties of blobs are as follows:
						</p>
						<ol type="i">
							<li>\(P_A\) can obtain blobs representing 1 and blocks representing 0.</li>
							<li>When presented with a blob, nobody can tell which bit it represents.</li>
							<li>\(P_A\) can open blobs by showing the other participants the single bit each represents; there is no blob \(P_A\) is able to "open" both as \(0\) and as \(1\).</li>
							<li>Any other participant can at will obtain blobs representing 0 and 1. Moreover, these blobs must look exactly like the blobs obtained by \(P_A\).</li>
						</ol>
						<p class="rp_original">
							To implement blobs in our model, we use a variation on Shamir's secret sharing scheme<sup class="reference" data-citation="7"><a href="#citation7">[7]</a></sup>. This variation was proposed by Blakley<sup class="reference" data-citation="6"><a href="#citation6">[6]</a></sup>, who independently discovered secret sharing schemes, and it is more efficient than Shamir's original construction.
						</p>
						<p class="rp_original">
							For our purposes, the scheme may be described as follows: a polynomial \(f\) of degree at most \(d\) over \(GF(2^k)\) is chosen uniformly, where \(k\) is an integer such that \(2^k&gt;n\). The secret to be shared is defined for convenience as the value of \(f\) at 0. The protocol also assigns a distinct non-zero point \(i_B\) in the field to each participant \(P_B\). The secret can now be divided among the \(n\) participants by providing each \(P_B\) with the value of \(f(i_B)\). It is not hard to see that more than \(d\) shares completely determine \(f\), and therefore the secret, while no Shannon information about the secret is revealed by any number of shares not exceeding \(d\).
						</p>
						<p class="rp_annotation">
							Recall GF(n) to be the Galois field of size \(n\); that is, the <span class="definable">group</span> within \(Zn/Z\) with operations multiplication, addition, subtraction, and (non-zero) division.
						</p>
						<p class="rp_original">
							We generalize slightly by allowing blobs to represent any value in \(GF(2^k)\). Blobs are now readily achieved:
						</p>
						<ol type="i" class="rp_original">
							<li>
								To obtain a blob representing the value \(v\), participant \(P_A\) chooses uniformly a polynomial \(f\) with \(deg(f)\leq d\), such that \(f(0)=v\). \(P_A\) then calculates \(n\) shares as above and distributes one to each participant. Using the subprotocol described below, the other participants are convinced that a consistent set of shares was distributed.
							</li>
							<li>
								Since the number of unreliable participants is smaller than \(d\), no <span class="definable">collusion</span> will gain any information in the Shannon sense about the value represented by a blob.
							</li>
						</ol>
						<p class="rp_annotation">
							To convince yourself of this fact, recall that given \((d-1)\) points in a polynomial of degree \(d\), any other (distinct) point in the field produces a different polynomial. Let's begin by fixing the input value to the polynomial of the \(d\)-th share; two distinct shares, therefore, must describe two different polynomials. We will quickly prove that, given \(d-1\) shares, we can create a \(d\)-th share which can make the blob represent any secret \(v\). From there we can deduce that, since each value \(v\) could be represented by these distinct polynomials, and the polynomial was chosen uniformly at random, the probability distribution on \(v\) is constant given any \((d-1)\) shares.
						</p>
						<p class="rp_annotation">
							Assume we have two polynomials \(f_1,\,f_2\) which share the \(d-1\) shares within a collusion, and share the secret \(f_1(0)=f_2(0)=v\). From there, we can show that there is a bijection between secrets \(v\) and the last share used to fully describe the polynomial. First, we prove injectivity. Assume we have two distinct final shares, \((x,y_1),\,(x,y_2)\), so we know that \(f_1(x)=y_1,\,f_2(x)=y_2\). 
						</p>
						<ol type="i" class="rp_original">
							<li value="3">
								To open a blob, \(P_A\) first broadcasts what its shares should be \((\{i_B\;|\;1\leq B\leq n\})\). Then each participant broadcasts a message stating whether they agree with their share that was broadcast by \(P_A\). If a participant does not agree, he is said to be <i>complaining</i> about \(P_A\). It is required that at least \(2d+a\) of the participants do not complain. By the remarks below, this condition ensures that \(P_A\) can only open a blob to reveal the single value it represents.
							</li>
							<li>
								Any participant can choose a polynomial and distribute shares of it, whence it is impossible to tell from a blob who generated it.
							</li>
						</ol>
						<p class="rp_original">
							By distributing inconsistent shares to reliable participants, a coalition of unreliable participants could allow \(P_A\) to open a block in two or more different ways. The following proof, which we informally call a "cut-and-choose procedure" (and is similar to the construction of <span class="reference" data-citation="8"><a href="#citation8">[8]</a></span>) enables us to remove this inconsistency. Let the original blob chosen by \(P_A\) be \(\beta\). Then the cut-and-choose works as follows:
						</p>
						<ol class="rp_original" type="a">
							<li>\(P_A\) establishes a new independently chosen blob \(\delta\).</li>
							<li>One of the other participants flips a coin and asks \(P_A\) to open \(\delta\), or to open \(\delta+\beta\), where \(\delta+\beta\) denotes the blob defined by the sum of corresponding shares of \(\delta\) and \(\beta\).</li>
							<li>
								Steps (a) and (b) are repeated until no complaints have occurred in \(m\) consecutive rounds, or until more than \(d\) participants have complained about \(P_A\). In the first case the proof is accepted, otherwise it is rejected.
							</li>
						</ol>
						<p class="rp_original">
							The participants take turns in executing step (b). By assumption, this means that \(P_A\) will be unable to predict the coinflips at least \(\frac{2d+a}{n}\) of the time.
						</p>
						<p class="rp_original">
							Note that the proof will always terminate: even if all unreliable participants work against an honest \(P_A\), they cannot enlarge the number of rounds by more than \(md\).
						</p>
						<p class="rp_original">
							When \(\beta\) is later opened, the shares held by complaining participants are of course ignored.
						</p>
						<p class="rp_original">
							If the proof is accepted, then the following holds with probability exponentially close to 1 in \(m\): all reliable participants who did not complain (of which there are at least \(d+a\)) have shares consistent with one polynomial of degree at most \(d\).
						</p>
						<p class="rp_original">
							Thus, with very high probability, \(P_A\) cannot convincingly claim that her blob contains anything but the secret determined by the \(d+a\) valid shares guaranteed by the fact above, since otherwise the condition in step (iii) would be violated.
						</p>
						<p class="rp_original">
							To see why this is satisfied, it suffices to consider the behavior of reliable participants, corresponding to the worst case assumption that all unreliable participants will try to help \(P_A\) by always agreeing with her. For any blob \(\gamma\), consider a polynomial consistent with a maximal number of shares of \(\gamma\), and let \(C(\gamma)\) be the number of remaining shares held by reliable and non-complaining participants. Thus \(C(\gamma)\) may vary over time. In other words, no matter how \(P_A\) tries to open \(\gamma\), at least \(C(\gamma)\) participants will complain. The case where \(P_A\) created \(\gamma\) correctly corresponds of course to \(C(y)=0\).
						</p>
						<p class="rp_original">
							In any of the rounds of the subprotocol above, it is easy to see that because the sum of \(\delta\) and \(\delta+\beta\) is just \(\beta\), \(C(\delta)+C(\delta+\beta)\geq C(\beta)\) must hold. So if at any point \(C(\beta)\gt 0\), then \(P_A\) cannot go through \(m\) rounds without complaints unless she can predict roughly \(\frac{2m}{3}\) coinflips.
						</p>
						<p class="rp_original">
							In <span class="reference" data-citation="13"><a href="#citation13">[13]</a></span>, it is shown how one can construct, using only blobs, efficient <i>minimum disclosure proofs</i> for membership in a very large class of languages, including <span class="definable">NP</span> and <span class="definable">BPP</span>. Since we can construct blobs in our model, we can also perform all such proofs directly.
						</p>
					</section>
					<section id="sec4">
						<h2>4. VSS and Fault Tolerant Blobs</h2>
						<p class="rp_original">
							When opening a blob, \(P_A\) was to broadcast the shares she distributed in creating it. If \(P_A\) is trying to prove some statement using the techniques of <span class="reference" data-citation="13"><a href="#citation13">[13]</a></span>, the previous section's results imply that it is in \(P_A\)'s interest to create and broadcast the shares properly. But in other cases, communication failures or a change of heart, for example, might keep \(P_A\) from ultimately broadcasting the shares. Even if the other participants were to make \(P_A\)'s shares public in efforts to open the block without \(P_A\)'s help, they would be left with a computational problem: unreliable participants might make public false values for their shares, and finding the value represented may require searching the exponentially many subsets of shares of size \(2d+a\) for one consistent with one polynomial of degree smaller than \(d\). Even worse, if \(P_A\) was already cheating when she created the blob, the majority of complainers could be reliable. In such cases, unreliable participants could choose at the time of opening between broadcasts that would leave no unique solution for the secret or other broadcast that would yield a particular value unambiguously.
						</p>
						<p class="rp_original">
							This is where the secret sharing scheme becomes insufficient and a VSS is needed. To avoid the problems mentioned above, and assist with things to be presented later, we provide for the "sharing of the shares of a blob" (as was done for similar reasons in <span class="reference" data-citation="14"><a href="#citation14">[14]</a></span>). Thus, to create a <i>double</i> blob \(\delta, P_A\) proceeds as follows:
						</p>
						<ol class="rp_original">
							<li>She creates an ordinary blob in the same way as in the previous section. This blob is called the <i>top level</i> blob, and contains the secret she commits to.</li>
							<li>For each participant \(P_B\), the following is done: suppose \(P_A\) sent the share \(s_B\) of her original blob to \(P_B\). Then \(P_B\) creates a <i>sub-blob</i>, i.e. he creates a blob \(\beta_B\) containing his share \(s_B\).</li>
							<li>By the remarks in the previous section, all participants are now committed to their share of the top-level blob. A cut-and-choose procedure is now used to check that everybody has committed to the proper share: \(P_A\) creates a number of additional double blobs \(\delta_1,\delta_2,\cdots,\delta_t\) (for which each participant creates his own sub-blobs), and according to coin flips made by other participants, either all shares of the new double blob are made public or the sum of corresponding shares of the new and the original double blob are broadcast. Thus in each round, every participant opens a sub-blob of his own (either a new one or a sum) to confirm his agreement or disagreement with \(P_A\) on what was sent originally. In order for the proof to be accepted, a subset consisting of at least \(2d+a\) participants must agree with \(P_A\) in al rounds. If a participant disagrees with \(P_A\) at any point, then his share and sub-blob will be ignored when the original double blob is later opened.</li>
						</ol>
						<p class="rp_original">
							It is easily seen that if the proof in (3) above is accepted, then the following holds with probability exponentially close to 1 in the number of <span class="definable" data-define="coin flip">coin flips</span>:
						</p>
						<ul class="rp_original">
							<li>all sub-blobs accepted by the cut-and-choose contain a uniquely defined share of the top-level blob; and</li>
							<li>all these shares are consistent with one polynomial.</li>
						</ul>
						<p class="rp_original">
							To open a double blob, all participants broadcast heir shares of the top level blob as well as all shares of their sub-blobs. The result of the opening is uniquely and easily determined, since in this case the effect of the sub-blobs is to prevent unreliable participants from issuing improper shares of the top level blob: if a participant cannot confirm his share by opening his sub-blob correctly, it will just be ignored.
						</p>
					</section>
					<section id="sec5">
						<h2>5. Multiparty Computations</h2>
						<p class="rp_original">
							This section considers general multiparty computations. These may involve secret input from each participant, and a single output which should become known to all reliable participants.
						</p>
						<p class="rp_original">
							In the first step of the protocol, all participants commit to their secret input bits by distributing shares of them to all participants. The basic idea is now to do the computation by having each participant perform a corresponding computation on the shares he received. There are two problems with this idea: first, we cannot trust all participants to do the correct computation. Therefore participants must be committed to their shares, so that they can prove that the protocol was followed. This suggests a structure similar to that of a double blob. Secondly, for technical reasons explained later, all reliable participants must be able to complete the computation on their shares. Thus we cannot tolerate any complaints about the shares distributed, since there may be no way to tell whether a complainer is reliable or not. This leads to the following definition of a <i>robust</i> double blob:
						</p>
						<ol class="rp_original">
							<li>like a double blob, a robust double blob has a top-level blob and sub-blobs, where the top-level contains the bit committed to.</li>
							<li><i>all</i> sub-blobs contain valid shares of the top-level blob.</li>
						</ol>
						<p class="rp_original">
							The double blob as described in the previous section clearly does not always satisfy these properties. We can, however, get robustness by using the fact that a double blob, once verified by cut-and-choose, can always be opened without the help of its creator, and even in spite of unreliable participants. First, notice that the content of a top-level blob is completely determined by the shares of the sub-blobs (called sub-shares), if these are consistent. Thus, to create a robust double blob \(\rho, P_A\) creates a set \(S=\{d_1,d_2,\cdots,d_n\}\) of double blobs, each one is supposed to contain a share of \(\rho\) (note that the sub-blobs in \(\delta_B\) are created by \(P_B\) after receiving shares from \(P_A\)). Once each \(\delta_B\) is verified as in the previous section, it is opened to \(P_B\). Remember that this operation can be achieved without the help of \(P_A\). At this point \(P_B\) commits to the share hidden in the double blob \(\delta_B\) using a single blob \(\beta_B\). A gigantic cut-and-choose is then used over this structure to prove its correctness. Two things have to be proven about this structure:
						</p>
						<ul class="rp_original">
							<li>All double blobs in \(S\) contain shares of \(\rho\) consistent with one polynomial.</li>
							<li>Each \(P_B\) has committed to the same share as is contained in the double blob \(P_A\) made for him (\(Contents(\beta_B)=Contents(\delta_B)\)).</li>
						</ul>
						<p class="rp_original">
							We leave it as an exercise to design a cut-and-choose procedure that will establish this fact.
						</p>
						<p class="rp_original">
							Note that this protocol leaves no possibility for \(P_A\) to cheat and blame the resulting disagreement on some other participant: if less than \(d\) participants complain about \(P_A\), then a valid commitment has (with very high probability) been constructed, and otherwise it is obvious that \(P_A\) is unreliable.
						</p>
						<p class="rp_original">
							When this first phase including creation of commitments for all input bits and proofs of validity is completed successfully, the protocol is <span class="definable" data-define="fault-tolerance">fault-tolerant</span>: there is no way the unreliable participants can stop any reliable participant from computing the result.
						</p>
						<p class="rp_original">
							The computation is specified by a boolean circuit composed of XOR and AND gates. It is then clearly sufficient to be able to safely compute from two robust double blobs a new one both as the XOR of the two inputs and also as the AND.
						</p>
						<p class="rp_original">
							Computing the XOR of two double blobs is easy, based on the remarks in previous sections: all participants simply add their shares, both for the top-level blobs representing the actual bits, and for the sub-blobs. The outcome is just a new double blob representing the XOR of the inputs.
						</p>
						<p class="rp_original">
							Basically, computing the AND is just as simple: the participants merely multiply their shares. But this raises some technical problems, since the computation involves polynomials of degree larger than \(d\); polynomials of this large degree will not be robust enough against unreliable participants.
						</p>
						<p class="rp_original">
							Consequently, the AND is instead done in two steps:
						</p>
						<ol class="rp_original">
							<li>Each participant multiplies his shares of the two top-level blobs and commits to the product using a sub-blob. He then proves by a cut-and-choose (to be described below) that the multiplication was done correctly.</li>
						</ol>
						<p class="rp_original">
							The result of step 1 is a double blob containing the AND of the two bits, but with a large degree polynomial in the top-level blob. We cannot continue the computation with this blob, since for one thing the degree would eventually grow too large for the secrets to be uniquely determined. Therefore, this degree is brought down below \(d\) as follows:
						</p>
						<ol class="rp_original">
							<li value="2">Each participant chooses a pair of robust double blobs constructed as in the beginning of this section, and such that the top level involves a pair of randomly chosen polynomials \((f,g)\), where \(deg(f)\lt 2d, deg(g)\lt d,\) and \(f(0)=g(0)\in\{0,1\}\). We leave as an (easy) exercise construction of a cut-and-choose for proving correctness of such a pair. When all these pairs are added, the result will be a pair stil satisfying the conditions above, but such that nobody knows the common value of \(f\) and \(g\) in 0. Finally, the double blob constructed with \(f\) is x-ored with the one computed in step 1, and the result is opened. If this result is 0, then the computation continues with the blob from \(g\), otherwise \(1+g\) (the complemented bit) is used.</li>
						</ol>
						<p class="rp_original">
							We have now only to describe the cut-and-choose mentioned in step 1. In principle, this procedure is essentially the same as the computation protocols of <span class="reference" data-citation="15"><a href="#citation15">[15]</a></span>: the prover has committed to \(s_1,s_2,\) and \(s_3\), and claims that \(s_1s_2=s_3\). He then commits to a row-permuted version of the multiplication table for the field used. The other participants, responsive to their coin flips, now ask him either to open the entire table or to prove that one of the rows contains commitments to the tuple \((s_1,s_2,s_2)\). This is repeated to attain the desired level of certainty. Note that since the size of the field need only just exceed \(n\), only a number of messages quadratic in \(n\) are sent.
						</p>
						<p class="rp_original">
							We call attention to the possibility of a tradeoff between vulnerability to disruption and efficiency of the protocol. The initial commitment phase could in fact be completed correctly using only ordinary double blibs, if we require that <i>nobody</i> complains about anybody during the initial phase. This requirement is easily seen to imply that all the double blobs constructed are (with very high probability) robust. With this method, however, it is not possible to find out who has not been following the protocol in the first phase, if complaints do occur.
						</p>
					</section>
					<section id="sec6">
						<h2>6. Generalizations</h2>
						<p class="rp_original">
							The one third assumption on the number of unreliable participants is necessary to ensure that Byzantine agreement is possible. It is natural, however, to ask what can be done if we ensure this simply by assuming the existence of a <span class="definable">broadcast channel</span> as part of the model?
						</p>
						<p class="rp_original">
							In fact, even with this assumption, it is impossible to implement unconditionally secure blobs while tolerating more than \(d\) unreliable participants. Informally, this is so, since if \(P_A\) tries to commit to some secret, she must send a set of messages containing enough Shannon information to determine her secret completely. She cannot use the broadcast channel for this, since her secret would then become public immediately. Moreover, if there are \(U\) unreliable participants, then no subset of this size of smaller must be given enough information to determine the secret, since the set of unreliable participants is unknown. When later the participants try to determine which secret \(P_A\) is in fact committed to, the unreliable participants are free to fabricate some set of messages which they will claim \(P_A\) sent them originally. Since any subset of \(U\) messages leaves the secret completely undetermined, it is easy to construct the set of false messages such that it is consistent with the messages sent to \(U\) reliable participants. We thus have a situation where \(2U\) participants seem to agree on something, while the rest, say \(R\), participants are complaining. But if we allow \(U\gt n/3\), then \(R\leq U\), and thus there is no way of finding out whether the situation is in fact as described above, or the \(R\) participants are just unreliable ones, complaining for no good reason! Moreover, this ambiguous situation could result, even if \(P_A\) has followed the protocol. However, an extension is possible<sup class="reference" data-citation="16"><a href="#citation16">[16]</a></sup> using this broadcast channel: more unreliable participants can be tolerated if we are willing to revert to a cryptographic assumption in the case where \(n/3\lt U\lt n/2\). An "Obliviously Cryptographic" multiparty computation protocol may therefore be achieved given this feature. 
						</p>
						<p class="rp_original">
							It is also possible to tolerate more unreliable participants, if we change the model by restricting their behavior. If we assume that no participant will ever send an incorrect message during the protocol, then two forms of behavior remain, that may cause problems in the protocol:
						</p>
						<ol class="rp_original">
							<li>Sharing secret information with the other participants; and</li>
							<li>Stopping the protocol too early.</li>
						</ol>
						<p class="rp_original">
							In the following, assume that at least \(C\) participants will complete the protocol, while at most \(L\) participants will leak secrets to others.
						</p>
						<p class="rp_original">
							Clearly, information about the inputs to a computation must be distributed in such a way that any subset of \(C\) participants or more can recover all inputs, since otherwise there is no guarantee that the computation can be completed. But if the inputs are to remain unconditionally protected, this means that we must have \(L\lt C\).
						</p>
						<p class="rp_original">
							One can now make the simplifying assumption that the set of participants is partitioned in one subset in which participants may show both forms of unreliable behavior mentioned above, and another subset, where there is no deviation from the protocol at all. This means that \(C+L=n\), and therefore that \(L=\lfloor\frac{(n-1)}{2}\rfloor\lt C\). Hence the best a protocol can hope to do in this case is to tolerate the situation where \(L=\lfloor\frac{(n-1)}{2}\rfloor\) and \(C=n-L\). But this can easily be accomplished using our basic protocol with polynomials of degree \(L\). Because of the inequality on \(L\), multiplication of polynomials will not lead to loss of information. As usual, protection against early stopping is effective after the initial commitment phase, where double blobs are used. If a participant stops, the remaining ones can use the corresponding subshares as input to a separate instance of the basic protocol which will simulate the missing participant.
						</p>
						<p class="rp_original">
							Without the assumption that \(C+L=n\), things seem to become more complicated. It is clear that as long as \(L\leq\lfloor\frac{(n-1)}{2}\rfloor\), then the solution outlined above still works, but without this condition it is not clear what happens. The method with multiplication of polynomials does not work any more, because it leads to polynomials of a degree larger than the number of available shares. Therefore the construction of a general computation protocol under these special assumptions remains an open problem.
						</p>
					</section>
					<section id="sec7">
						<h2>7. Acknowledgements</h2>
						<p class="rp_original">
							We would like to thank Gilles Brassard, Ernie Brickell, Shafi Goldwasser, Jeroen van de Graaf, Silvio Micali, Micheal Sacks and Avi Wigderson for the discussions about this paper and their interest in our result.
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color8">
                <h1>References</h1>
                <ol id="referencelist">
                    <li id="citation1">Oded Goldreich, Silvio Micali, and Avi Wigderson. <a href="81.html">How to play any mental game or a completeness theorem for protocols with honest majority.</a> In <i>Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing</i>, pages 218–229, New York City, 25–27 May 1987.</li>
					<li id="citation2">A.C. Yao. <a href="49.html">Protocols for secure computations (extended abstract).</a> In <i>Proc. of the 23rd Annu. IEEE Symp. on Foundations of Computer Science.</i> pages 160-164. 1982.</li>
					<li id="citation3">Chaum, Damgard, and van de Graaf. <a href="82.html">Multiparty Computations ensuring secrecy of each party's input and correctness of the result.</a> To appear in <i>Proceedings of Crypto 87</i>.</li>
					<li id="citation4">Chor, Goldwasser, Micali, and Awerbuch: Verifiable Secret Sharing and Achieving Simultaneity in the Presence of faults. <i>Proceedings of FOCS 85</i>, pp.383-395.</li>
					<li id="citation5">Lamport, Shostak, and Pease: The Byzantine Generals Problem. ACM trans. <i>Prog. Languages and Systems</i>, vol.4, no.3, 1982, pp.382-401.</li>
					<li id="citation6">Blakely: Security proofs for information protection systems. <i>Proceedings of the 1980 Symposium on Security and Privacy</i>, IEEE Computer Society Press, NY, 198, pp.79-88.</li>
					<li id="citation7">Shamir: How to share a secret. <i>CACM</i>, vol.22, no.11, 1979, pp.612-613.</li>
					<li id="citation8">Benaloh: Secret sharing homomorphisms, <i>Proc. of Crypto 86</i>.</li>
					<li id="citation9">Bárány and Furedi: Mental Poker with Three or More Players, <i>Information and Control</i>, vol. 59, 1983, pp.84-93.</li>
					<li id="citation10">Chaum: The Dining Cryptographers Problem, to appear.</li>
					<li id="citation11">Ben-Or, Goldwasser, and Wigderson: Completeness Theorems for Non-Cryptographic Fault-Tolerant Distributed Computation. To appear in <i>Proceedings of STOC 88</i>.</li>
					<li id="citation12">Dole and Strong: Polynomial Algorithms for Multiple Processor Agreement. <i>Proceedings of STOC 82</i>, pp.401-407.</li>
					<li id="citation13">Brassard, Chaum, and Crépeau: Minimum Disclosure Proofs of knowledge. To appear.</li>
					<li id="citation14">Chaum: How to keep a secret alive.<i>Proceedings of Crypto 84.</i></li>
					<li id="citation15">Brassard and Crépeau: Zero-Knowledge Simulation of Boolean Circuits. <i>Proceedings of Crypto 86</i>.</li>
					<li id="citation16">Crépeau: Ph.D Thesis, in preparation</li>
                </ol>
            </div>
            <div class="main_toplevel main_section main_color9">
                <div class="rp_problems">
                    <p><a href="mailto:multipartycomputationorg+34@gmail.com">Problem with this page?</a></p>
                </div>
                <p>Created by Nicolas Schank 2014, Brown University</p>
				<p>All original work is free for any use by anyone whatsoever.</p>
				<p>For more information about liability and licensing Yao's original paper, see <a href="../liability.html">Liability</a>.</p>
            </div>
        </div>
    </body>
</html>
<!--
7. Annotate paper
	7.0. proofread
	7.1. copy assumptions
	7.2. copy theorems
	7.3. copy definitions
	7.4. mark definitions
	7.5. mark equations
	7.6. link to previous research
8. Write protocol descriptions 
9. Check previous research for places to link
10. Write intro, goals, results
11. Tags
12. Consider implementations
13. Find reference
-->