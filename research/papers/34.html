<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Multiparty Unconditionally Secure Protocols - Chaum, Crépeau, Damgård, 1988</title>
        <link rel="stylesheet" type="text/css" href="../../style/main.css">
        <link rel="stylesheet" type="text/css" href="../../style/equation.css">
        <link rel="stylesheet" type="text/css" href="../../style/ref.css">
        <link rel="stylesheet" type="text/css" href="../../style/glossary.css">
        <link rel="stylesheet" type="text/css" href="../../style/researchPaper.css">
        <link rel="icon" href="../../img/favicon.ico" type="image/x-icon">
		<script type="text/javascript" src="../../script/blockShare.js"></script>
        <script type="text/javascript" src="../../script/equation.js"></script>
        <script type="text/javascript" src="../../script/ref.js"></script>
        <script type="text/javascript" src="../../script/glossary.js"></script>
        <script type="text/javascript" src="../../script/def.js"></script>
        <script type="text/javascript"
                src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
        </script>
        <script type="text/javascript">
			<!--
            function fill(box)
			{
				switch (box)
				{
					default:
						return "No info on this equation yet.";
				}
			}

			function authorLink(ref)
			{
				switch (ref)
				{
					default:
						return "#";
				}
			}

			self_def["non-general word"] = "definition";
			//-->
        </script>
    </head>
    <body>
        <div class="main_foreground">
            <div class="main_toplevel main_header">
                <h1>Multiparty Computation</h1>
            </div>
            <div class="main_toplevel main_navigation">
                <a href="../../index.html"><div class="main_navbox"><h2>home</h2></div></a>
                <a href="../../learn.html"><div class="main_navbox"><h2>learn</h2></div></a>
                <a href="../../research.html"><div class="main_navbox"><h2>research</h2></div></a>
                <a href="../../nextsteps.html"><div class="main_navbox"><h2>build</h2></div></a>
                <a href="../../resources.html"><div class="main_navbox"><h2>resources</h2></div></a>
                <a href="../../aboutus.html"><div class="main_navbox"><h2>about us</h2></div></a>
            </div>
            <div class="main_toplevel main_section main_color1">
                <div class="main_section_nav_container">
                    <div class="main_section_nav_box"><a href="../timeline.html">Timeline</a></div>
                    <div class="main_section_nav_box"><a href="../title.html">By Title</a></div>
                    <div class="main_section_nav_box"><a href="../authors.html">By Author</a></div>
                    <div class="main_section_nav_box"><a href="../tag.html">By Category</a></div>
                </div>
                <div class="main_window main_fullwidth" id="_A"></a>
                    <div class="rp_linkbox"><a href="pdf/34.pdf"><img src="../../img/PDF.png" class="rp_link" alt="view pdf" /></a></div>
					
                    <span class="rp_title">Multiparty Unconditionally Secure Protocols</span>
                    <span class="rp_info">1988
                        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                        <a class="rp_author" href="../authors/David Chaum.html">David Chaum</a>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Claude Crépeau.html">Claude Crépeau</a>
						&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
						<a class="rp_author" href="../authors/Ivan Damgård.html">Ivan Damgård</a>
					</span>
						
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a>
								<ol>
									<li><a href="#intro">Introduction</a></li>
									<li><a href="#goals">Goals and Results</a></li>
									<li><a href="#assumptions">Assumptions</a></li>
									<li><a href="#defs">Definitions</a></li>
									<li><a href="#theorems">Theorems</a></li>
									<li><a href="#protocols">Protocols</a></li>
									<li><a href="#further">Further Reading</a></li>
									<li><a href="#ref">Referencing This Paper</a></li>
								</ol>
							</li>
                            <li><a href="#_B">Annotated Extended Abstract</a></li>
                        </ol>
                    </div>
					
                    <div class="rp_snippet">
						[U]nder the assumption that each pair of participants can communicate secretly, any reasonable function can be computed if at least \(\frac{2n}{3}\) of the participants are honest...
					</div>
						
                    <section id="intro">
						<h2>Introduction</h2>
						<p class="rp_analysis">
							<b>Multiparty Unconditionally Secure Protocols</b> is...
						</p>
					</section>
					<section id="goals">
						<h2>Goals and Results</h2>
						<p class="rp_analysis">
							Some goals that they had.
						</p>
						<p class="rp_analysis">
							Don't forget some results, too!
						</p>
					</section>
					<section id="assumptions">
						<h2>Assumptions</h2>
					</section>
					<section id="defs">
						<h2>Definitions</h2>
						<a href="#def1"><span class="rp_definition_header">Definition 1 - </span></a>
						<p class="rp_original rp_definition">
							A definition 
						</p>
					</section>
					<section id="theorems">
						<h2>Theorems</h2>
						<p class="rp_original">Some general definitions used by several theorems</p>
						<a href="#theorem1"><span class="rp_theorem_header">Theorem 1</span></a>
						<p class="rp_original rp_theorem">
							A theorem
						</p>
					</section>
					<section id="protocol">
						<h2>Protocols</h2>
						<h3><a href="#secxx">Some Protocol Defined</a></h3>
						<ul class="rp_analysis">
							<li><b>Number of parties: </b></li>
							<li><b>Function(s): </b></li>
							<li><b>Privacy constraints: </b></li>
							<li><b>Security constraints: </b></li>
							<li><b>Cheating: </b></li>
							<li><b>Bits exchanged: </b></li>
							<li><b>Runtime:</b></li>
						</ul>
					</section>
					<section id="further">
						<h2>Further Reading</h2>
					</section>
					<section id="ref">
						<h2>Referencing This Paper</h2>
						<p class="rp_analysis">To cite this paper, simply copy and paste the below into your citation:</p>
						<p class="rp_self_reference">
							A reference for this paper
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color5" id="_B">
                <div class="main_window main_fullwidth">
                    <div class="main_toc">
                        <h4 style="color:#333333">Table of Contents</h4>
                        <ol type="A">
                            <li><a href="#_A">Overview</a></li>
                            <li>
                                <a href="#_B">Annotated Extended Abstract</a>
                                <ol>
                                    <li>
										<a href="#sec1">Introduction</a>
										<ol>
											<li><a href="#sec1.1">Results</a></li>
											<li><a href="#sec1.2">Algorithm</a></li>
											<li><a href="#sec1.3">Related Works</a></li>
										</ol>
									</li>
                                </ol>
                            </li>
                        </ol>
                    </div>
					<h1>Multiparty Unconditionally Secure Protocols</h1>
					<section id="abstract">
						<h2>Abstract</h2>
						Assume \(n\) participants \(P_1,P_2,\dots,P_n\) share the knowledge of a multivariable function \(F\) and that they want to publicly compute \(z=F(x_1,x_2,\dots,x_n)\), where \(x_i\) is a secret input provided by \(P_i\). The difficulty is to simultaneously provide the secrecy of each \(x_i\) and to guarantee the correctness of the common result \(z\). Such a task has been accomplished in <span class="reference" data-citation="1"><a href="#citation1">[1]</a></span> under the assumption that <span class="definable" data-define="trapdoor permutation">trapdoor permutations</span> exist. The result we propose in this extended abstract is that, under the assumption that each pair of participants can communicate secretly, any reasonable function can be computed if at least \(\frac{2n}{3}\) of the participants are honest and this is proved without any cryptographic assumption. Our result is based on a non-cryptographic verifiable secret-sharing protocol that we also introduce in this paper.
					</section>
                    <section id="sec1">
                        <h2>1. Introduction</h2>
						
						<p class="rp_original">
							The problem of multiparty function computation is as follows: \(n\) participants \(P_1,P_2,\dots,P_n\) sharing the knowledge of a multivariable function \(F\) want to publicly compute \(z=F(x_1,x_2,\dots,x_n)\), where \(x_i\) is a secret input provided by \(P_i\). The goal is to preserve the maximum privacy of the \(x_i\)'s and to simultaneously guarantee the correctness of the common result \(z\). Intrinsically, the value of \(z\) will reveal some information about the secret inputs. We say that input value \(x_i\) is cryptographically secure in this context if it is believed hard to determine in polynomial time more information about \(x_i\) than what is necessarily given by \(z\).
						</p>
						<p class="rp_original">
							The problem of achieving secure multiparty function computation in a public key cryptographic setting, was first posed by Yao<sup class="reference" data-citation="2"><a href="#citation2">[2]</a></sup>. He also asked for which functions this problem admitted a solution. The answer to these questions was found by Goldreich, Micali, and Wigderson<sup class="reference" data-citation="1"><a href="#citation1">[1]</a></sup> who showed that a solution, based on the existence of <span class="definable" data-define="trapdoor one-way permutation">trapdoor one-way permutations</span>, exists no matter what the function is. They exhibited a "compiler" that transforms any multiparty function computation problem into a multiparty cryptographically secure protocol.
						</p>
						<p class="rp_original">
							Inspired by their work, Chaum, Damgård, and Van de Graaf presented a more direct and practical solution<sup class="reference" data-citation="3"><a href="#citation3">[3]</a></sup> based on a specific trapdoor function. Their protocol had the advantage that one \(x_i\) was unconditionally secure, i.e. no information at all is available about it, other than the amount released by \(z\). All these constructions rely on trapdoor one-way functions, and therefore must assume essentially that public key cryptography is possible.
						</p>
						<p class="rp_original">
							A much weaker assumption is to assert the existence of authenticated secrecy channels, i.e. a way of communicating in which the identity of the sender is known (authentication) and the data transferred is revealed only to the single person it is designed for (secrecy). Such channels are very practical and can be implemented very easily: for example, this channel can be obtained by writing down messages on pieces of paper and physically handing them out to the other parties. They can also be implemented using conventional cryptography (secret key systems). Two fundamental questions remain: Which protocol problems can be solved assuming only the existence of these authenticated secrecy channels between pairs of participants, and can al parties have their secrets unconditionally secure?
						</p>
						<section id="sec1.1">
							<h3>1.1. Results</h3>
							<p class="rp_original">
								In this paper, we show that essentially any multiparty protocol problem can be solved under the assumption of the existence of authenticated secrecy channels between pairs of participants and that each party;s secrets can be unconditionally secure. As explained below, under such a model it is required that less than one third of the participants deviate from the protocol. The number of cheaters tolerated by our solution is therefore optimal.
							</p>
							<p class="rp_original">
								The techniques presented do not rely on any cryptographic assumptions; they provide secrecy and correctness by means of a new non-cryptographi verifiable secret sharing (VSS) scheme. These schemes were introduced in the cryptographic setting in <span class="reference" data-citation="4"><a href="#citation4">[4]</a></span>. To this day, all previous solutions relied on public key cryptography. We introduce the first VSS scheme that does not rely on such assumptions. Sections <a href="#sec3">3</a> and <a href="#sec4">4</a> are devoted to the construction of this new scheme and to its application toward achieving our goal.
							</p>
						</section>
						<section id="sec1.2">
							<h3>1.2. Algorithm</h3>
							<p class="rp_original">
								The general structure of the algorithms is similar to the ones of <span class="reference" data-citation="1"><a href="#citation1">[1]</a></span> and <span class="reference" data-citation="3"><a href="#citation3">[3]</a></span> in the sense that it takes place in two steps: Commitment and Computation. First the participants enter a stage in which they commit to their inputs. This commitment is performed using the VSS, so that every participant gets a share of everybody else's secret. If some participants are trying to commit to something improper or are simply not collaborating, this first phase will identify them and the remaining participants will take the actions relevant to this situation. This is the very best we can hope for. What else could you do with someone who does not want to participate? Once everyone has committed to their inputs, the second phase is the actual evaluation of the function. The computation is performed locally by each participant on the shares he or she got from the others.
							</p>
							<p class="rp_original">
								Our construction achieves the following properties:
							</p>
							<ul class="rp_original">
								<li>
									Unconditional Secrecy: In both stages, it is not possible for any subset of less than \(\frac{n}{3}\) participants to gain any information about the remaining people's inputs.
								</li>
								<li>
									Built-In Fault Tolerance: In the second phase, no such subset will be able to prevent the honest participants from completing correctly the secret evaluation of the function (see <a href="#sec5">Section 5</a>).
								</li>
							</ul>
							<p class="rp_original">
								Again, we mean that our solution does not depend on some restrictions of the computing power of the participants. Earlier solutions relied on cryptographic assumptions both for secrecy of the inputs and correctness of the computation. If in the best case these assumptions turned out to be true, the secrecy and correctness would still be dependent on the limitations in computing power of the participants.
							</p>
						</section>
						<section id="sec1.3">
							<h3>1.3. Related Works</h3>
							<p class="rp_original">
								Our work has drawn inspiration from and relies on a number of earlier contributions. The Byzantine Generals problem proposed and solved by <span class="reference" data-citation="5"><a href="#citation5">[5]</a></span> can be thought of as underlying our work. Also, the type of so called secret sharing schemes proposed by <span class="reference" data-citation="6"><a href="#citation6">[6]</a></span> and <span class="reference" data-citation="7"><a href="#citation7">[7]</a></span> are basic building blocks. The usefulness of their homomorphic structue was observed by <span class="reference" data-citation="8"><a href="#citation8">[8]</a></span>, who proposed techniques very similar to ours.
							</p>
							<p class="rp_original">
								Other work has been able to provide unconditional privacy in multiparty protocols. A poker protocol<sup class="reference" data-citation="9"><a href="#citation9">[9]</a></sup> used a model similar to ours, but was unable to tolerate active cheaters. The dining cryptographers problem<sup class="reference" data-citation="10"><a href="#citation10">[10]</a></sup>, also based on a similar model, provided unconditional untraceability of messages and was able to tolerate active disruption. The present work stems from that of <span class="reference" data-citation="3"><a href="#citation3">[3]</a></span>, where general multiparty protocols were provided based on <span class="definable" data-define="trapdoor one-way function">trapdoor one-way functions</span> that can offer unconditional privacy to one participant. It was also shown there that unconditional protection of a single designated participant is all that can be achieved under that model.
							</p>
							<p class="rp_original">
								Some concurrent and independent work<sup class="reference" data-citation="11"><a href="#citation11">[11]</a></sup> has also been performed on this topic: during discussions with Shafi Goldwasser and Avi Wigderson, we learned that, together with Michael Ben-Or, they were working on results similar to ours. At that time, all of us had results in a very early stage. Finally, by the time of submission to this conference, both groups have ended up getting almost identical results by quite different means.
							</p>
						</section>
                    </section>
					<section id="sec2">
						<h2>2. The Model</h2>
						<p class="rp_original">
							For convenience, the number of participants will be called \(n\), which can always be written as \(n=3d+a\), where \(a=\)1, 2, or 3. Let \(P_1,P_2,\cdots,P_n\) be the participants.
						</p>
						<p class="rp_original">
							Our assumptions about at least \(2d+a\) of the participants are that:
						</p>
						<ul class="rp_original">
							<li>They do not leak secret information to other participants; and</li>
							<li>They send the correct messages defined by the protocol</li>
						</ul>
						<p class="rp_original">
							We call a participant satisfying the above properties <i>reliable</i>. At the start of the protocol, it is of course not generally agreed which participants are reliable. Our basic assumptions about the communication between reliable participants \(P_A\) and \(P_B\) are that:
						</p>
						<ul class="rp_original">
							<li>When \(P_A\) sends a message to \(P_B\), nobody else can learn anything about its content;</li>
							<li>When \(P_B\) receives a message from \(P_A\), \(P_B\) can be certain that nobody but \(P_A\) could have sent the message; and</li>
							<li>Messages sent will be received in a timely manner.</li>
						</ul>
						<p class="rp_original">
							Finally, we complete our model by assuming the following:
						</p>
						<ul class="rp_original">
							<li>All participants agree on the protocols to be followed; and</li>
							<li>Participants can determine whether messages sent to them were sent before deadlines set in the protocol.</li>
						</ul>
						<p class="rp_original">
							Our protocols ensure that all reliable participants obtain the correct result. IT is proved constructively in <span class="reference" data-citation="5"><a href="#citation5">[5]</a></span>, under a model like ours, that a necessary and sufficient condition for all reliable participants to agree on a message&mdash;such as the result of a protocol&mdash;is that at least \(2d+a\) of the participants are reliable. Hence, our two-thirds assumption is optimal. A polynomial algorithm solving this problem is presented in <span class="reference" data-citation="12"><a href="#citation12">[12]</a></span>. Their construction allows us to obtain an efficient "broadcast" channel: a means allowing any participant to make a message known to all participants, in such a way that all reliable participants will obtain the same value of the message. (Assuming a broadcast channel, moreover, would not enable us to weaken our other requirements, but remains interesting in some other context, as explained in <a href="#sec6">Section 6</a>.)
						</p>
						<p class="rp_original">
							For simplicity in the following descriptions, we use the terminology of information theory because we make the assumption that the channels are unconditionally secure. Notice however that in fact we get protocols as strong as the secrecy and authentication of the channels used. If the channels were not unconditionally secure, for example, the protocol would not be unconditionally secure for all participants but its correctness would still be guaranteed.
						</p>
					</section>
					<section id="sec3">
						<h2>3. Implementing Blobs using Secret Sharing</h2>
						<p class="rp_original">
							In <span class="reference" data-citation="13"><a href="#citation13">[13]</a></span>, a fundamental protocol primitive is described: <i>the blob</i>. The purpose of blobs is to allow a participant \(P_A\) to <i><span class="definable" data-define="commitment">commit</span></i> to a bit in such a way that he or she cannot later change his or her mind about the bit, but nobody else can discover it without the participant's help. The defining properties of blocks are as follows:
						</p>
						<ol type="i">
							<li>\(P_A\) can obtain blobs representing 1 and blocks representing 0.</li>
							<li>When presented with a blob, nobody can tell which bit it represents.</li>
							<li>\(P_A\) can open blobs by showing the other participants the single bit each represents; there is no blob \(P_A\) is able to "open" both as \(0\) and as \(1\).</li>
							<li>Any other participant can at will obtain blobs representing 0 and 1. Moreover, these blobs must look exactly like the blobs obtained by \(P_A\).</li>
						</ol>
						<p class="rp_original">
							To implement blobs in our model, we use a variation on Shamir's secret sharing scheme<sup class="reference" data-citation="7"><a href="#citation7">[7]</a></sup>. This variation was proposed by Blakley<sup class="reference" data-citation="6"><a href="#citation6">[6]</a></sup>, who independently discovered secret sharing schemes, and it is more efficient than Shamir's original construction.
						</p>
						<p class="rp_original">
							For our purposes, the scheme may be described as follows: a polynomial \(f\) of degree at most \(d\) over \(GF(2^k)\) is chosen uniformly, where \(k\) is an integer such that \(2^k&gt;n\). The secret to be shared is defined for convenience as the value of \(f\) at 0. The protocol also assigns a distinct non-zero point \(i_B\) in the field to each participant \(P_B\). The secret can now be divided among the \(n\) participants by providing each \(P_B\) with the value of \(f(i_B)\). It is not hard to see that more than \(d\) shares completely determine \(f\), and therefore the secret, while no Shannon information about the secret is revealed by any number of shares not exceeding \(d\).
						</p>
						<p class="rp_original">
							We generalize slightly by allowing blobs to represent any value in \(GF(2^k)\). Blobs are now readily achieved:
						</p>
						<ol type="i">
							<li>
								To obtain a blob representing the value \(v\), participant \(P_A\) chooses uniformly a polynomial \(f\) with \(def(f)\leq d\), such that \(f(0)=v\). She then calculates \(n\) shares as above and distributes one to each participant. Using the subprotocol described below, she convinces the other participants that she has distributed a consistent set of shares.
							</li>
							<li>
								Since the number of unreliable participants is smaller than \(d\), no <span class="definable">collusion</span> will gain any information in the Shannon sense about the value represented by a blob.
							</li>
							<li>
								To open a blob, \(P_A\) first broadcasts what its shares should be \((\{i_B\;|\;1\leq B\leq n\})\). Then each participant broadcasts a message stating whether they agree with their share that was broadcast by \(P_A\). If a participant does not agree, he is said to be <i>complaining</i> about \(P_A\). It is required that at least \(2d+a\) of the participants do not complain. By the remarks below, this condition ensures that \(P_A\) can only open a blob to reveal the single value it represents.
							</li>
							<li>
								Any participant can choose a polynomial and distribute shares of it, whence it is impossible to tell from a blob who generated it.
							</li>
						</ol>
						<p class="rp_original">
							By distributing inconsistent shares to reliable participants, a coalition of unreliable participants could allow \(P_A\) to open a block in two or more different ways. The following proof, which we informally call a "cut-and-choose procedure" (and is similar to the construction of <span class="reference" data-citation="8"><a href="#citation8">[8]</a></span>) enables us to remove this inconsistency. Let the original blob chosen by \(P_A\) be \(\beta\). Then the cut-and-choose works as follows:
						</p>
						<ol class="rp_original" type="a">
							<li>\(P_A\) establishes a new independently chosen blob \(\delta\).</li>
							<li>One of the other participants flips a coin and asks \(P_A\) to open \(\delta\), or to open \(\delta+\beta\), where \(\delta+\beta\) denotes the blob defined by the sum of corresponding shares of \(\delta\) and \(\beta\).</li>
							<li>
								Steps (a) and (b) are repeated until no complaints have occurred in \(m\) consecutive rounds, or until more than \(d\) participants have complained about \(P_A\). In the first case the proof is accepted, otherwise it is rejected.
							</li>
						</ol>
						<p class="rp_original">
							The participants take turns in executing step (b). By assumption, this means that \(P_A\) will be unable to predict the coinflips at least \(\frac{2d+a}{n}\) of the time.
						</p>
						<p class="rp_original">
							Note that the proof will always terminate: even if all unreliable participants work against an honest \(P_A\), they cannot enlarge the number of rounds by more than \(md\).
						</p>
						<p class="rp_original">
							When \(\beta\) is later opened, the shares held by complaining participants are of course ignored.
						</p>
						<p class="rp_original">
							If the proof is accepted, then the following holds with probability exponentially close to 1 in \(m\): all reliable participants who did not complain (of which there are at least \(d+a\)) have shares consistent with one polynomial of degree at most \(d\).
						</p>
						<p class="rp_original">
							Thus, with very high probability, \(P_A\) cannot convincingly claim that her blob contains anything but the secret determined by the \(d+a\) valid shares guaranteed by the fact above, since otherwise the condition in step (iii) would be violated.
						</p>
						<p class="rp_original">
							To see why this is satisfied, it suffices to consider the behavior of reliable participants, corresponding to the worst case assumption that all unreliable participants will try to help \(P_A\) by always agreeing with her. For any blob \(\gamma\), consider a polynomial consistent with a maximal number of shares of \(\gamma\), and let \(C(\gamma)\) be the number of remaining shares held by reliable and non-complaining participants. Thus \(C(\gamma)\) may vary over time. In other words, no matter how \(P_A\) tries to open \(\gamma\), at least \(C(\gamma)\) participants will complain. The case where \(P_A\) created \(\gamma\) correctly corresponds of course to \(C(y)=0\).
						</p>
					</section>
                </div>
            </div>
            <div class="main_toplevel main_section main_color8">
                <h1>References</h1>
                <ol id="referencelist">
                    <li id="citation1">GMW</li>
					<li id="citation2">Ya</li>
					<li id="citation3">CDG</li>
					<li id="citation4">CGMA</li>
					<li id="citation5">LPS</li>
					<li id="citation6">Bl</li>
					<li id="citation7">Sh</li>
					<li id="citation8">Be</li>
					<li id="citation9">BF</li>
					<li id="citation10">Ch2</li>
					<li id="citation11">BGW</li>
					<li id="citation12">DS</li>
					<li id="citation13">BCC</li>
                </ol>
            </div>
            <div class="main_toplevel main_section main_color9">
                <div class="rp_problems">
                    <p><a href="mailto:multipartycomputationorg+34@gmail.com">Problem with this page?</a></p>
                </div>
                <p>Copyright &copy; Nicolas Schank 2014, Brown University</p>
            </div>
        </div>
    </body>
</html>